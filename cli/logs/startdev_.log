== startdev 2023-07-31T16:01:00Z Start Airflow local containers
Attaching to airflow-airflow-init-1, airflow-airflow-scheduler-1, airflow-airflow-triggerer-1, airflow-airflow-webserver-1, airflow-airflow-worker-1, airflow-postgres-1, airflow-redis-1
airflow-airflow-init-1       | 
airflow-airflow-init-1       | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | [[34m2023-07-31T16:01:04.179+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:01:04.180+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:01:04.186+0000[0m] {[34mdb.py:[0m1591} INFO[0m - Creating tables[0m
airflow-airflow-init-1       | Upgrades done
airflow-airflow-init-1       | airflow already exist in the db
airflow-airflow-init-1       | 2.6.3
airflow-airflow-init-1 exited with code 0
airflow-airflow-triggerer-1  | 
airflow-airflow-worker-1     | 
airflow-airflow-webserver-1  | 
airflow-airflow-scheduler-1  | 
airflow-airflow-scheduler-1  | BACKEND=redis
airflow-airflow-scheduler-1  | DB_HOST=redis
airflow-airflow-scheduler-1  | DB_PORT=6379
airflow-airflow-worker-1     | BACKEND=redis
airflow-airflow-worker-1     | DB_HOST=redis
airflow-airflow-worker-1     | DB_PORT=6379
airflow-airflow-scheduler-1  | 
airflow-airflow-triggerer-1  |   ____________       _____________
airflow-airflow-triggerer-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-triggerer-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-triggerer-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-triggerer-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:01:13.680+0000[0m] {[34mtriggerer_job_runner.py:[0m173} INFO[0m - Setting up TriggererHandlerWrapper with handler <FileTaskHandler (NOTSET)>[0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:01:13.961+0000[0m] {[34mtriggerer_job_runner.py:[0m229} INFO[0m - Setting up logging queue listener with handlers [<RedirectStdHandler <stdout> (NOTSET)>, <TriggererHandlerWrapper (NOTSET)>][0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:01:13.982+0000[0m] {[34mtriggerer_job_runner.py:[0m325} INFO[0m - Starting the triggerer[0m
airflow-airflow-worker-1     | 
airflow-airflow-scheduler-1  |   ____________       _____________
airflow-airflow-scheduler-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-scheduler-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-scheduler-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-scheduler-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:01:16.088+0000[0m] {[34mexecutor_loader.py:[0m114} INFO[0m - Loaded executor: CeleryExecutor[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:01:16.118+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:01:16.119+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:01:16.122+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 30[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:01:16.123+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:01:16.127+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
airflow-airflow-worker-1     |  
airflow-airflow-worker-1     |  -------------- celery@cc22559518e2 v5.2.7 (dawn-chorus)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     | -- ******* ---- Linux-5.19.0-50-generic-x86_64-with-debian-11.7 2023-07-31 16:01:16
airflow-airflow-worker-1     | - *** --- * --- 
airflow-airflow-worker-1     | - ** ---------- [config]
airflow-airflow-worker-1     | - ** ---------- .> app:         airflow.executors.celery_executor:0x7f3930723790
airflow-airflow-worker-1     | - ** ---------- .> transport:   redis://redis:6379/0
airflow-airflow-worker-1     | - ** ---------- .> results:     postgresql://airflow:**@postgres/airflow
airflow-airflow-worker-1     | - *** --- * --- .> concurrency: 16 (prefork)
airflow-airflow-worker-1     | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     |  -------------- [queues]
airflow-airflow-worker-1     |                 .> default          exchange=default(direct) key=default
airflow-airflow-worker-1     |                 
airflow-airflow-worker-1     | 
airflow-airflow-worker-1     | [tasks]
airflow-airflow-worker-1     |   . airflow.executors.celery_executor.execute_command
airflow-airflow-worker-1     | 
airflow-airflow-webserver-1  | [[34m2023-07-31T16:01:20.416+0000[0m] {[34mproviders_manager.py:[0m247} INFO[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:01:40 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /home HTTP/1.1" 200 419815 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:51 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.18.0.1 - - [31/Jul/2023:16:01:52 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
== startdev 2023-07-31T16:06:10Z Start Airflow local containers
== startdev 2023-07-31T16:07:02Z Start Airflow local containers
Attaching to airflow-airflow-init-1
airflow-airflow-init-1  | 
airflow-airflow-init-1  | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1  | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1  | [[34m2023-07-31T16:09:00.751+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:00.752+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:00.754+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:00.754+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1  | Upgrades done
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.401+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.406+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Public[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.409+0000[0m] {[34mmanager.py:[0m853} WARNING[0m - No user yet created, use flask fab command to do it.[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.445+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Passwords[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.449+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Passwords to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.455+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Passwords[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.458+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Passwords to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.470+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on My Password[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.473+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.479+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on My Password[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.483+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.495+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on My Profile[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.498+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.504+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on My Profile[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.507+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.534+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.538+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.545+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.548+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.554+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.558+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.565+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.569+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.581+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on List Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.585+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on List Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.599+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Security[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.603+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Security to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.623+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.627+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.633+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.637+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.643+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.646+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.652+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.656+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.668+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on List Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.672+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on List Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.690+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on User Stats Chart[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.694+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on User Stats Chart to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.705+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on User's Statistics[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.710+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on User's Statistics to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.736+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Permissions[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.739+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Permissions to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.750+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Actions[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.755+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Actions to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.781+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on View Menus[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.784+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on View Menus to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.795+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Resources[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.798+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Resources to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.822+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Permission Views[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.827+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Permission Views to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.837+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Permission Pairs[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:03.841+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Permission Pairs to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:09:04.407+0000[0m] {[34mmanager.py:[0m212} INFO[0m - Added user airflow[0m
airflow-airflow-init-1  | User "airflow" created with role "Admin"
airflow-airflow-init-1  | 2.6.3
airflow-airflow-init-1 exited with code 0
Attaching to airflow-airflow-init-1, airflow-airflow-scheduler-1, airflow-airflow-triggerer-1, airflow-airflow-webserver-1, airflow-airflow-worker-1, airflow-postgres-1, airflow-redis-1
airflow-airflow-init-1       | 
airflow-airflow-init-1       | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | [[34m2023-07-31T16:09:08.854+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:09:08.854+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:09:08.861+0000[0m] {[34mdb.py:[0m1591} INFO[0m - Creating tables[0m
airflow-airflow-init-1       | Upgrades done
airflow-airflow-init-1       | airflow already exist in the db
airflow-airflow-init-1       | 2.6.3
airflow-airflow-init-1 exited with code 0
airflow-airflow-triggerer-1  | 
airflow-airflow-webserver-1  | 
airflow-airflow-scheduler-1  | 
airflow-airflow-worker-1     | 
airflow-airflow-worker-1     | BACKEND=redis
airflow-airflow-worker-1     | DB_HOST=redis
airflow-airflow-worker-1     | DB_PORT=6379
airflow-airflow-scheduler-1  | BACKEND=redis
airflow-airflow-scheduler-1  | DB_HOST=redis
airflow-airflow-scheduler-1  | DB_PORT=6379
airflow-airflow-scheduler-1  | 
airflow-airflow-worker-1     | 
airflow-airflow-triggerer-1  |   ____________       _____________
airflow-airflow-triggerer-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-triggerer-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-triggerer-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-triggerer-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:09:23.355+0000[0m] {[34mtriggerer_job_runner.py:[0m173} INFO[0m - Setting up TriggererHandlerWrapper with handler <FileTaskHandler (NOTSET)>[0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:09:24.362+0000[0m] {[34mtriggerer_job_runner.py:[0m229} INFO[0m - Setting up logging queue listener with handlers [<RedirectStdHandler <stdout> (NOTSET)>, <TriggererHandlerWrapper (NOTSET)>][0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:09:24.394+0000[0m] {[34mtriggerer_job_runner.py:[0m325} INFO[0m - Starting the triggerer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.066+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.074+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.085+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.090+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.098+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.103+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.110+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.115+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.122+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.129+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role Admin[0m
airflow-airflow-scheduler-1  |   ____________       _____________
airflow-airflow-scheduler-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-scheduler-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-scheduler-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-scheduler-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:09:26.135+0000[0m] {[34mexecutor_loader.py:[0m114} INFO[0m - Loaded executor: CeleryExecutor[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.154+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Browse[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.159+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role Admin[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:09:26.183+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.185+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Jobs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:09:26.184+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.192+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role Admin[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:09:26.191+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 31[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:09:26.192+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:09:26.195+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.204+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Jobs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.209+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.252+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Audit Logs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.258+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.266+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Audit Logs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.271+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.314+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.321+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.331+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.338+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.346+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.352+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.361+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.366+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.375+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.380+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.405+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.411+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Admin to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.443+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.450+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.459+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.465+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.473+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.571+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.580+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.586+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.595+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.601+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.652+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Task Reschedules[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.659+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Reschedules to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.672+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Task Reschedules[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.682+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Reschedules to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.727+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Triggers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.733+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Triggers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.741+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Triggers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.748+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Triggers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.782+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Configurations[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.788+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Configurations to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.797+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Configurations[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.803+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Configurations to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.850+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.856+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.865+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.870+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.879+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.885+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.893+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.901+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.910+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.916+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.956+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.962+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.970+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.977+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.988+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: muldelete on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:26.996+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission muldelete on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.004+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulemailsent on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.009+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulemailsent on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.017+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulemailsentfalse on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.022+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulemailsentfalse on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.030+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulnotificationsent on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.036+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulnotificationsent on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.043+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulnotificationsentfalse on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.050+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulnotificationsentfalse on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.084+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Plugins[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.091+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.109+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Plugins[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.114+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.147+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Providers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.153+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Providers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.161+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Providers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.167+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Providers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.227+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.235+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.243+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.249+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.262+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.272+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.279+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.285+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.294+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.300+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.345+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.351+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.359+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.365+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.375+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.381+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.389+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.397+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.438+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on DAG Dependencies[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.445+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.480+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on DAGs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.488+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.507+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Datasets[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.517+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.532+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Documentation[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.538+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.553+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Docs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:27.560+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.116+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAGs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.141+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on DAGs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.156+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on DAGs[0m
airflow-airflow-worker-1     |  
airflow-airflow-worker-1     |  -------------- celery@1f69c81681e2 v5.2.7 (dawn-chorus)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     | -- ******* ---- Linux-5.19.0-50-generic-x86_64-with-debian-11.7 2023-07-31 16:09:28
airflow-airflow-worker-1     | - *** --- * --- 
airflow-airflow-worker-1     | - ** ---------- [config]
airflow-airflow-worker-1     | - ** ---------- .> app:         airflow.executors.celery_executor:0x7f6a8c0ce990
airflow-airflow-worker-1     | - ** ---------- .> transport:   redis://redis:6379/0
airflow-airflow-worker-1     | - ** ---------- .> results:     postgresql://airflow:**@postgres/airflow
airflow-airflow-worker-1     | - *** --- * --- .> concurrency: 16 (prefork)
airflow-airflow-worker-1     | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     |  -------------- [queues]
airflow-airflow-worker-1     |                 .> default          exchange=default(direct) key=default
airflow-airflow-worker-1     |                 
airflow-airflow-worker-1     | 
airflow-airflow-worker-1     | [tasks]
airflow-airflow-worker-1     |   . airflow.executors.celery_executor.execute_command
airflow-airflow-worker-1     | 
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.412+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Datasets[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.521+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on ImportError[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.713+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Code[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.742+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Warnings[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.946+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.957+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.961+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.973+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Dependencies[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.976+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.979+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.982+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.985+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.988+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.990+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.994+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:28.997+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.001+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.004+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.007+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.010+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.013+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.016+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.023+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Task Logs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.026+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.028+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.036+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Website[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.039+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.042+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.045+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.048+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.050+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.053+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.056+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.061+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.064+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.067+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.070+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.074+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.079+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.082+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.088+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.091+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.099+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.102+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.105+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.108+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.111+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.114+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.117+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.120+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.123+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.126+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.129+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.132+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.135+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.139+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.147+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.150+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.158+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.161+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.163+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.166+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.169+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.172+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.176+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.179+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.182+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.185+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.188+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.191+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.194+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.198+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.201+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.204+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.207+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.211+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.214+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.217+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.221+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.225+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.230+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.233+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.241+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.243+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.246+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.248+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.251+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.254+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.256+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.259+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.261+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.264+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.267+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.270+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.273+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.276+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.282+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.285+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.291+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.293+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.297+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.300+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.305+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.309+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.316+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.319+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.324+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.327+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.331+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.335+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.339+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.343+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.347+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.351+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.356+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.359+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.362+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.365+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.368+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.373+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Configurations to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.377+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Admin to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.381+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Configurations to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.385+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.388+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.392+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.396+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on XComs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.399+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.402+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.405+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.408+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.411+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.414+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.416+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.419+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.422+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Providers to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.425+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.428+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.430+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.433+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.436+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on XComs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.439+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.446+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.449+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.452+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.455+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.460+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.469+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.476+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.479+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:29.483+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T16:09:34.918+0000[0m] {[34mproviders_manager.py:[0m247} INFO[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:09:47 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:10:18 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:10:24.455+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:10:48 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /home?status=active HTTP/1.1" 302 321 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive HTTP/1.1" 200 17862 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:03 +0000] "GET /static/appbuilder/webfonts/fa-solid-900.woff2 HTTP/1.1" 304 0 "http://localhost:8080/static/appbuilder/css/fontawesome/solid.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | [[34m2023-07-31T16:11:10.277+0000[0m] {[34mmanager.py:[0m226} INFO[0m - Updated user Airflow Admin[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "POST /login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive HTTP/1.1" 302 267 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /home?status=active HTTP/1.1" 200 31700 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:10 +0000] "GET /static/pin_32.png HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /home?status=active HTTP/1.1" 200 31700 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:14 +0000] "GET /static/pin_32.png HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /home?status=paused HTTP/1.1" 200 419827 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:15 +0000] "GET /static/pin_32.png HTTP/1.1" 304 0 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:16 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:16 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:16 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:16 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /home?status=all HTTP/1.1" 200 419815 "http://localhost:8080/home?status=paused" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "GET /static/pin_32.png HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:17 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /datasets HTTP/1.1" 200 22273 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:18 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /static/dist/datasets.0d0f8ea99c3f499dc8e8.js HTTP/1.1" 200 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /object/datasets_summary?offset=0&limit=25&order_by=-last_dataset_update HTTP/1.1" 200 816 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /object/dataset_dependencies HTTP/1.1" 200 3106 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:19 +0000] "GET /static/pin_32.png HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:11:24.510+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /users/list/ HTTP/1.1" 200 36050 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:39 +0000] "GET /static/appbuilder/webfonts/fa-regular-400.woff2 HTTP/1.1" 200 0 "http://localhost:8080/static/appbuilder/css/fontawesome/regular.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /roles/list/ HTTP/1.1" 200 61968 "http://localhost:8080/users/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:42 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /userstatschartview/chart/ HTTP/1.1" 200 33894 "http://localhost:8080/roles/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:45 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/js/google_charts.js HTTP/1.1" 200 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:46 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:11:48 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /actions/list/ HTTP/1.1" 200 27096 "http://localhost:8080/userstatschartview/chart/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:50 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /home HTTP/1.1" 200 419815 "http://localhost:8080/actions/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:57 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /dagrun/list/ HTTP/1.1" 200 31159 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:11:59 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:01 +0000] "GET /job/list/ HTTP/1.1" 200 33624 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:02 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /log/list/ HTTP/1.1" 200 39093 "http://localhost:8080/job/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:12 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /taskinstance/list/ HTTP/1.1" 200 35684 "http://localhost:8080/log/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:15 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /taskreschedule/list/ HTTP/1.1" 200 27644 "http://localhost:8080/taskinstance/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:17 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /triggerview/list/ HTTP/1.1" 200 25331 "http://localhost:8080/taskreschedule/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:18 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /slamiss/list/ HTTP/1.1" 200 29561 "http://localhost:8080/triggerview/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:20 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /dag-dependencies HTTP/1.1" 200 7981 "http://localhost:8080/slamiss/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.css HTTP/1.1" 200 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/dagre-d3.min.js HTTP/1.1" 200 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 200 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/d3-shape.min.js HTTP/1.1" 200 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:22 +0000] "GET /static/dist/dagDependencies.29e86fab5692b30df6f2.js HTTP/1.1" 200 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:12:24.571+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:12:48 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /variable/list/ HTTP/1.1" 200 26518 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:50 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /dag-dependencies HTTP/1.1" 200 7979 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/dagre-d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/d3-shape.min.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:12:52 +0000] "GET /static/dist/dagDependencies.29e86fab5692b30df6f2.js HTTP/1.1" 304 0 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:13:18 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:13:24.630+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /configuration HTTP/1.1" 200 21481 "http://localhost:8080/dag-dependencies" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:29 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:30 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /variable/list/ HTTP/1.1" 200 26518 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:35 +0000] "GET /static/appbuilder/webfonts/fa-solid-900.woff2 HTTP/1.1" 304 0 "http://localhost:8080/static/appbuilder/css/fontawesome/solid.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:37 +0000] "GET /connection/list/ HTTP/1.1" 200 30060 "http://localhost:8080/variable/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:38 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /configuration HTTP/1.1" 200 21481 "http://localhost:8080/connection/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:41 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:13:48 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /xcom/list/ HTTP/1.1" 200 28006 "http://localhost:8080/configuration" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:50 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /home HTTP/1.1" 200 419815 "http://localhost:8080/xcom/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:13:52 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-init-1       | 
airflow-airflow-init-1       | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | [[34m2023-07-31T16:14:13.106+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:14:13.106+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:14:13.116+0000[0m] {[34mdb.py:[0m1591} INFO[0m - Creating tables[0m
airflow-airflow-init-1       | Upgrades done
airflow-airflow-init-1       | airflow already exist in the db
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:14:18 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-init-1       | 2.6.3
airflow-airflow-init-1 exited with code 0
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:14:24.682+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:14:26.326+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:14:48 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:15:18 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:15:24.739+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:15:49 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:16:19 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:16:24.797+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:16:49 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:17:19 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:17:24.859+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:17:49 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:18:19 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:18:24.914+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /datasets HTTP/1.1" 200 22273 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:42 +0000] "GET /static/dist/datasets.0d0f8ea99c3f499dc8e8.js HTTP/1.1" 304 0 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:43 +0000] "GET /object/datasets_summary?offset=0&limit=25&order_by=-last_dataset_update HTTP/1.1" 200 816 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:43 +0000] "GET /object/dataset_dependencies HTTP/1.1" 200 3106 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:45 +0000] "GET /api/v1/datasets/s3%3A%2F%2Fconsuming_1_task%2Fdataset_other.txt HTTP/1.1" 200 430 "http://localhost:8080/datasets?uri=s3%253A%252F%252Fconsuming_1_task%252Fdataset_other.txt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:45 +0000] "GET /api/v1/datasets/events?limit=25&order_by=-timestamp&dataset_id=5 HTTP/1.1" 200 49 "http://localhost:8080/datasets?uri=s3%253A%252F%252Fconsuming_1_task%252Fdataset_other.txt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:18:49 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /dagrun/list/ HTTP/1.1" 200 31159 "http://localhost:8080/datasets" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:18:56 +0000] "GET /static/appbuilder/webfonts/fa-solid-900.woff2 HTTP/1.1" 304 0 "http://localhost:8080/static/appbuilder/css/fontawesome/solid.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /home HTTP/1.1" 200 419815 "http://localhost:8080/dagrun/list/" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:00 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /dags/dataset_consumes_1/grid HTTP/1.1" 200 10209 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:11 +0000] "GET /static/dist/grid.fd7d0b19bd6a74faf072.js HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:19:12 +0000] "GET /object/grid_data?dag_id=dataset_consumes_1&num_runs=25 HTTP/1.1" 200 282 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:19:19 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:19:24.973+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:19:26.397+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:19:49 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:20:19 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:20:25.035+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:20:49 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /dags/dataset_consumes_1/graph HTTP/1.1" 200 11475 "http://localhost:8080/dags/dataset_consumes_1/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:50 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/d3-shape.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/dagre-d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:20:51 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.js HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:21:19 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:21:25.096+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:21:50 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:22:20 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:22:25.161+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /dags/dataset_consumes_1/landing-times?days=30&root= HTTP/1.1" 200 44247 "http://localhost:8080/dags/dataset_consumes_1/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:42 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/nv.d3.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/nv.d3.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:43 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /dags/dataset_consumes_1/gantt?root= HTTP/1.1" 200 44559 "http://localhost:8080/dags/dataset_consumes_1/landing-times?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/gantt.9995f2d594526c5d78cc.css HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/gantt.9995f2d594526c5d78cc.js HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:22:44 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-redis-1              | 1:M 31 Jul 2023 16:22:47.682 * 100 changes in 300 seconds. Saving...
airflow-redis-1              | 1:M 31 Jul 2023 16:22:47.683 * Background saving started by pid 521
airflow-redis-1              | 521:C 31 Jul 2023 16:22:47.686 * DB saved on disk
airflow-redis-1              | 521:C 31 Jul 2023 16:22:47.687 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
airflow-redis-1              | 1:M 31 Jul 2023 16:22:47.783 * Background saving terminated with success
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:22:50 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:23:20 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:23:25.220+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /dags/dataset_consumes_1/code?root= HTTP/1.1" 200 61325 "http://localhost:8080/dags/dataset_consumes_1/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:23:29 +0000] "GET /static/dist/dagCode.f0a516f657a0c4d2f6e2.js HTTP/1.1" 200 0 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:23:50 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:24:20 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:24:25.281+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:24:26.464+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:24:50 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:25:20 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:25:25.346+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:25:50 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:26:20 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:26:25.405+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:26:50 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:27:20 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:27:25.464+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:27:51 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:28:21 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:28:25.523+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:28:51 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:29:21 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:29:25.581+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:29:26.521+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:29:51 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:30:21 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:30:25.649+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:30:51 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:31:21 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:31:25.711+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:31:51 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:32:21 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:32:25.768+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:32:51 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:33:21 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:33:25.826+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:33:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:34:22 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:34:25.886+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:34:26.591+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:34:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:35:22 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:35:25.950+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:35:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:36:22 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:36:26.005+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-redis-1              | 1:M 31 Jul 2023 16:36:48.894 * 100 changes in 300 seconds. Saving...
airflow-redis-1              | 1:M 31 Jul 2023 16:36:48.895 * Background saving started by pid 1026
airflow-redis-1              | 1026:C 31 Jul 2023 16:36:48.897 * DB saved on disk
airflow-redis-1              | 1026:C 31 Jul 2023 16:36:48.897 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
airflow-redis-1              | 1:M 31 Jul 2023 16:36:48.996 * Background saving terminated with success
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:36:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:37:22 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:37:26.060+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:37:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:38:22 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:38:26.115+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:38:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:39:22 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:39:26.178+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:39:26.672+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:39:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:40:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:40:26.237+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:40:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:41:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:41:26.297+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:41:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:42:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:42:26.351+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:42:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:43:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:43:26.416+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:43:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:44:24 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:44:26.474+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:44:26.752+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:44:54 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:45:24 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:45:26.527+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:45:54 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:46:24 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:46:26.585+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:46:54 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:47:24 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:47:26.641+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:47:54 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:48:24 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:48:26.697+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:48:55 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:49:25 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:49:26.746+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:49:26.837+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:49:55 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /home HTTP/1.1" 200 419815 "http://localhost:8080/dags/dataset_consumes_1/code?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:21 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:22 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /home HTTP/1.1" 200 419815 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:24 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:25 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:50:25 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /home HTTP/1.1" 200 419815 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:50:26.805+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:26 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:27 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:27 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:27 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:27 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /home HTTP/1.1" 200 419815 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:31 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /home?status=all HTTP/1.1" 200 419815 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:47 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /home?status=all HTTP/1.1" 200 419815 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:50:49 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:50:55 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-redis-1              | 1:M 31 Jul 2023 16:51:05.130 * 100 changes in 300 seconds. Saving...
airflow-redis-1              | 1:M 31 Jul 2023 16:51:05.130 * Background saving started by pid 1537
airflow-redis-1              | 1537:C 31 Jul 2023 16:51:05.134 * DB saved on disk
airflow-redis-1              | 1537:C 31 Jul 2023 16:51:05.134 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
airflow-redis-1              | 1:M 31 Jul 2023 16:51:05.231 * Background saving terminated with success
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /home?status=all HTTP/1.1" 200 419815 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:17 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:18 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:18 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:18 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:51:18 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:51:25 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:51:26.861+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:51:55 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /home?status=all HTTP/1.1" 200 419815 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:05 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:06 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:06 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:06 +0000] "POST /dag_stats HTTP/1.1" 200 8120 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:52:06 +0000] "POST /task_stats HTTP/1.1" 200 26005 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
== startdev 2023-07-31T16:52:30Z Start Airflow local containers
Attaching to airflow-airflow-init-1
airflow-airflow-init-1  | 
airflow-airflow-init-1  | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1  | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1  | [[34m2023-07-31T16:52:46.548+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:52:46.548+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1  | [[34m2023-07-31T16:52:46.557+0000[0m] {[34mdb.py:[0m1591} INFO[0m - Creating tables[0m
airflow-airflow-init-1  | Upgrades done
airflow-airflow-init-1  | airflow already exist in the db
airflow-airflow-init-1  | 2.6.3
airflow-airflow-init-1 exited with code 0
Attaching to airflow-airflow-init-1, airflow-airflow-scheduler-1, airflow-airflow-triggerer-1, airflow-airflow-webserver-1, airflow-airflow-worker-1, airflow-postgres-1, airflow-redis-1
airflow-airflow-init-1       | 
airflow-airflow-init-1       | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | [[34m2023-07-31T16:52:58.786+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:52:58.787+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1       | [[34m2023-07-31T16:52:58.794+0000[0m] {[34mdb.py:[0m1591} INFO[0m - Creating tables[0m
airflow-airflow-init-1       | Upgrades done
airflow-airflow-init-1       | airflow already exist in the db
airflow-airflow-init-1       | 2.6.3
airflow-airflow-init-1 exited with code 0
airflow-airflow-triggerer-1  | 
airflow-airflow-worker-1     | 
airflow-airflow-webserver-1  | 
airflow-airflow-scheduler-1  | 
airflow-airflow-worker-1     | BACKEND=redis
airflow-airflow-worker-1     | DB_HOST=redis
airflow-airflow-worker-1     | DB_PORT=6379
airflow-airflow-scheduler-1  | BACKEND=redis
airflow-airflow-scheduler-1  | DB_HOST=redis
airflow-airflow-scheduler-1  | DB_PORT=6379
airflow-airflow-scheduler-1  | 
airflow-airflow-worker-1     | 
airflow-airflow-triggerer-1  |   ____________       _____________
airflow-airflow-triggerer-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-triggerer-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-triggerer-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-triggerer-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:53:08.660+0000[0m] {[34mtriggerer_job_runner.py:[0m173} INFO[0m - Setting up TriggererHandlerWrapper with handler <FileTaskHandler (NOTSET)>[0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:53:08.954+0000[0m] {[34mtriggerer_job_runner.py:[0m229} INFO[0m - Setting up logging queue listener with handlers [<RedirectStdHandler <stdout> (NOTSET)>, <TriggererHandlerWrapper (NOTSET)>][0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:53:08.968+0000[0m] {[34mtriggerer_job_runner.py:[0m325} INFO[0m - Starting the triggerer[0m
airflow-airflow-scheduler-1  |   ____________       _____________
airflow-airflow-scheduler-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-scheduler-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-scheduler-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-scheduler-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:53:11.141+0000[0m] {[34mexecutor_loader.py:[0m114} INFO[0m - Loaded executor: CeleryExecutor[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:53:11.180+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:53:11.180+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:53:11.185+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:53:11.188+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:53:11.192+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
airflow-airflow-worker-1     |  
airflow-airflow-worker-1     |  -------------- celery@1f69c81681e2 v5.2.7 (dawn-chorus)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     | -- ******* ---- Linux-5.19.0-50-generic-x86_64-with-debian-11.7 2023-07-31 16:53:11
airflow-airflow-worker-1     | - *** --- * --- 
airflow-airflow-worker-1     | - ** ---------- [config]
airflow-airflow-worker-1     | - ** ---------- .> app:         airflow.executors.celery_executor:0x7f0ecad3c9d0
airflow-airflow-worker-1     | - ** ---------- .> transport:   redis://redis:6379/0
airflow-airflow-worker-1     | - ** ---------- .> results:     postgresql://airflow:**@postgres/airflow
airflow-airflow-worker-1     | - *** --- * --- .> concurrency: 16 (prefork)
airflow-airflow-worker-1     | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     |  -------------- [queues]
airflow-airflow-worker-1     |                 .> default          exchange=default(direct) key=default
airflow-airflow-worker-1     |                 
airflow-airflow-worker-1     | 
airflow-airflow-worker-1     | [tasks]
airflow-airflow-worker-1     |   . airflow.executors.celery_executor.execute_command
airflow-airflow-worker-1     | 
airflow-airflow-webserver-1  | [[34m2023-07-31T16:53:15.260+0000[0m] {[34mproviders_manager.py:[0m247} INFO[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:53:35 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:04 +0000] "GET /home?status=all HTTP/1.1" 200 427340 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:04 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:04 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:04 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "POST /dag_stats HTTP/1.1" 200 8276 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:05 +0000] "POST /task_stats HTTP/1.1" 200 26526 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:54:05 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:54:09.038+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /dags/my_data_pipeline/grid HTTP/1.1" 200 10180 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/grid.fd7d0b19bd6a74faf072.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:25 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:26 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:26 +0000] "GET /object/grid_data?dag_id=my_data_pipeline&num_runs=25 HTTP/1.1" 200 665 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:54:35 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /dags/my_data_pipeline/graph HTTP/1.1" 200 11495 "http://localhost:8080/dags/my_data_pipeline/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/dagre-d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/d3-shape.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.js HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:38 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:49 +0000] "POST /trigger HTTP/1.1" 302 285 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:49 +0000] "GET /dags/my_data_pipeline/graph HTTP/1.1" 200 11803 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/dagre-d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/d3-shape.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.668+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-02T00:00:00+00:00, run_after=2023-04-03T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:50 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.758+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data manual__2023-07-31T16:54:49.757766+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.758+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.758+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.758+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data manual__2023-07-31T16:54:49.757766+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.763+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.763+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.764+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:50.764+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'manual__2023-07-31T16:54:49.757766+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.068+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.069+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.083+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data manual__2023-07-31T16:54:49.757766+00:00 [queued]> to 2a3735e3-01be-4710-af8d-452da15ad5c1[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.083+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-01T00:00:00+00:00 [queued]> to 84c7c03a-b29d-4e6a-bc9d-a79b396f0221[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.117+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-03T00:00:00+00:00, run_after=2023-04-04T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.191+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.192+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.192+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.196+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.196+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.274+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.289+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-02T00:00:00+00:00 [queued]> to 8424a725-31fa-4595-82c4-d7e62abf4097[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.324+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-04T00:00:00+00:00, run_after=2023-04-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.420+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.420+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.420+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.423+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.423+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.464+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.473+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-03T00:00:00+00:00 [queued]> to 4da26068-c99d-47a9-a8b3-03b2ee1f4223[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.509+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-05T00:00:00+00:00, run_after=2023-04-06T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.597+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.598+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.598+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.612+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.613+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.674+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.679+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-04T00:00:00+00:00 [queued]> to 6e13c514-91e7-4ce1-aa4c-a0e1acfad75f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.712+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-06T00:00:00+00:00, run_after=2023-04-07T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.839+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.840+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.840+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.843+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.844+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.896+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.903+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-05T00:00:00+00:00 [queued]> to 147a65cd-0878-46a1-a850-5d379b9580a4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:51.938+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-07T00:00:00+00:00, run_after=2023-04-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.054+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.054+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.055+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.057+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.058+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.105+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.113+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-06T00:00:00+00:00 [queued]> to 7cf009b9-9ae6-4747-8a27-f81e93a84e71[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.149+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-08T00:00:00+00:00, run_after=2023-04-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.309+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.309+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.310+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.313+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.313+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.359+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.364+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-07T00:00:00+00:00 [queued]> to 2790107c-8e8b-47d4-8549-a2013c6f96e0[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.393+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-09T00:00:00+00:00, run_after=2023-04-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.538+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.539+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.539+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.546+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.546+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.644+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.650+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-08T00:00:00+00:00 [queued]> to 72089663-cb17-4b90-941d-e661c97f6921[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.693+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-10T00:00:00+00:00, run_after=2023-04-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.847+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.847+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.847+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.850+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.850+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.907+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.913+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-09T00:00:00+00:00 [queued]> to c74a398f-a944-41e9-8b14-a3ce2b193cfc[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:52.944+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-11T00:00:00+00:00, run_after=2023-04-12T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.144+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.144+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.145+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.148+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.148+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.193+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.200+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-10T00:00:00+00:00 [queued]> to e55ae74f-9e72-43eb-a6ce-7c321fdd06cf[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.232+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-12T00:00:00+00:00, run_after=2023-04-13T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.448+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.448+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.448+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.451+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.451+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.611+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.620+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-11T00:00:00+00:00 [queued]> to 61a7085e-a6d3-4ac0-a713-cd5fca8628c6[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.659+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-13T00:00:00+00:00, run_after=2023-04-14T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:53 +0000] "GET /object/task_instances?dag_id=my_data_pipeline&execution_date=2023-07-31T16%3A54%3A49.757766%2B00%3A00 HTTP/1.1" 200 2067 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.873+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.873+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.874+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.877+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:53.877+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.050+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.056+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-12T00:00:00+00:00 [queued]> to dadb558a-3d5b-47fb-9a48-02ba006a191f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.097+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-14T00:00:00+00:00, run_after=2023-04-15T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.308+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-13T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.308+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.308+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-13T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.311+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.312+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.376+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.383+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-13T00:00:00+00:00 [queued]> to 48e3d69d-6558-4f52-b84c-3f178be2d8e3[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.418+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-15T00:00:00+00:00, run_after=2023-04-16T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /dags/my_data_pipeline/grid?root= HTTP/1.1" 200 10204 "http://localhost:8080/dags/my_data_pipeline/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.643+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-14T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.643+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.643+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-14T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.646+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.646+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.777+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.785+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-14T00:00:00+00:00 [queued]> to 38dedd23-f64f-4599-bdeb-f9614e6abd88[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:54.837+0000[0m] {[34mscheduler_job_runner.py:[0m1298} INFO[0m - DAG my_data_pipeline is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:54 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:55 +0000] "GET /static/dist/grid.fd7d0b19bd6a74faf072.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:55.457+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:55.457+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:55.458+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:55.465+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:55.465+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:55.649+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:55.661+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-15T00:00:00+00:00 [queued]> to f892b1d5-3149-4fb9-b5a9-66b93ba5f102[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.036+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-05T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.037+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.037+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.037+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.037+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-05T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.041+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.041+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.042+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.042+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.042+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.042+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.436+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.436+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.436+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.436+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.436+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.437+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.437+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.437+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.453+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=manual__2023-07-31T16:54:49.757766+00:00, map_index=-1, run_start_date=2023-07-31 16:54:54.725679+00:00, run_end_date=2023-07-31 16:54:55.733661+00:00, run_duration=1.007982, state=success, executor_state=success, try_number=1, max_tries=1, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:50.759702+00:00, queued_by_job_id=4, pid=109[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.455+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:54.679349+00:00, run_end_date=2023-07-31 16:54:55.808097+00:00, run_duration=1.128748, state=success, executor_state=success, try_number=1, max_tries=1, job_id=6, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:50.759702+00:00, queued_by_job_id=4, pid=108[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.455+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-04T00:00:00+00:00 [queued]> to 3f404085-05c7-4e62-8744-97ea766bb3ff[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.455+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:54.280299+00:00, run_end_date=2023-07-31 16:54:55.457243+00:00, run_duration=1.176944, state=success, executor_state=success, try_number=1, max_tries=1, job_id=5, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:51.599081+00:00, queued_by_job_id=4, pid=103[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.455+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-05T00:00:00+00:00 [queued]> to 3561b916-14d4-4883-8aa0-37a924b78468[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.456+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:54.686084+00:00, run_end_date=2023-07-31 16:54:55.639079+00:00, run_duration=0.952995, state=success, executor_state=success, try_number=1, max_tries=1, job_id=11, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:51.841531+00:00, queued_by_job_id=4, pid=107[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.457+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-06T00:00:00+00:00 [queued]> to df223c72-8b07-4271-a894-26a58b85d133[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.458+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:54.448717+00:00, run_end_date=2023-07-31 16:54:55.315482+00:00, run_duration=0.866765, state=success, executor_state=success, try_number=1, max_tries=1, job_id=8, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:52.055873+00:00, queued_by_job_id=4, pid=105[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:56 +0000] "GET /object/grid_data?dag_id=my_data_pipeline&num_runs=25 HTTP/1.1" 200 16086 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:56 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.821+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-08T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data manual__2023-07-31T16:54:49.757766+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.821+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.821+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.821+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.821+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.821+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-08T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data manual__2023-07-31T16:54:49.757766+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.824+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.825+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.825+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.825+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.825+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.825+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.825+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:56.826+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'manual__2023-07-31T16:54:49.757766+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.315+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.315+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.315+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.315+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.315+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.316+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.316+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.316+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.316+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.337+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data manual__2023-07-31T16:54:49.757766+00:00 [queued]> to 02732c5f-cb04-4970-be40-a8923f5558af[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.338+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-01T00:00:00+00:00 [queued]> to 01aeb176-ff43-4634-9dc7-3d1b10cd2a30[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.338+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:56.022500+00:00, run_end_date=2023-07-31 16:54:56.605750+00:00, run_duration=0.58325, state=success, executor_state=success, try_number=1, max_tries=1, job_id=9, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:51.193142+00:00, queued_by_job_id=4, pid=117[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.338+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:55.295981+00:00, run_end_date=2023-07-31 16:54:56.283190+00:00, run_duration=0.987209, state=success, executor_state=success, try_number=1, max_tries=1, job_id=10, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:51.421417+00:00, queued_by_job_id=4, pid=114[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.338+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-03T00:00:00+00:00 [queued]> to bd27840d-4770-4ee9-88f7-cb3b3764199b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.338+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:55.215213+00:00, run_end_date=2023-07-31 16:54:56.246853+00:00, run_duration=1.03164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=12, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:52.540280+00:00, queued_by_job_id=4, pid=113[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.339+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-08T00:00:00+00:00 [queued]> to 1d3b0de3-ad08-472b-b6f0-a098368aef2d[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.339+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:56.443550+00:00, run_end_date=2023-07-31 16:54:56.972827+00:00, run_duration=0.529277, state=success, executor_state=success, try_number=1, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:53.145841+00:00, queued_by_job_id=4, pid=122[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.339+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:56.218807+00:00, run_end_date=2023-07-31 16:54:56.808397+00:00, run_duration=0.58959, state=success, executor_state=success, try_number=1, max_tries=1, job_id=13, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:53.449392+00:00, queued_by_job_id=4, pid=121[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.590+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-07T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.591+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.591+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.591+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.591+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.591+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-07T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.594+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.595+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.595+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.595+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.595+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.595+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.595+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.595+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.854+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.854+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.854+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.854+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.854+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.871+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-02T00:00:00+00:00 [queued]> to ca741c1c-c289-4d37-8596-8557e4c6f7ef[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.871+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-07T00:00:00+00:00 [queued]> to 4216c28e-9748-42f5-b130-aef3c069762d[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.871+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:56.472436+00:00, run_end_date=2023-07-31 16:54:57.312539+00:00, run_duration=0.840103, state=success, executor_state=success, try_number=1, max_tries=1, job_id=15, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:52.311078+00:00, queued_by_job_id=4, pid=124[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.872+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-10T00:00:00+00:00 [queued]> to 6809f65f-4ecf-41ee-ab7b-9262b2e36f00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:57.872+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-11T00:00:00+00:00 [queued]> to 6f4445bf-558f-4d9b-9b77-d7d72dd5eaf7[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.076+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.076+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.076+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.080+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.080+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.192+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.192+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.223+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-09T00:00:00+00:00 [queued]> to 559a9bd8-c21c-45ae-80f0-d50e67cccc4a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:58.223+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:57.028565+00:00, run_end_date=2023-07-31 16:54:57.758267+00:00, run_duration=0.729702, state=success, executor_state=success, try_number=1, max_tries=1, job_id=16, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:52.848370+00:00, queued_by_job_id=4, pid=132[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.807+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 8 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-05T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-06T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data manual__2023-07-31T16:54:49.757766+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.807+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.807+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.808+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.808+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.808+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.808+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.808+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.808+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.808+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-05T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-06T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data manual__2023-07-31T16:54:49.757766+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.817+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.817+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.817+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.817+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.818+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.819+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:54:59.819+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'manual__2023-07-31T16:54:49.757766+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:54:59 +0000] "GET /object/grid_data?dag_id=my_data_pipeline&num_runs=25 HTTP/1.1" 200 16888 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.631+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.632+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.656+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=manual__2023-07-31T16:54:49.757766+00:00, map_index=-1, run_start_date=2023-07-31 16:54:59.103311+00:00, run_end_date=2023-07-31 16:54:59.565288+00:00, run_duration=0.461977, state=success, executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:56.822524+00:00, queued_by_job_id=4, pid=154[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.656+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data manual__2023-07-31T16:54:49.757766+00:00 [queued]> to 028e2403-4fe7-4efa-a7fe-ef6222d30033[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.656+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:59.524776+00:00, run_end_date=2023-07-31 16:55:00.000770+00:00, run_duration=0.475994, state=success, executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:56.822524+00:00, queued_by_job_id=4, pid=158[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.656+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-04T00:00:00+00:00 [queued]> to d5c920ff-8bbf-48b5-8385-d4debc63feb2[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.656+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:58.815956+00:00, run_end_date=2023-07-31 16:54:59.404363+00:00, run_duration=0.588407, state=success, executor_state=success, try_number=1, max_tries=1, job_id=21, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:56.038890+00:00, queued_by_job_id=4, pid=148[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.656+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-05T00:00:00+00:00 [queued]> to 44ed1bab-83de-442b-9f11-8e64ba488c42[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:58.869179+00:00, run_end_date=2023-07-31 16:54:59.392471+00:00, run_duration=0.523292, state=success, executor_state=success, try_number=1, max_tries=1, job_id=22, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:56.038890+00:00, queued_by_job_id=4, pid=149[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-06T00:00:00+00:00 [queued]> to f45797d7-de8a-46b5-ae28-4b8caae4bb95[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:58.957311+00:00, run_end_date=2023-07-31 16:54:59.563294+00:00, run_duration=0.605983, state=success, executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:56.038890+00:00, queued_by_job_id=4, pid=152[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:59.649022+00:00, run_end_date=2023-07-31 16:55:00.176937+00:00, run_duration=0.527915, state=success, executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:56.822524+00:00, queued_by_job_id=4, pid=159[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:58.664862+00:00, run_end_date=2023-07-31 16:54:59.239427+00:00, run_duration=0.574565, state=success, executor_state=success, try_number=1, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:53.874918+00:00, queued_by_job_id=4, pid=147[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-12T00:00:00+00:00 [queued]> to ec861e12-ecde-4596-baf8-2abf3cdfd597[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-13T00:00:00+00:00 [queued]> to f0eec04a-8f94-4a5e-89a2-48fb2be2e486[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.657+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:57.743980+00:00, run_end_date=2023-07-31 16:54:58.593405+00:00, run_duration=0.849425, state=success, executor_state=success, try_number=1, max_tries=1, job_id=17, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:54.309327+00:00, queued_by_job_id=4, pid=139[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.658+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:57.884608+00:00, run_end_date=2023-07-31 16:54:58.622998+00:00, run_duration=0.73839, state=success, executor_state=success, try_number=1, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:54.644361+00:00, queued_by_job_id=4, pid=140[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.658+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-14T00:00:00+00:00 [queued]> to 676dd24c-ce54-4343-b8ae-d749c033cf69[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.658+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:54:58.535931+00:00, run_end_date=2023-07-31 16:54:59.168916+00:00, run_duration=0.632985, state=success, executor_state=success, try_number=1, max_tries=1, job_id=19, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:54:55.459606+00:00, queued_by_job_id=4, pid=146[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.658+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-15T00:00:00+00:00 [queued]> to 173f8efa-9867-4dbe-a72f-0c675612121a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.976+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.977+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.977+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.977+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.979+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.980+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.980+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:00.980+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.215+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.215+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.215+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.216+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.216+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.232+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:00.208854+00:00, run_end_date=2023-07-31 16:55:00.892538+00:00, run_duration=0.683684, state=success, executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:57.592285+00:00, queued_by_job_id=4, pid=168[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.233+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-03T00:00:00+00:00 [queued]> to eda5d9b9-28d9-4309-9278-810d9525da7e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.233+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:00.311141+00:00, run_end_date=2023-07-31 16:55:00.877552+00:00, run_duration=0.566411, state=success, executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:57.592285+00:00, queued_by_job_id=4, pid=170[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.234+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-08T00:00:00+00:00 [queued]> to 0ba64935-1e87-4b2c-bf9e-e7026d805811[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.234+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:00.424968+00:00, run_end_date=2023-07-31 16:55:00.945132+00:00, run_duration=0.520164, state=success, executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:58.077023+00:00, queued_by_job_id=4, pid=171[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.486+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-07T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-09T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.486+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.487+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.487+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.487+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.487+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-07T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-09T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.490+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.490+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.490+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.491+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.491+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.491+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.491+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.491+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.880+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.881+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.881+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.881+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.881+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.881+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.881+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.900+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:00.902721+00:00, run_end_date=2023-07-31 16:55:01.475510+00:00, run_duration=0.572789, state=success, executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:56.822524+00:00, queued_by_job_id=4, pid=173[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.901+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-02T00:00:00+00:00 [queued]> to 7dc25006-64ad-48c1-a2e2-47c0ebffd807[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.901+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-07T00:00:00+00:00 [queued]> to f370dcc4-22e0-4036-be6c-36141322e783[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.901+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-09T00:00:00+00:00 [queued]> to 2d0f9c9c-4c03-41f1-9dfe-7fc57e4eea5a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.901+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:00.761894+00:00, run_end_date=2023-07-31 16:55:01.545624+00:00, run_duration=0.78373, state=success, executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:57.592285+00:00, queued_by_job_id=4, pid=174[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.901+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-11T00:00:00+00:00 [queued]> to 999dbce2-e50e-4e7b-abe5-06e7129c5321[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:01.901+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:00.277745+00:00, run_end_date=2023-07-31 16:55:00.916387+00:00, run_duration=0.638642, state=success, executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:57.592285+00:00, queued_by_job_id=4, pid=169[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.120+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.120+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.120+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.121+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.123+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.124+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.124+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.124+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.298+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.299+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.305+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-01T00:00:00+00:00 [queued]> to e65d0a6d-5d5f-4155-80de-0965146a572f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.306+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-10T00:00:00+00:00 [queued]> to d28d8adc-24c1-49cf-9022-4d50d39c5882[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.950+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-07-31 16:54:49.757766+00:00: manual__2023-07-31T16:54:49.757766+00:00, state:running, queued_at: 2023-07-31 16:54:49.803652+00:00. externally triggered: True> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.951+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-07-31 16:54:49.757766+00:00, run_id=manual__2023-07-31T16:54:49.757766+00:00, run_start_date=2023-07-31 16:54:50.680214+00:00, run_end_date=2023-07-31 16:55:02.951056+00:00, run_duration=12.270842, state=success, external_trigger=True, run_type=manual, data_interval_start=2023-07-30 16:54:49.757766+00:00, data_interval_end=2023-07-31 16:54:49.757766+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:02.957+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-31T16:54:49.757766+00:00, run_after=2023-08-01T16:54:49.757766+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:03 +0000] "GET /object/grid_data?dag_id=my_data_pipeline&num_runs=25 HTTP/1.1" 200 17531 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:03.163+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='manual__2023-07-31T16:54:49.757766+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:03.168+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=manual__2023-07-31T16:54:49.757766+00:00, map_index=-1, run_start_date=2023-07-31 16:55:01.960361+00:00, run_end_date=2023-07-31 16:55:02.701490+00:00, run_duration=0.741129, state=success, executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=188[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.233+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-06 00:00:00+00:00: scheduled__2023-04-06T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:51.932541+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.233+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-06 00:00:00+00:00, run_id=scheduled__2023-04-06T00:00:00+00:00, run_start_date=2023-07-31 16:54:51.949474+00:00, run_end_date=2023-07-31 16:55:04.233717+00:00, run_duration=12.284243, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-06 00:00:00+00:00, data_interval_end=2023-04-07 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.240+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-07T00:00:00+00:00, run_after=2023-04-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.250+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-04 00:00:00+00:00: scheduled__2023-04-04T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:51.503302+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.250+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-04 00:00:00+00:00, run_id=scheduled__2023-04-04T00:00:00+00:00, run_start_date=2023-07-31 16:54:51.519369+00:00, run_end_date=2023-07-31 16:55:04.250580+00:00, run_duration=12.731211, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-04 00:00:00+00:00, data_interval_end=2023-04-05 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.256+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-05T00:00:00+00:00, run_after=2023-04-06T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.271+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-05 00:00:00+00:00: scheduled__2023-04-05T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:51.706492+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.271+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-05 00:00:00+00:00, run_id=scheduled__2023-04-05T00:00:00+00:00, run_start_date=2023-07-31 16:54:51.725609+00:00, run_end_date=2023-07-31 16:55:04.271689+00:00, run_duration=12.54608, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-05 00:00:00+00:00, data_interval_end=2023-04-06 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.277+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-06T00:00:00+00:00, run_after=2023-04-07T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.404+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.404+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.404+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.404+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.404+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.404+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.407+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.407+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.408+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.408+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.408+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.408+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.408+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.408+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.865+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.865+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.865+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.865+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.865+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.866+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.894+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:03.422639+00:00, run_end_date=2023-07-31 16:55:03.899197+00:00, run_duration=0.476558, state=success, executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=203[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.895+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:02.544992+00:00, run_end_date=2023-07-31 16:55:03.149030+00:00, run_duration=0.604038, state=success, executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=193[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.895+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:02.696868+00:00, run_end_date=2023-07-31 16:55:03.592048+00:00, run_duration=0.89518, state=success, executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=195[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.895+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:03.991256+00:00, run_end_date=2023-07-31 16:55:04.506731+00:00, run_duration=0.515475, state=success, executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:00.977908+00:00, queued_by_job_id=4, pid=206[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.895+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:04.133184+00:00, run_end_date=2023-07-31 16:55:04.580524+00:00, run_duration=0.44734, state=success, executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:01.487876+00:00, queued_by_job_id=4, pid=207[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.895+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:04.197708+00:00, run_end_date=2023-07-31 16:55:04.659888+00:00, run_duration=0.46218, state=success, executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:02.121884+00:00, queued_by_job_id=4, pid=208[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.895+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-15T00:00:00+00:00 [queued]> to 57d6a681-73d9-4fc0-8668-7ba7caa0a33b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.896+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:02.307350+00:00, run_end_date=2023-07-31 16:55:03.090191+00:00, run_duration=0.782841, state=success, executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=192[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.896+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-13T00:00:00+00:00 [queued]> to 07a03681-f6dd-46ca-9f4f-08ded6327fcc[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.896+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:02.710398+00:00, run_end_date=2023-07-31 16:55:03.592129+00:00, run_duration=0.881731, state=success, executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=196[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.896+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:03.140189+00:00, run_end_date=2023-07-31 16:55:03.746141+00:00, run_duration=0.605952, state=success, executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=199[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.896+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:03.286701+00:00, run_end_date=2023-07-31 16:55:03.868669+00:00, run_duration=0.581968, state=success, executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:54:59.811161+00:00, queued_by_job_id=4, pid=202[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.896+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-12T00:00:00+00:00 [queued]> to 00f67ba6-55c4-42b8-9373-968b400bd16e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.896+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-14T00:00:00+00:00 [queued]> to 86ee27c6-0239-44d7-a893-0dfde1ca5672[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.926+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-07T00:00:00+00:00, run_after=2023-04-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.959+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-01 00:00:00+00:00: scheduled__2023-04-01T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:50.647883+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.960+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-01 00:00:00+00:00, run_id=scheduled__2023-04-01T00:00:00+00:00, run_start_date=2023-07-31 16:54:50.679970+00:00, run_end_date=2023-07-31 16:55:04.960134+00:00, run_duration=14.280164, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-01 00:00:00+00:00, data_interval_end=2023-04-02 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.965+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-02T00:00:00+00:00, run_after=2023-04-03T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.978+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-03 00:00:00+00:00: scheduled__2023-04-03T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:51.317605+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.978+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-03 00:00:00+00:00, run_id=scheduled__2023-04-03T00:00:00+00:00, run_start_date=2023-07-31 16:54:51.336249+00:00, run_end_date=2023-07-31 16:55:04.978422+00:00, run_duration=13.642173, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-03 00:00:00+00:00, data_interval_end=2023-04-04 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.990+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-04T00:00:00+00:00, run_after=2023-04-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.996+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-02 00:00:00+00:00: scheduled__2023-04-02T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:51.110521+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:04.997+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-02 00:00:00+00:00, run_id=scheduled__2023-04-02T00:00:00+00:00, run_start_date=2023-07-31 16:54:51.126490+00:00, run_end_date=2023-07-31 16:55:04.997158+00:00, run_duration=13.870668, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-02 00:00:00+00:00, data_interval_end=2023-04-03 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.001+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-03T00:00:00+00:00, run_after=2023-04-04T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.008+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-08 00:00:00+00:00: scheduled__2023-04-08T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:52.388144+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.008+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-08 00:00:00+00:00, run_id=scheduled__2023-04-08T00:00:00+00:00, run_start_date=2023-07-31 16:54:52.408283+00:00, run_end_date=2023-07-31 16:55:05.008547+00:00, run_duration=12.600264, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-08 00:00:00+00:00, data_interval_end=2023-04-09 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.013+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-09T00:00:00+00:00, run_after=2023-04-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.043+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-07 00:00:00+00:00: scheduled__2023-04-07T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:52.140407+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.043+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-07 00:00:00+00:00, run_id=scheduled__2023-04-07T00:00:00+00:00, run_start_date=2023-07-31 16:54:52.160399+00:00, run_end_date=2023-07-31 16:55:05.043505+00:00, run_duration=12.883106, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-07 00:00:00+00:00, data_interval_end=2023-04-08 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.049+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-08T00:00:00+00:00, run_after=2023-04-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.107+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:05.118+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:04.377342+00:00, run_end_date=2023-07-31 16:55:04.847169+00:00, run_duration=0.469827, state=success, executor_state=success, try_number=1, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:01.487876+00:00, queued_by_job_id=4, pid=211[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:55:05 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.146+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-09T00:00:00+00:00, run_after=2023-04-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.168+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-10 00:00:00+00:00: scheduled__2023-04-10T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:52.938796+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.169+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-10 00:00:00+00:00, run_id=scheduled__2023-04-10T00:00:00+00:00, run_start_date=2023-07-31 16:54:52.959432+00:00, run_end_date=2023-07-31 16:55:06.169043+00:00, run_duration=13.209611, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-10 00:00:00+00:00, data_interval_end=2023-04-11 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.172+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-11T00:00:00+00:00, run_after=2023-04-12T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.178+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-09 00:00:00+00:00: scheduled__2023-04-09T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:52.686398+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.179+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-09 00:00:00+00:00, run_id=scheduled__2023-04-09T00:00:00+00:00, run_start_date=2023-07-31 16:54:52.706879+00:00, run_end_date=2023-07-31 16:55:06.179212+00:00, run_duration=13.472333, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-09 00:00:00+00:00, data_interval_end=2023-04-10 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.184+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-10T00:00:00+00:00, run_after=2023-04-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.189+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-11 00:00:00+00:00: scheduled__2023-04-11T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:53.226161+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.190+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-11 00:00:00+00:00, run_id=scheduled__2023-04-11T00:00:00+00:00, run_start_date=2023-07-31 16:54:53.244521+00:00, run_end_date=2023-07-31 16:55:06.190320+00:00, run_duration=12.945799, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-11 00:00:00+00:00, data_interval_end=2023-04-12 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.194+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-12T00:00:00+00:00, run_after=2023-04-13T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.199+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-13 00:00:00+00:00: scheduled__2023-04-13T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:54.086389+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.199+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-13 00:00:00+00:00, run_id=scheduled__2023-04-13T00:00:00+00:00, run_start_date=2023-07-31 16:54:54.108172+00:00, run_end_date=2023-07-31 16:55:06.199330+00:00, run_duration=12.091158, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-13 00:00:00+00:00, data_interval_end=2023-04-14 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.202+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-14T00:00:00+00:00, run_after=2023-04-15T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.206+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-12 00:00:00+00:00: scheduled__2023-04-12T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:53.653440+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.207+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-12 00:00:00+00:00, run_id=scheduled__2023-04-12T00:00:00+00:00, run_start_date=2023-07-31 16:54:53.674977+00:00, run_end_date=2023-07-31 16:55:06.207148+00:00, run_duration=12.532171, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-12 00:00:00+00:00, data_interval_end=2023-04-13 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.210+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-13T00:00:00+00:00, run_after=2023-04-14T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.214+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-14 00:00:00+00:00: scheduled__2023-04-14T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:54.410267+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.215+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-14 00:00:00+00:00, run_id=scheduled__2023-04-14T00:00:00+00:00, run_start_date=2023-07-31 16:54:54.433828+00:00, run_end_date=2023-07-31 16:55:06.215029+00:00, run_duration=11.781201, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-14 00:00:00+00:00, data_interval_end=2023-04-15 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.218+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-15T00:00:00+00:00, run_after=2023-04-16T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.243+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.243+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.243+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.243+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.243+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.243+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.244+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.244+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.250+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:04.848804+00:00, run_end_date=2023-07-31 16:55:05.263148+00:00, run_duration=0.414344, state=success, executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:02.121884+00:00, queued_by_job_id=4, pid=217[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.251+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:04.276213+00:00, run_end_date=2023-07-31 16:55:04.872006+00:00, run_duration=0.595793, state=success, executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:01.487876+00:00, queued_by_job_id=4, pid=209[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.251+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:04.361388+00:00, run_end_date=2023-07-31 16:55:04.932224+00:00, run_duration=0.570836, state=success, executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:00.977908+00:00, queued_by_job_id=4, pid=210[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.251+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:04.468396+00:00, run_end_date=2023-07-31 16:55:05.072863+00:00, run_duration=0.604467, state=success, executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:01.487876+00:00, queued_by_job_id=4, pid=216[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.251+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:05.799623+00:00, run_end_date=2023-07-31 16:55:06.054024+00:00, run_duration=0.254401, state=success, executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:04.405405+00:00, queued_by_job_id=4, pid=222[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.251+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:05.830372+00:00, run_end_date=2023-07-31 16:55:06.050503+00:00, run_duration=0.220131, state=success, executor_state=success, try_number=1, max_tries=1, job_id=50, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:04.405405+00:00, queued_by_job_id=4, pid=223[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.251+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:05.852568+00:00, run_end_date=2023-07-31 16:55:06.068313+00:00, run_duration=0.215745, state=success, executor_state=success, try_number=1, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:04.405405+00:00, queued_by_job_id=4, pid=224[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:06.252+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:05.872645+00:00, run_end_date=2023-07-31 16:55:06.088350+00:00, run_duration=0.215705, state=success, executor_state=success, try_number=1, max_tries=1, job_id=52, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:04.405405+00:00, queued_by_job_id=4, pid=225[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:06 +0000] "GET /object/grid_data?dag_id=my_data_pipeline&num_runs=25 HTTP/1.1" 200 19032 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:07.277+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-16T00:00:00+00:00, run_after=2023-04-17T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:07.311+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-15 00:00:00+00:00: scheduled__2023-04-15T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:54:54.820899+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:07.312+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-15 00:00:00+00:00, run_id=scheduled__2023-04-15T00:00:00+00:00, run_start_date=2023-07-31 16:54:54.886614+00:00, run_end_date=2023-07-31 16:55:07.312331+00:00, run_duration=12.425717, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-15 00:00:00+00:00, data_interval_end=2023-04-16 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:07.317+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-16T00:00:00+00:00, run_after=2023-04-17T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.211+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-17T00:00:00+00:00, run_after=2023-04-18T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.273+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-16T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.273+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.274+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-16T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.277+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.277+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.336+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.345+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-16T00:00:00+00:00 [queued]> to 7094782d-1d9f-422f-92a2-fa4759b52213[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.386+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-18T00:00:00+00:00, run_after=2023-04-19T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.459+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.460+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.460+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.464+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.465+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.513+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.522+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-17T00:00:00+00:00 [queued]> to f8cb36cf-048e-479f-8f43-e281e6000cce[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.561+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-19T00:00:00+00:00, run_after=2023-04-20T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.650+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.651+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.651+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.654+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.655+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.718+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.727+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-18T00:00:00+00:00 [queued]> to b7277d49-f964-465d-bb64-5b9549e01ce0[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.765+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-20T00:00:00+00:00, run_after=2023-04-21T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.879+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.879+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.879+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.883+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.883+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.937+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.943+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-19T00:00:00+00:00 [queued]> to 2af12df8-89b1-4f7d-be59-74fede8e2f44[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:08.973+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-21T00:00:00+00:00, run_after=2023-04-22T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.072+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.073+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.073+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.076+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.076+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:55:09.091+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.113+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.119+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-20T00:00:00+00:00 [queued]> to 8dab4a2e-c77f-44d0-87ef-2145c3f2552e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.158+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-22T00:00:00+00:00, run_after=2023-04-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.282+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.282+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.282+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.285+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.286+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.336+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.351+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-21T00:00:00+00:00 [queued]> to 0da54949-e376-41ef-b9a2-0ac9ab66d619[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.385+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-23T00:00:00+00:00, run_after=2023-04-24T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:09 +0000] "GET /object/grid_data?dag_id=my_data_pipeline&num_runs=25 HTTP/1.1" 200 25517 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.538+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.538+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.538+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.544+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.544+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.612+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.620+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-22T00:00:00+00:00 [queued]> to 80cdc26b-1904-4bbb-b7ba-dabddb404c2d[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.664+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-24T00:00:00+00:00, run_after=2023-04-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.878+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.879+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.879+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.882+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.883+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.950+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.956+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-23T00:00:00+00:00 [queued]> to eb162c12-5940-4af0-8e2a-c8bc4f5df21c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:09.988+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-25T00:00:00+00:00, run_after=2023-04-26T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.154+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.155+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.155+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.158+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.159+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.239+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.245+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-24T00:00:00+00:00 [queued]> to 6cd80e0f-28ed-4f5f-9b0b-b935e57c1a22[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.278+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-26T00:00:00+00:00, run_after=2023-04-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.550+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.551+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.551+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.554+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.554+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.699+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.717+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-25T00:00:00+00:00 [queued]> to a6a7ae98-683e-4aae-b934-2b2accb069a8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:10.775+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-27T00:00:00+00:00, run_after=2023-04-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.009+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.009+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.009+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.010+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.010+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.016+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.017+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.017+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.017+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.018+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.018+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.451+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.479+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:09.921689+00:00, run_end_date=2023-07-31 16:55:10.527518+00:00, run_duration=0.605829, state=success, executor_state=success, try_number=1, max_tries=1, job_id=53, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:08.275063+00:00, queued_by_job_id=4, pid=239[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.479+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-16T00:00:00+00:00 [queued]> to 11f95e3e-354b-4cd5-a506-fc374665d66e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.479+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-17T00:00:00+00:00 [queued]> to fcbf939a-b842-4adc-9909-1836a25a0fe2[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.480+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:10.100258+00:00, run_end_date=2023-07-31 16:55:10.546655+00:00, run_duration=0.446397, state=success, executor_state=success, try_number=1, max_tries=1, job_id=54, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:08.462547+00:00, queued_by_job_id=4, pid=240[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.480+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-26T00:00:00+00:00 [queued]> to 2cab18f8-454a-4f63-a487-f8aecc6a5991[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.480+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:10.528492+00:00, run_end_date=2023-07-31 16:55:11.123410+00:00, run_duration=0.594918, state=success, executor_state=success, try_number=1, max_tries=1, job_id=55, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:08.652065+00:00, queued_by_job_id=4, pid=245[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.532+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-28T00:00:00+00:00, run_after=2023-04-29T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.759+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.759+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.759+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.760+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.766+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.766+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.766+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:11.766+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.014+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.014+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /dags/my_data_pipeline/duration?days=30&root= HTTP/1.1" 200 49107 "http://localhost:8080/dags/my_data_pipeline/grid?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.039+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-18T00:00:00+00:00 [queued]> to 3dadd474-cde3-4769-8024-8610d489e33c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.039+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-27T00:00:00+00:00 [queued]> to 6efc9ca5-f5b2-46b9-9727-d8fca555d2d4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.091+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-29T00:00:00+00:00, run_after=2023-04-30T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/durationChart.89b44e023d6e6031dec0.js HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/nv.d3.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /static/dist/nv.d3.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.600+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.600+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.600+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.601+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.601+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.621+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.621+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.622+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.622+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.623+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:12.623+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:12 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.059+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.060+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.060+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.060+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.060+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.087+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:11.063193+00:00, run_end_date=2023-07-31 16:55:11.838299+00:00, run_duration=0.775106, state=success, executor_state=success, try_number=1, max_tries=1, job_id=57, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:08.880632+00:00, queued_by_job_id=4, pid=257[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.087+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-19T00:00:00+00:00 [queued]> to e3bdb604-5791-4666-ba14-9e2b35946f6f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.088+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-20T00:00:00+00:00 [queued]> to 1d6589cc-e53e-485f-b387-00f7adba122e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.088+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:11.133212+00:00, run_end_date=2023-07-31 16:55:11.784903+00:00, run_duration=0.651691, state=success, executor_state=success, try_number=1, max_tries=1, job_id=56, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:09.074264+00:00, queued_by_job_id=4, pid=258[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.088+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-28T00:00:00+00:00 [queued]> to 5835e8d2-5745-4089-b026-095178335fdc[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.178+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-30T00:00:00+00:00, run_after=2023-05-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.477+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.478+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.478+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.478+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.478+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.478+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.486+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.486+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.487+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.487+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.487+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.487+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.488+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:13.488+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.110+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.110+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.110+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.112+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.113+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.113+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.113+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.153+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:11.619937+00:00, run_end_date=2023-07-31 16:55:12.756391+00:00, run_duration=1.136454, state=success, executor_state=success, try_number=1, max_tries=1, job_id=58, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:09.283518+00:00, queued_by_job_id=4, pid=260[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.154+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-21T00:00:00+00:00 [queued]> to 8fb1ee08-5925-4ec9-994c-c07071d2edb5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.154+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:11.917214+00:00, run_end_date=2023-07-31 16:55:12.931778+00:00, run_duration=1.014564, state=success, executor_state=success, try_number=1, max_tries=1, job_id=59, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:09.539665+00:00, queued_by_job_id=4, pid=264[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.154+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-22T00:00:00+00:00 [queued]> to 20cbc706-2842-4487-a2b9-347e65aba81e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.155+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:12.349885+00:00, run_end_date=2023-07-31 16:55:13.173197+00:00, run_duration=0.823312, state=success, executor_state=success, try_number=1, max_tries=1, job_id=60, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:10.156240+00:00, queued_by_job_id=4, pid=267[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.155+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-24T00:00:00+00:00 [queued]> to bc88231d-92a1-4535-8e6e-22c76571fe3c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.155+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-29T00:00:00+00:00 [queued]> to 91616ac8-4f7f-46cc-91c2-24d9a895dd7f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.234+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-01T00:00:00+00:00, run_after=2023-05-02T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.556+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.556+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.557+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.557+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.561+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.561+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.561+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.561+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.803+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.803+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.803+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.818+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-04-30T00:00:00+00:00 [queued]> to 7b44ddb6-a720-4ea1-b5e0-b9121d987419[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.819+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-23T00:00:00+00:00 [queued]> to 914cd905-ad9f-48cc-add9-972fb8974bda[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.819+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:13.284148+00:00, run_end_date=2023-07-31 16:55:14.170036+00:00, run_duration=0.885888, state=success, executor_state=success, try_number=1, max_tries=1, job_id=61, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:09.880361+00:00, queued_by_job_id=4, pid=274[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:14.852+0000[0m] {[34mscheduler_job_runner.py:[0m1298} INFO[0m - DAG my_data_pipeline is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.081+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.081+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.081+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.081+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.085+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.085+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.085+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.086+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.300+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.300+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.300+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.300+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.315+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-25T00:00:00+00:00 [queued]> to 9ecdab7c-3200-4cd0-94bd-e594847d8132[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.315+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:13.634157+00:00, run_end_date=2023-07-31 16:55:14.750526+00:00, run_duration=1.116369, state=success, executor_state=success, try_number=1, max_tries=1, job_id=62, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:10.551967+00:00, queued_by_job_id=4, pid=279[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.315+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:14.180497+00:00, run_end_date=2023-07-31 16:55:15.078567+00:00, run_duration=0.89807, state=success, executor_state=success, try_number=1, max_tries=1, job_id=63, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:11.012040+00:00, queued_by_job_id=4, pid=282[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.316+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-01T00:00:00+00:00 [queued]> to 1dadcf93-d43e-459c-acb1-9f579bfff84f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.553+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-16T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.553+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.553+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-16T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.556+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.556+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.630+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:15.641+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-16T00:00:00+00:00 [queued]> to 79719369-60ea-4be9-a898-28f1fe7563d1[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.132+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.132+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.132+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.135+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.135+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.264+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.265+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.272+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:14.517387+00:00, run_end_date=2023-07-31 16:55:15.352225+00:00, run_duration=0.834838, state=success, executor_state=success, try_number=1, max_tries=1, job_id=64, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:11.012040+00:00, queued_by_job_id=4, pid=286[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.272+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-26T00:00:00+00:00 [queued]> to 494d40b0-63a5-4226-ada4-84141b62f7fc[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.500+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.502+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.507+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.521+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.521+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.698+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.698+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.704+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-17T00:00:00+00:00 [queued]> to 74a39b36-6b5f-4d2d-a77e-8dc7adc2d621[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.705+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:14.868636+00:00, run_end_date=2023-07-31 16:55:15.731178+00:00, run_duration=0.862542, state=success, executor_state=success, try_number=1, max_tries=1, job_id=65, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:11.012040+00:00, queued_by_job_id=4, pid=289[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.980+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.980+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.982+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.985+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:16.985+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:17.054+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:17.057+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:17.064+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:15.477352+00:00, run_end_date=2023-07-31 16:55:16.440466+00:00, run_duration=0.963114, state=success, executor_state=success, try_number=1, max_tries=1, job_id=66, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:11.761228+00:00, queued_by_job_id=4, pid=295[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:17.065+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-27T00:00:00+00:00 [queued]> to bc211ed6-c09c-4550-9d07-3e1bcaa4da1e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.788+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 7 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-18T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-20T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.790+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.790+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.790+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-18T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-20T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.800+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.803+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.803+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.803+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.804+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.804+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.804+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.804+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.804+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.805+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.805+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.805+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.805+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:18.805+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.599+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.600+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.600+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.600+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.600+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.600+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.600+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.601+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.602+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.651+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:17.074295+00:00, run_end_date=2023-07-31 16:55:18.120048+00:00, run_duration=1.045753, state=success, executor_state=success, try_number=1, max_tries=1, job_id=70, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:11.761228+00:00, queued_by_job_id=4, pid=307[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.652+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-18T00:00:00+00:00 [queued]> to 92c40e67-78b5-4bc9-af6a-3a8e0731538c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.652+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-19T00:00:00+00:00 [queued]> to 75ea801e-d64f-481a-b2d4-def14630f478[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.653+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:16.950309+00:00, run_end_date=2023-07-31 16:55:18.039116+00:00, run_duration=1.088807, state=success, executor_state=success, try_number=1, max_tries=1, job_id=69, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:12.603038+00:00, queued_by_job_id=4, pid=306[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.653+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:17.749882+00:00, run_end_date=2023-07-31 16:55:18.485393+00:00, run_duration=0.735511, state=success, executor_state=success, try_number=1, max_tries=1, job_id=73, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:12.603038+00:00, queued_by_job_id=4, pid=312[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.654+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-20T00:00:00+00:00 [queued]> to bae4df65-71b5-4245-9a76-543d424a57f4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.654+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-21T00:00:00+00:00 [queued]> to eb0c64f4-2bbf-4c5c-9b44-2f0edd2472a6[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.654+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:17.662140+00:00, run_end_date=2023-07-31 16:55:18.398966+00:00, run_duration=0.736826, state=success, executor_state=success, try_number=1, max_tries=1, job_id=71, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:13.480935+00:00, queued_by_job_id=4, pid=310[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.654+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:16.522985+00:00, run_end_date=2023-07-31 16:55:17.237146+00:00, run_duration=0.714161, state=success, executor_state=success, try_number=1, max_tries=1, job_id=67, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:13.480935+00:00, queued_by_job_id=4, pid=299[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.654+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-22T00:00:00+00:00 [queued]> to 804a5926-d796-4e7d-8be8-d25712af56df[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.655+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:17.188268+00:00, run_end_date=2023-07-31 16:55:18.036676+00:00, run_duration=0.848408, state=success, executor_state=success, try_number=1, max_tries=1, job_id=72, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:13.480935+00:00, queued_by_job_id=4, pid=308[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.655+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-24T00:00:00+00:00 [queued]> to fdb5c7e9-888f-4d02-b7a5-ae38f044c4fb[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.655+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:18.095485+00:00, run_end_date=2023-07-31 16:55:18.820474+00:00, run_duration=0.724989, state=success, executor_state=success, try_number=1, max_tries=1, job_id=74, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:15.083288+00:00, queued_by_job_id=4, pid=315[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.655+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:17.122541+00:00, run_end_date=2023-07-31 16:55:18.086816+00:00, run_duration=0.964275, state=success, executor_state=success, try_number=1, max_tries=1, job_id=68, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:12.603038+00:00, queued_by_job_id=4, pid=305[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.655+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-28T00:00:00+00:00 [queued]> to af118440-1305-46eb-a07e-b52dd7569948[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:19.656+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:18.522678+00:00, run_end_date=2023-07-31 16:55:19.211102+00:00, run_duration=0.688424, state=success, executor_state=success, try_number=1, max_tries=1, job_id=76, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:13.480935+00:00, queued_by_job_id=4, pid=317[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.049+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-23T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.050+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.050+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.050+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.050+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.050+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-23T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.055+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.055+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.055+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.056+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.056+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.056+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.056+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.057+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.453+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.453+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.453+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.453+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.453+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.482+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:18.697403+00:00, run_end_date=2023-07-31 16:55:19.565793+00:00, run_duration=0.86839, state=success, executor_state=success, try_number=1, max_tries=1, job_id=78, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:15.554344+00:00, queued_by_job_id=4, pid=320[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.483+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-25T00:00:00+00:00 [queued]> to d2fba9aa-9d24-4a18-8699-eee064e68dc0[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.483+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:18.324157+00:00, run_end_date=2023-07-31 16:55:19.345542+00:00, run_duration=1.021385, state=success, executor_state=success, try_number=1, max_tries=1, job_id=75, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:14.558165+00:00, queued_by_job_id=4, pid=319[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.483+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-23T00:00:00+00:00 [queued]> to faa8864a-a841-4501-b220-36dc78a1f88b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.483+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-29T00:00:00+00:00 [queued]> to 350894ad-e21b-4e7e-805a-75b89ac42933[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.483+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-04-30T00:00:00+00:00 [queued]> to c48fd84d-0f5a-4859-89e6-45a2d2381d75[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.484+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-04-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:18.622079+00:00, run_end_date=2023-07-31 16:55:19.307384+00:00, run_duration=0.685305, state=success, executor_state=success, try_number=1, max_tries=1, job_id=77, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:14.558165+00:00, queued_by_job_id=4, pid=318[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.484+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:19.177883+00:00, run_end_date=2023-07-31 16:55:19.903946+00:00, run_duration=0.726063, state=success, executor_state=success, try_number=1, max_tries=1, job_id=79, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:15.083288+00:00, queued_by_job_id=4, pid=328[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.484+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:19.482462+00:00, run_end_date=2023-07-31 16:55:20.080806+00:00, run_duration=0.598344, state=success, executor_state=success, try_number=1, max_tries=1, job_id=80, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:16.983164+00:00, queued_by_job_id=4, pid=329[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.565+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-16 00:00:00+00:00: scheduled__2023-04-16T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:08.203833+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.565+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-16 00:00:00+00:00, run_id=scheduled__2023-04-16T00:00:00+00:00, run_start_date=2023-07-31 16:55:08.234995+00:00, run_end_date=2023-07-31 16:55:20.565728+00:00, run_duration=12.330733, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-16 00:00:00+00:00, data_interval_end=2023-04-17 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.571+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-17T00:00:00+00:00, run_after=2023-04-18T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.705+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.705+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.705+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.706+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.706+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.710+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.710+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.710+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.711+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.711+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:20.711+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.078+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.078+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.078+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.078+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.079+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.098+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:19.879211+00:00, run_end_date=2023-07-31 16:55:20.432787+00:00, run_duration=0.553576, state=success, executor_state=success, try_number=1, max_tries=1, job_id=82, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:16.508701+00:00, queued_by_job_id=4, pid=330[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.099+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-26T00:00:00+00:00 [queued]> to b66d214e-277f-4168-a735-5e60c0a671bc[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.099+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:19.908887+00:00, run_end_date=2023-07-31 16:55:20.502266+00:00, run_duration=0.593379, state=success, executor_state=success, try_number=1, max_tries=1, job_id=81, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:16.133441+00:00, queued_by_job_id=4, pid=331[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.099+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-27T00:00:00+00:00 [queued]> to e551223b-e406-425e-ad04-480a95197d2c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.099+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-01T00:00:00+00:00 [queued]> to 0067af3c-644d-4011-9dd6-ef0be6e20335[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.128+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-18T00:00:00+00:00, run_after=2023-04-19T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.212+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-17 00:00:00+00:00: scheduled__2023-04-17T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:08.379970+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.213+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-17 00:00:00+00:00, run_id=scheduled__2023-04-17T00:00:00+00:00, run_start_date=2023-07-31 16:55:08.399782+00:00, run_end_date=2023-07-31 16:55:21.213130+00:00, run_duration=12.813348, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-17 00:00:00+00:00, data_interval_end=2023-04-18 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:21.223+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-18T00:00:00+00:00, run_after=2023-04-19T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.473+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-19T00:00:00+00:00, run_after=2023-04-20T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.503+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-19 00:00:00+00:00: scheduled__2023-04-19T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:08.755093+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.504+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-19 00:00:00+00:00, run_id=scheduled__2023-04-19T00:00:00+00:00, run_start_date=2023-07-31 16:55:08.778930+00:00, run_end_date=2023-07-31 16:55:22.504091+00:00, run_duration=13.725161, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-19 00:00:00+00:00, data_interval_end=2023-04-20 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.508+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-20T00:00:00+00:00, run_after=2023-04-21T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.519+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-22 00:00:00+00:00: scheduled__2023-04-22T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:09.378917+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.520+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-22 00:00:00+00:00, run_id=scheduled__2023-04-22T00:00:00+00:00, run_start_date=2023-07-31 16:55:09.398283+00:00, run_end_date=2023-07-31 16:55:22.520240+00:00, run_duration=13.121957, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-22 00:00:00+00:00, data_interval_end=2023-04-23 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.526+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-23T00:00:00+00:00, run_after=2023-04-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.544+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-21 00:00:00+00:00: scheduled__2023-04-21T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:09.147562+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.545+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-21 00:00:00+00:00, run_id=scheduled__2023-04-21T00:00:00+00:00, run_start_date=2023-07-31 16:55:09.168882+00:00, run_end_date=2023-07-31 16:55:22.545302+00:00, run_duration=13.37642, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-21 00:00:00+00:00, data_interval_end=2023-04-22 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.551+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-22T00:00:00+00:00, run_after=2023-04-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.557+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-24 00:00:00+00:00: scheduled__2023-04-24T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:09.982072+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.558+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-24 00:00:00+00:00, run_id=scheduled__2023-04-24T00:00:00+00:00, run_start_date=2023-07-31 16:55:09.999895+00:00, run_end_date=2023-07-31 16:55:22.557976+00:00, run_duration=12.558081, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-24 00:00:00+00:00, data_interval_end=2023-04-25 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.562+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-25T00:00:00+00:00, run_after=2023-04-26T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.568+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-20 00:00:00+00:00: scheduled__2023-04-20T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:08.968108+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.569+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-20 00:00:00+00:00, run_id=scheduled__2023-04-20T00:00:00+00:00, run_start_date=2023-07-31 16:55:08.985355+00:00, run_end_date=2023-07-31 16:55:22.568969+00:00, run_duration=13.583614, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-20 00:00:00+00:00, data_interval_end=2023-04-21 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.573+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-21T00:00:00+00:00, run_after=2023-04-22T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.785+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.785+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.786+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.793+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:21.698924+00:00, run_end_date=2023-07-31 16:55:22.175629+00:00, run_duration=0.476705, state=success, executor_state=success, try_number=1, max_tries=1, job_id=84, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:18.792950+00:00, queued_by_job_id=4, pid=350[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.793+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:21.657462+00:00, run_end_date=2023-07-31 16:55:22.191381+00:00, run_duration=0.533919, state=success, executor_state=success, try_number=1, max_tries=1, job_id=83, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:18.792950+00:00, queued_by_job_id=4, pid=351[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:22.793+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:21.764217+00:00, run_end_date=2023-07-31 16:55:22.490587+00:00, run_duration=0.72637, state=success, executor_state=success, try_number=1, max_tries=1, job_id=85, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:18.792950+00:00, queued_by_job_id=4, pid=352[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.133+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-22T00:00:00+00:00, run_after=2023-04-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.159+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-25 00:00:00+00:00: scheduled__2023-04-25T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:10.271382+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.159+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-25 00:00:00+00:00, run_id=scheduled__2023-04-25T00:00:00+00:00, run_start_date=2023-07-31 16:55:10.303161+00:00, run_end_date=2023-07-31 16:55:23.159641+00:00, run_duration=12.85648, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-25 00:00:00+00:00, data_interval_end=2023-04-26 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.164+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-26T00:00:00+00:00, run_after=2023-04-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.169+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-23 00:00:00+00:00: scheduled__2023-04-23T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:09.653075+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.170+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-23 00:00:00+00:00, run_id=scheduled__2023-04-23T00:00:00+00:00, run_start_date=2023-07-31 16:55:09.676455+00:00, run_end_date=2023-07-31 16:55:23.169965+00:00, run_duration=13.49351, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-23 00:00:00+00:00, data_interval_end=2023-04-24 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.174+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-24T00:00:00+00:00, run_after=2023-04-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.179+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-18 00:00:00+00:00: scheduled__2023-04-18T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:08.552377+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.180+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-18 00:00:00+00:00, run_id=scheduled__2023-04-18T00:00:00+00:00, run_start_date=2023-07-31 16:55:08.575488+00:00, run_end_date=2023-07-31 16:55:23.180251+00:00, run_duration=14.604763, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-18 00:00:00+00:00, data_interval_end=2023-04-19 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.184+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-19T00:00:00+00:00, run_after=2023-04-20T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.250+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-30T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.250+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.250+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.251+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.251+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-04-30T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.254+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.254+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.254+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.254+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.254+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.254+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-04-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.448+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.448+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.448+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.448+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.448+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.448+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.449+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.449+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.449+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.449+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.449+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.449+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.479+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:22.876666+00:00, run_end_date=2023-07-31 16:55:23.167825+00:00, run_duration=0.291159, state=success, executor_state=success, try_number=1, max_tries=1, job_id=93, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:18.792950+00:00, queued_by_job_id=4, pid=363[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.480+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:21.807965+00:00, run_end_date=2023-07-31 16:55:22.462296+00:00, run_duration=0.654331, state=success, executor_state=success, try_number=1, max_tries=1, job_id=88, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:18.792950+00:00, queued_by_job_id=4, pid=353[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.480+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:21.925779+00:00, run_end_date=2023-07-31 16:55:22.507225+00:00, run_duration=0.581446, state=success, executor_state=success, try_number=1, max_tries=1, job_id=86, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:18.792950+00:00, queued_by_job_id=4, pid=354[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.481+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:22.840715+00:00, run_end_date=2023-07-31 16:55:23.142173+00:00, run_duration=0.301458, state=success, executor_state=success, try_number=1, max_tries=1, job_id=92, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:20.052246+00:00, queued_by_job_id=4, pid=362[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.481+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:22.092185+00:00, run_end_date=2023-07-31 16:55:22.702376+00:00, run_duration=0.610191, state=success, executor_state=success, try_number=1, max_tries=1, job_id=89, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:20.052246+00:00, queued_by_job_id=4, pid=356[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.481+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-28T00:00:00+00:00 [queued]> to bac0eb11-bbac-48bf-9b3e-1229cc67b076[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.481+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:22.073258+00:00, run_end_date=2023-07-31 16:55:22.621603+00:00, run_duration=0.548345, state=success, executor_state=success, try_number=1, max_tries=1, job_id=87, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:18.792950+00:00, queued_by_job_id=4, pid=357[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.481+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-29T00:00:00+00:00 [queued]> to 34a0bfd4-f682-4d38-a5a0-b40911088f08[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.481+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:22.637820+00:00, run_end_date=2023-07-31 16:55:23.024869+00:00, run_duration=0.387049, state=success, executor_state=success, try_number=1, max_tries=1, job_id=90, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:20.052246+00:00, queued_by_job_id=4, pid=361[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.481+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-04-30T00:00:00+00:00 [queued]> to ec068051-aa69-404c-9fa3-db7c97903f63[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.483+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-04-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:22.420366+00:00, run_end_date=2023-07-31 16:55:22.976039+00:00, run_duration=0.555673, state=success, executor_state=success, try_number=1, max_tries=1, job_id=91, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:20.052246+00:00, queued_by_job_id=4, pid=360[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.483+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:22.954822+00:00, run_end_date=2023-07-31 16:55:23.278003+00:00, run_duration=0.323181, state=success, executor_state=success, try_number=1, max_tries=1, job_id=94, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:20.707674+00:00, queued_by_job_id=4, pid=364[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.514+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-20T00:00:00+00:00, run_after=2023-04-21T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.532+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-27 00:00:00+00:00: scheduled__2023-04-27T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:11.526002+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.532+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-27 00:00:00+00:00, run_id=scheduled__2023-04-27T00:00:00+00:00, run_start_date=2023-07-31 16:55:11.544386+00:00, run_end_date=2023-07-31 16:55:23.532614+00:00, run_duration=11.988228, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-27 00:00:00+00:00, data_interval_end=2023-04-28 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.536+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-28T00:00:00+00:00, run_after=2023-04-29T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.542+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-26 00:00:00+00:00: scheduled__2023-04-26T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:10.767185+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.542+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-26 00:00:00+00:00, run_id=scheduled__2023-04-26T00:00:00+00:00, run_start_date=2023-07-31 16:55:10.800392+00:00, run_end_date=2023-07-31 16:55:23.542490+00:00, run_duration=12.742098, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-26 00:00:00+00:00, data_interval_end=2023-04-27 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.547+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-27T00:00:00+00:00, run_after=2023-04-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.594+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-01T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.594+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.594+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-01T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.597+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.597+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.637+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.637+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.642+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:23.052854+00:00, run_end_date=2023-07-31 16:55:23.424802+00:00, run_duration=0.371948, state=success, executor_state=success, try_number=1, max_tries=1, job_id=95, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:20.707674+00:00, queued_by_job_id=4, pid=365[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.643+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-01T00:00:00+00:00 [queued]> to 9dd67260-dafc-49d0-97ce-22282d1ff818[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.669+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-28T00:00:00+00:00, run_after=2023-04-29T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.738+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:23.744+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:23.169872+00:00, run_end_date=2023-07-31 16:55:23.475909+00:00, run_duration=0.306037, state=success, executor_state=success, try_number=1, max_tries=1, job_id=96, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:20.707674+00:00, queued_by_job_id=4, pid=366[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.699+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-29T00:00:00+00:00, run_after=2023-04-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.722+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-28 00:00:00+00:00: scheduled__2023-04-28T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:12.079171+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.722+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-28 00:00:00+00:00, run_id=scheduled__2023-04-28T00:00:00+00:00, run_start_date=2023-07-31 16:55:12.126589+00:00, run_end_date=2023-07-31 16:55:24.722294+00:00, run_duration=12.595705, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-28 00:00:00+00:00, data_interval_end=2023-04-29 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.726+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-29T00:00:00+00:00, run_after=2023-04-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.738+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-29 00:00:00+00:00: scheduled__2023-04-29T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:13.162826+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.739+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-29 00:00:00+00:00, run_id=scheduled__2023-04-29T00:00:00+00:00, run_start_date=2023-07-31 16:55:13.224376+00:00, run_end_date=2023-07-31 16:55:24.739187+00:00, run_duration=11.514811, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-29 00:00:00+00:00, data_interval_end=2023-04-30 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.743+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-04-30T00:00:00+00:00, run_after=2023-05-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.769+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.769+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.769+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-04-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.774+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:24.430660+00:00, run_end_date=2023-07-31 16:55:24.648071+00:00, run_duration=0.217411, state=success, executor_state=success, try_number=1, max_tries=1, job_id=99, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:23.251712+00:00, queued_by_job_id=4, pid=377[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.774+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:24.417045+00:00, run_end_date=2023-07-31 16:55:24.628424+00:00, run_duration=0.211379, state=success, executor_state=success, try_number=1, max_tries=1, job_id=98, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:23.251712+00:00, queued_by_job_id=4, pid=376[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:24.774+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-04-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:24.406946+00:00, run_end_date=2023-07-31 16:55:24.628424+00:00, run_duration=0.221478, state=success, executor_state=success, try_number=1, max_tries=1, job_id=97, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:23.251712+00:00, queued_by_job_id=4, pid=375[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.812+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-01T00:00:00+00:00, run_after=2023-05-02T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.860+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-04-30 00:00:00+00:00: scheduled__2023-04-30T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:14.228645+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.860+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-04-30 00:00:00+00:00, run_id=scheduled__2023-04-30T00:00:00+00:00, run_start_date=2023-07-31 16:55:14.249526+00:00, run_end_date=2023-07-31 16:55:25.860666+00:00, run_duration=11.61114, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-04-30 00:00:00+00:00, data_interval_end=2023-05-01 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.866+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-01T00:00:00+00:00, run_after=2023-05-02T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.874+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-01 00:00:00+00:00: scheduled__2023-05-01T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:14.847657+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.874+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-01 00:00:00+00:00, run_id=scheduled__2023-05-01T00:00:00+00:00, run_start_date=2023-07-31 16:55:14.869594+00:00, run_end_date=2023-07-31 16:55:25.874441+00:00, run_duration=11.004847, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-01 00:00:00+00:00, data_interval_end=2023-05-02 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.879+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-02T00:00:00+00:00, run_after=2023-05-03T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.915+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:25.926+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:24.626372+00:00, run_end_date=2023-07-31 16:55:24.811427+00:00, run_duration=0.185055, state=success, executor_state=success, try_number=1, max_tries=1, job_id=100, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:23.595283+00:00, queued_by_job_id=4, pid=378[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /dags/my_data_pipeline/gantt?root= HTTP/1.1" 200 49010 "http://localhost:8080/dags/my_data_pipeline/duration?days=30&root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/gantt.9995f2d594526c5d78cc.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /static/dist/gantt.9995f2d594526c5d78cc.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:26 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:26.958+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-03T00:00:00+00:00, run_after=2023-05-04T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.005+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.005+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.006+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.009+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.009+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.049+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.057+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-02T00:00:00+00:00 [queued]> to e34cc40b-69c3-4285-b20b-5b37ebe76fd3[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.088+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-04T00:00:00+00:00, run_after=2023-05-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.151+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.151+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.152+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.155+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.155+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.202+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.208+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-03T00:00:00+00:00 [queued]> to 55fe7235-491b-4c31-9b6c-42ac7256f7d3[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.239+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-05T00:00:00+00:00, run_after=2023-05-06T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.313+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.313+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.313+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.316+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.316+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.367+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.372+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-04T00:00:00+00:00 [queued]> to 04c7f43a-c353-4873-a2c4-db338c7d74b5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.407+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-06T00:00:00+00:00, run_after=2023-05-07T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.493+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.493+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.493+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.496+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.496+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.568+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.573+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-05T00:00:00+00:00 [queued]> to 5bb54fe7-ff75-4a84-bc5c-06e397331a94[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.610+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-07T00:00:00+00:00, run_after=2023-05-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.710+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.711+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.711+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.714+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.715+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.762+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.768+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-06T00:00:00+00:00 [queued]> to f3389c23-e257-4609-91a2-5a18263d94b3[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.810+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-08T00:00:00+00:00, run_after=2023-05-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.953+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.954+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.954+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.957+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:27.957+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.006+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.012+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-07T00:00:00+00:00 [queued]> to b04cbcf4-a75a-4a81-a219-780e26bef288[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.062+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-09T00:00:00+00:00, run_after=2023-05-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.225+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.225+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.225+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.228+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.228+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.348+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.355+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-08T00:00:00+00:00 [queued]> to ea76cb8e-3523-4606-b032-cc87115f55fd[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.394+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-10T00:00:00+00:00, run_after=2023-05-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.536+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.536+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.536+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.539+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.540+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.645+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.655+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-09T00:00:00+00:00 [queued]> to 7937a228-73a4-414a-bc0b-168d9c14bc73[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.691+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-11T00:00:00+00:00, run_after=2023-05-12T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.870+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.870+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.870+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.875+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:28.875+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.015+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.029+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-10T00:00:00+00:00 [queued]> to a3b80df0-cfe6-44f0-886e-ee38c62d145f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.085+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-12T00:00:00+00:00, run_after=2023-05-13T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.309+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-11T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.310+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.310+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.311+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.311+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-11T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.316+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.316+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.316+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.316+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.317+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.317+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.686+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.686+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.686+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.686+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.687+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.687+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.712+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:28.365604+00:00, run_end_date=2023-07-31 16:55:28.864477+00:00, run_duration=0.498873, state=success, executor_state=success, try_number=1, max_tries=1, job_id=101, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:27.006954+00:00, queued_by_job_id=4, pid=390[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.713+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-02T00:00:00+00:00 [queued]> to 9eafd88c-aa07-4bc8-be4f-8c2561f128fd[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.713+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-03T00:00:00+00:00 [queued]> to 40590a3d-16ee-40f0-abaf-79592032d9b6[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.713+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:28.560152+00:00, run_end_date=2023-07-31 16:55:29.056103+00:00, run_duration=0.495951, state=success, executor_state=success, try_number=1, max_tries=1, job_id=102, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:27.153044+00:00, queued_by_job_id=4, pid=392[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.713+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-11T00:00:00+00:00 [queued]> to 3ddeafeb-38dd-4279-a91d-7353e4fcc2c4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.713+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:28.904499+00:00, run_end_date=2023-07-31 16:55:29.323064+00:00, run_duration=0.418565, state=success, executor_state=success, try_number=1, max_tries=1, job_id=103, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:27.314422+00:00, queued_by_job_id=4, pid=396[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.749+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-13T00:00:00+00:00, run_after=2023-05-14T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.966+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.967+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.972+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.972+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.972+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.973+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.973+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:29.973+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.408+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.409+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.409+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.409+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.447+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-04T00:00:00+00:00 [queued]> to 81b15291-e540-4b0e-a2ae-184c9873353c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.447+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-05T00:00:00+00:00 [queued]> to d282d472-2f41-464f-b521-ec81007a2fa4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.447+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:29.212448+00:00, run_end_date=2023-07-31 16:55:29.766567+00:00, run_duration=0.554119, state=success, executor_state=success, try_number=1, max_tries=1, job_id=104, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:27.494511+00:00, queued_by_job_id=4, pid=398[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.447+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-12T00:00:00+00:00 [queued]> to 15757f99-c842-4cd7-b329-7d8c5a6c7bb7[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.534+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-14T00:00:00+00:00, run_after=2023-05-15T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.784+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-06T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.784+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.784+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.784+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.784+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-06T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.789+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.789+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.789+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.790+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.790+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:30.790+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.231+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.232+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.232+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.232+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.232+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.232+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.262+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-07T00:00:00+00:00 [queued]> to f71df257-ec5b-455f-98ca-df93f35f5780[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.262+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:29.885411+00:00, run_end_date=2023-07-31 16:55:30.401022+00:00, run_duration=0.515611, state=success, executor_state=success, try_number=1, max_tries=1, job_id=106, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:27.955053+00:00, queued_by_job_id=4, pid=403[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.262+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-06T00:00:00+00:00 [queued]> to e03d81a7-8afb-436a-8f81-6487dfcb18ab[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.263+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:29.921924+00:00, run_end_date=2023-07-31 16:55:30.503556+00:00, run_duration=0.581632, state=success, executor_state=success, try_number=1, max_tries=1, job_id=105, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:27.712559+00:00, queued_by_job_id=4, pid=404[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.263+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-13T00:00:00+00:00 [queued]> to 274286f9-ee26-424c-b32f-5e851a648475[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.263+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:30.344127+00:00, run_end_date=2023-07-31 16:55:30.944944+00:00, run_duration=0.600817, state=success, executor_state=success, try_number=1, max_tries=1, job_id=107, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:28.226280+00:00, queued_by_job_id=4, pid=410[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.298+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-15T00:00:00+00:00, run_after=2023-05-16T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.531+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-08T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.531+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.531+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.531+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.532+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-08T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.538+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.539+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.539+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.539+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.539+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.539+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:31 +0000] "GET /dags/my_data_pipeline/audit_log?root= HTTP/1.1" 200 112792 "http://localhost:8080/dags/my_data_pipeline/gantt?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.948+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.948+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.948+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.948+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.963+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:30.568283+00:00, run_end_date=2023-07-31 16:55:31.095106+00:00, run_duration=0.526823, state=success, executor_state=success, try_number=1, max_tries=1, job_id=108, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:28.537619+00:00, queued_by_job_id=4, pid=412[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.964+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-09T00:00:00+00:00 [queued]> to e5c02248-1a81-451a-80ee-a69d1752a96e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.964+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-08T00:00:00+00:00 [queued]> to 4a3e3ae9-4089-47b3-9ebd-f1b7dfee6036[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:31.964+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-14T00:00:00+00:00 [queued]> to 285a9767-9619-4075-8ebf-756e2823ae2b[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:31 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.008+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/dataTables.bootstrap.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.281+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.281+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.281+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.290+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.290+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/dataTables.bootstrap.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /static/dist/jquery.dataTables.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.500+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.500+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.515+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:31.293324+00:00, run_end_date=2023-07-31 16:55:32.082926+00:00, run_duration=0.789602, state=success, executor_state=success, try_number=1, max_tries=1, job_id=109, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:28.871665+00:00, queued_by_job_id=4, pid=419[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.515+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-15T00:00:00+00:00 [queued]> to 32b030bd-a225-433a-b730-461c0bea52e3[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.559+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-17T00:00:00+00:00, run_after=2023-05-18T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:32 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.852+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.852+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.852+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.852+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.852+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.856+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.857+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.857+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.857+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.857+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:32.857+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.194+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.194+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.194+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.194+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.194+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.216+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-02T00:00:00+00:00 [queued]> to 99ac0172-6e2f-46b5-baf2-dfdf93bedffa[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.216+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:31.804925+00:00, run_end_date=2023-07-31 16:55:32.550628+00:00, run_duration=0.745703, state=success, executor_state=success, try_number=1, max_tries=1, job_id=110, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:29.312838+00:00, queued_by_job_id=4, pid=424[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.216+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-10T00:00:00+00:00 [queued]> to f84e52eb-cb67-4d38-830b-619706aefe3e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.217+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:31.894233+00:00, run_end_date=2023-07-31 16:55:32.679814+00:00, run_duration=0.785581, state=success, executor_state=success, try_number=1, max_tries=1, job_id=111, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:29.312838+00:00, queued_by_job_id=4, pid=425[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.217+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-16T00:00:00+00:00 [queued]> to 503b07b2-0217-4006-b6a0-62084c71b33e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.264+0000[0m] {[34mscheduler_job_runner.py:[0m1298} INFO[0m - DAG my_data_pipeline is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.516+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-11T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.516+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.516+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.516+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.516+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.516+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-11T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.520+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.520+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.521+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.521+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.521+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.521+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.521+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:33.521+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.063+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.063+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.063+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.063+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.063+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.063+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.063+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.082+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-03T00:00:00+00:00 [queued]> to 66ef793b-c26d-4a7d-8c16-cc95e0900ca4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.083+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:32.307919+00:00, run_end_date=2023-07-31 16:55:32.974751+00:00, run_duration=0.666832, state=success, executor_state=success, try_number=1, max_tries=1, job_id=112, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:29.312838+00:00, queued_by_job_id=4, pid=429[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.083+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:32.574759+00:00, run_end_date=2023-07-31 16:55:33.407744+00:00, run_duration=0.832985, state=success, executor_state=success, try_number=1, max_tries=1, job_id=113, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:29.969426+00:00, queued_by_job_id=4, pid=431[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.083+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:32.760561+00:00, run_end_date=2023-07-31 16:55:33.367485+00:00, run_duration=0.606924, state=success, executor_state=success, try_number=1, max_tries=1, job_id=114, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:29.969426+00:00, queued_by_job_id=4, pid=432[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.083+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-05T00:00:00+00:00 [queued]> to 1912cbef-f821-4fc7-8f6f-d564c517b791[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.083+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-11T00:00:00+00:00 [queued]> to 8551688b-793e-45e3-8fb2-a7a4f6fef7ce[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.083+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-17T00:00:00+00:00 [queued]> to 813b4c8f-14e3-4cb1-82ae-b120b45a1ee1[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.454+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.455+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.455+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.455+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.458+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.458+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.458+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.459+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.653+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.653+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.653+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.654+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.654+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.670+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-04T00:00:00+00:00 [queued]> to 20aa9c6f-e6e8-48ed-8be2-4f70738dcb3f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.670+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:33.637484+00:00, run_end_date=2023-07-31 16:55:34.221924+00:00, run_duration=0.58444, state=success, executor_state=success, try_number=1, max_tries=1, job_id=116, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:30.786584+00:00, queued_by_job_id=4, pid=445[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.670+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:33.584420+00:00, run_end_date=2023-07-31 16:55:34.301972+00:00, run_duration=0.717552, state=success, executor_state=success, try_number=1, max_tries=1, job_id=117, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:30.786584+00:00, queued_by_job_id=4, pid=446[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.670+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-07T00:00:00+00:00 [queued]> to a7ae8a33-d238-40f0-b342-2382acc94d66[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.671+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:33.621851+00:00, run_end_date=2023-07-31 16:55:34.273258+00:00, run_duration=0.651407, state=success, executor_state=success, try_number=1, max_tries=1, job_id=115, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:29.969426+00:00, queued_by_job_id=4, pid=444[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.904+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.904+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.904+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.904+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.904+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.908+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.908+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.908+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.908+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.908+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:34.909+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.354+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.354+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.354+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.355+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.355+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.371+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-06T00:00:00+00:00 [queued]> to e2ac89b8-0661-4151-8293-a6963b01d59a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.371+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:34.429452+00:00, run_end_date=2023-07-31 16:55:34.901566+00:00, run_duration=0.472114, state=success, executor_state=success, try_number=1, max_tries=1, job_id=120, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:31.533618+00:00, queued_by_job_id=4, pid=451[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.372+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:33.945675+00:00, run_end_date=2023-07-31 16:55:34.611753+00:00, run_duration=0.666078, state=success, executor_state=success, try_number=1, max_tries=1, job_id=118, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:30.786584+00:00, queued_by_job_id=4, pid=447[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.372+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-13T00:00:00+00:00 [queued]> to d7bce945-d8ab-4f98-89f2-c97aaaf19679[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.372+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-12T00:00:00+00:00 [queued]> to c928feac-b3ed-4748-b410-097d5175a3ad[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.618+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-08T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.618+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.618+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.618+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.618+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-08T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.622+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.622+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.622+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.622+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.623+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.623+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.988+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.988+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.988+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.988+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:35.988+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:36.027+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-08T00:00:00+00:00 [queued]> to cc4d3db8-256b-4cc6-a791-f92774fa31ac[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:36.027+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:34.563862+00:00, run_end_date=2023-07-31 16:55:35.320775+00:00, run_duration=0.756913, state=success, executor_state=success, try_number=1, max_tries=1, job_id=121, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:31.533618+00:00, queued_by_job_id=4, pid=455[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:36.027+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-09T00:00:00+00:00 [queued]> to 1d61c699-848d-4a9a-a587-f4f22f21f90e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:36.027+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-14T00:00:00+00:00 [queued]> to ee4b2b83-38de-444b-a4b0-95d27501c650[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:36.027+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:34.509797+00:00, run_end_date=2023-07-31 16:55:35.257342+00:00, run_duration=0.747545, state=success, executor_state=success, try_number=1, max_tries=1, job_id=119, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:31.533618+00:00, queued_by_job_id=4, pid=454[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:55:36 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.388+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-02 00:00:00+00:00: scheduled__2023-05-02T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:26.952191+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.388+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-02 00:00:00+00:00, run_id=scheduled__2023-05-02T00:00:00+00:00, run_start_date=2023-07-31 16:55:26.969680+00:00, run_end_date=2023-07-31 16:55:37.388711+00:00, run_duration=10.419031, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-02 00:00:00+00:00, data_interval_end=2023-05-03 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.393+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-03T00:00:00+00:00, run_after=2023-05-04T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.400+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-05 00:00:00+00:00: scheduled__2023-05-05T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:27.400966+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.401+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-05 00:00:00+00:00, run_id=scheduled__2023-05-05T00:00:00+00:00, run_start_date=2023-07-31 16:55:27.418461+00:00, run_end_date=2023-07-31 16:55:37.400952+00:00, run_duration=9.982491, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-05 00:00:00+00:00, data_interval_end=2023-05-06 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.405+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-06T00:00:00+00:00, run_after=2023-05-07T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.559+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 5 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.560+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.560+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.560+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.560+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.560+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.560+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.571+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.571+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:37.572+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.002+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.003+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.004+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.004+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.004+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.088+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:35.757526+00:00, run_end_date=2023-07-31 16:55:36.570962+00:00, run_duration=0.813436, state=success, executor_state=success, try_number=1, max_tries=1, job_id=125, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:32.853977+00:00, queued_by_job_id=4, pid=469[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.088+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:36.992566+00:00, run_end_date=2023-07-31 16:55:37.556027+00:00, run_duration=0.563461, state=success, executor_state=success, try_number=1, max_tries=1, job_id=129, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:33.518406+00:00, queued_by_job_id=4, pid=480[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.088+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:36.515461+00:00, run_end_date=2023-07-31 16:55:37.071430+00:00, run_duration=0.555969, state=success, executor_state=success, try_number=1, max_tries=1, job_id=127, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:33.518406+00:00, queued_by_job_id=4, pid=475[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.088+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:35.525137+00:00, run_end_date=2023-07-31 16:55:36.164251+00:00, run_duration=0.639114, state=success, executor_state=success, try_number=1, max_tries=1, job_id=123, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:32.853977+00:00, queued_by_job_id=4, pid=464[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.088+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-10T00:00:00+00:00 [queued]> to d9b62660-10d7-4aff-a621-708a54c81f78[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.088+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-16T00:00:00+00:00 [queued]> to ec407e81-4643-4fe4-be9a-85aa74bf4dc5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.089+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:35.622442+00:00, run_end_date=2023-07-31 16:55:36.347060+00:00, run_duration=0.724618, state=success, executor_state=success, try_number=1, max_tries=1, job_id=124, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:32.853977+00:00, queued_by_job_id=4, pid=465[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.089+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-11T00:00:00+00:00 [queued]> to a1784e79-e2af-4ea5-a69e-31378947c522[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.089+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:36.324822+00:00, run_end_date=2023-07-31 16:55:37.038097+00:00, run_duration=0.713275, state=success, executor_state=success, try_number=1, max_tries=1, job_id=126, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:33.518406+00:00, queued_by_job_id=4, pid=474[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.089+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-15T00:00:00+00:00 [queued]> to e9f365dd-5d7c-4aa9-9c28-662e5aeb52db[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.089+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:35.318691+00:00, run_end_date=2023-07-31 16:55:36.084035+00:00, run_duration=0.765344, state=success, executor_state=success, try_number=1, max_tries=1, job_id=122, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:32.282200+00:00, queued_by_job_id=4, pid=463[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.089+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-17T00:00:00+00:00 [queued]> to f81e12fe-ba15-445e-8fe3-8a2f6b5447f8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.089+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:36.855717+00:00, run_end_date=2023-07-31 16:55:37.344692+00:00, run_duration=0.488975, state=success, executor_state=success, try_number=1, max_tries=1, job_id=128, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:33.518406+00:00, queued_by_job_id=4, pid=479[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.135+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-07T00:00:00+00:00, run_after=2023-05-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.157+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-03 00:00:00+00:00: scheduled__2023-05-03T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:27.081608+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.157+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-03 00:00:00+00:00, run_id=scheduled__2023-05-03T00:00:00+00:00, run_start_date=2023-07-31 16:55:27.098599+00:00, run_end_date=2023-07-31 16:55:38.157802+00:00, run_duration=11.059203, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-03 00:00:00+00:00, data_interval_end=2023-05-04 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.161+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-04T00:00:00+00:00, run_after=2023-05-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.192+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-04 00:00:00+00:00: scheduled__2023-05-04T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:27.232585+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.192+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-04 00:00:00+00:00, run_id=scheduled__2023-05-04T00:00:00+00:00, run_start_date=2023-07-31 16:55:27.250286+00:00, run_end_date=2023-07-31 16:55:38.192598+00:00, run_duration=10.942312, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-04 00:00:00+00:00, data_interval_end=2023-05-05 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.200+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-05T00:00:00+00:00, run_after=2023-05-06T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.284+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-06 00:00:00+00:00: scheduled__2023-05-06T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:27.604850+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.284+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-06 00:00:00+00:00, run_id=scheduled__2023-05-06T00:00:00+00:00, run_start_date=2023-07-31 16:55:27.621608+00:00, run_end_date=2023-07-31 16:55:38.284319+00:00, run_duration=10.662711, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-06 00:00:00+00:00, data_interval_end=2023-05-07 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.302+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-07T00:00:00+00:00, run_after=2023-05-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.346+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.346+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.346+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.351+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.351+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.430+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.431+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.431+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.431+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.449+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:37.324163+00:00, run_end_date=2023-07-31 16:55:37.846981+00:00, run_duration=0.522818, state=success, executor_state=success, try_number=1, max_tries=1, job_id=131, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:34.456100+00:00, queued_by_job_id=4, pid=483[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.449+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:37.411444+00:00, run_end_date=2023-07-31 16:55:37.964332+00:00, run_duration=0.552888, state=success, executor_state=success, try_number=1, max_tries=1, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:34.905997+00:00, queued_by_job_id=4, pid=484[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.449+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:37.224746+00:00, run_end_date=2023-07-31 16:55:37.720260+00:00, run_duration=0.495514, state=success, executor_state=success, try_number=1, max_tries=1, job_id=130, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:34.905997+00:00, queued_by_job_id=4, pid=481[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.449+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-12T00:00:00+00:00 [queued]> to 2a073f52-edd5-48c7-8a46-7116e842e269[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.477+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-08T00:00:00+00:00, run_after=2023-05-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.518+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-09 00:00:00+00:00: scheduled__2023-05-09T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:28.388347+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.518+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-09 00:00:00+00:00, run_id=scheduled__2023-05-09T00:00:00+00:00, run_start_date=2023-07-31 16:55:28.412977+00:00, run_end_date=2023-07-31 16:55:38.518710+00:00, run_duration=10.105733, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-09 00:00:00+00:00, data_interval_end=2023-05-10 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.523+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-10T00:00:00+00:00, run_after=2023-05-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.529+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-07 00:00:00+00:00: scheduled__2023-05-07T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:27.800089+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.530+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-07 00:00:00+00:00, run_id=scheduled__2023-05-07T00:00:00+00:00, run_start_date=2023-07-31 16:55:27.826231+00:00, run_end_date=2023-07-31 16:55:38.529933+00:00, run_duration=10.703702, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-07 00:00:00+00:00, data_interval_end=2023-05-08 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.535+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-08T00:00:00+00:00, run_after=2023-05-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.623+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-13T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.623+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.623+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-13T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.626+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.627+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.718+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.719+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.719+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.719+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.726+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:37.660075+00:00, run_end_date=2023-07-31 16:55:38.301353+00:00, run_duration=0.641278, state=success, executor_state=success, try_number=1, max_tries=1, job_id=133, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:35.620085+00:00, queued_by_job_id=4, pid=491[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.726+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:37.652412+00:00, run_end_date=2023-07-31 16:55:38.232147+00:00, run_duration=0.579735, state=success, executor_state=success, try_number=1, max_tries=1, job_id=134, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:34.456100+00:00, queued_by_job_id=4, pid=492[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.727+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-13T00:00:00+00:00 [queued]> to 9fb3abe3-51b1-43d5-a392-d85ba697c50f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.727+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:37.635398+00:00, run_end_date=2023-07-31 16:55:38.296247+00:00, run_duration=0.660849, state=success, executor_state=success, try_number=1, max_tries=1, job_id=135, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:34.905997+00:00, queued_by_job_id=4, pid=490[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.754+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-09T00:00:00+00:00, run_after=2023-05-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.778+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-08 00:00:00+00:00: scheduled__2023-05-08T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:28.056183+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.778+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-08 00:00:00+00:00, run_id=scheduled__2023-05-08T00:00:00+00:00, run_start_date=2023-07-31 16:55:28.079097+00:00, run_end_date=2023-07-31 16:55:38.778626+00:00, run_duration=10.699529, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-08 00:00:00+00:00, data_interval_end=2023-05-09 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.782+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-09T00:00:00+00:00, run_after=2023-05-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.892+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-14T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.893+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.893+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-14T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.896+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:38.896+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:39.006+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:39.006+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:39.006+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:39.020+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:38.288413+00:00, run_end_date=2023-07-31 16:55:38.731480+00:00, run_duration=0.443067, state=success, executor_state=success, try_number=1, max_tries=1, job_id=137, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:35.620085+00:00, queued_by_job_id=4, pid=494[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:39.020+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-14T00:00:00+00:00 [queued]> to ce09f597-903f-4140-8e5e-d36d43c1b4ed[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:39.021+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:38.129850+00:00, run_end_date=2023-07-31 16:55:38.682583+00:00, run_duration=0.552733, state=success, executor_state=success, try_number=1, max_tries=1, job_id=136, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:35.620085+00:00, queued_by_job_id=4, pid=493[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:39.050+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-10T00:00:00+00:00, run_after=2023-05-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.232+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-11T00:00:00+00:00, run_after=2023-05-12T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.263+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-11 00:00:00+00:00: scheduled__2023-05-11T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:29.071484+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.263+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-11 00:00:00+00:00, run_id=scheduled__2023-05-11T00:00:00+00:00, run_start_date=2023-07-31 16:55:29.111355+00:00, run_end_date=2023-07-31 16:55:40.263677+00:00, run_duration=11.152322, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-11 00:00:00+00:00, data_interval_end=2023-05-12 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.268+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-12T00:00:00+00:00, run_after=2023-05-13T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.297+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-12 00:00:00+00:00: scheduled__2023-05-12T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:29.742619+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.298+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-12 00:00:00+00:00, run_id=scheduled__2023-05-12T00:00:00+00:00, run_start_date=2023-07-31 16:55:29.766898+00:00, run_end_date=2023-07-31 16:55:40.298222+00:00, run_duration=10.531324, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-12 00:00:00+00:00, data_interval_end=2023-05-13 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.303+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-13T00:00:00+00:00, run_after=2023-05-14T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.308+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-10 00:00:00+00:00: scheduled__2023-05-10T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:28.682027+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.308+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-10 00:00:00+00:00, run_id=scheduled__2023-05-10T00:00:00+00:00, run_start_date=2023-07-31 16:55:28.711928+00:00, run_end_date=2023-07-31 16:55:40.308602+00:00, run_duration=11.596674, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-10 00:00:00+00:00, data_interval_end=2023-05-11 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.312+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-11T00:00:00+00:00, run_after=2023-05-12T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.332+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.333+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.333+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.333+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.333+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-17T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.335+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.336+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.336+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.336+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.336+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.336+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.475+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.475+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.475+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.475+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.476+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.476+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.476+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.476+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.476+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.476+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.500+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:39.669373+00:00, run_end_date=2023-07-31 16:55:39.962290+00:00, run_duration=0.292917, state=success, executor_state=success, try_number=1, max_tries=1, job_id=142, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:37.563240+00:00, queued_by_job_id=4, pid=510[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.500+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:39.592121+00:00, run_end_date=2023-07-31 16:55:39.954079+00:00, run_duration=0.361958, state=success, executor_state=success, try_number=1, max_tries=1, job_id=140, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:37.563240+00:00, queued_by_job_id=4, pid=508[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.500+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-16T00:00:00+00:00 [queued]> to 4da65c77-d915-4ea1-bde0-a2ea51ebf18b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.501+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:39.273076+00:00, run_end_date=2023-07-31 16:55:39.634060+00:00, run_duration=0.360984, state=success, executor_state=success, try_number=1, max_tries=1, job_id=138, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:37.563240+00:00, queued_by_job_id=4, pid=504[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.501+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:39.905651+00:00, run_end_date=2023-07-31 16:55:40.169494+00:00, run_duration=0.263843, state=success, executor_state=success, try_number=1, max_tries=1, job_id=143, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:38.347463+00:00, queued_by_job_id=4, pid=511[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.501+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:40.108563+00:00, run_end_date=2023-07-31 16:55:40.304974+00:00, run_duration=0.196411, state=success, executor_state=success, try_number=1, max_tries=1, job_id=144, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:38.624527+00:00, queued_by_job_id=4, pid=512[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.501+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-15T00:00:00+00:00 [queued]> to 830f08f8-2ffc-40e8-b0cb-2eb19a41e61c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.501+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:39.466579+00:00, run_end_date=2023-07-31 16:55:39.770119+00:00, run_duration=0.30354, state=success, executor_state=success, try_number=1, max_tries=1, job_id=139, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:37.563240+00:00, queued_by_job_id=4, pid=506[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.501+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-17T00:00:00+00:00 [queued]> to bbea4e1d-6c8b-41c4-b731-52b5489e6c57[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.501+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:39.669373+00:00, run_end_date=2023-07-31 16:55:39.985138+00:00, run_duration=0.315765, state=success, executor_state=success, try_number=1, max_tries=1, job_id=141, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:37.563240+00:00, queued_by_job_id=4, pid=509[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.527+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-12T00:00:00+00:00, run_after=2023-05-13T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.576+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-13 00:00:00+00:00: scheduled__2023-05-13T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:30.523471+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.576+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-13 00:00:00+00:00, run_id=scheduled__2023-05-13T00:00:00+00:00, run_start_date=2023-07-31 16:55:30.549464+00:00, run_end_date=2023-07-31 16:55:40.576869+00:00, run_duration=10.027405, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-13 00:00:00+00:00, data_interval_end=2023-05-14 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.582+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-14T00:00:00+00:00, run_after=2023-05-15T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.614+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:40.619+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:40.222376+00:00, run_end_date=2023-07-31 16:55:40.456974+00:00, run_duration=0.234598, state=success, executor_state=success, try_number=1, max_tries=1, job_id=145, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:38.894056+00:00, queued_by_job_id=4, pid=513[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:41.069+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-15T00:00:00+00:00, run_after=2023-05-16T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:41.099+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-14 00:00:00+00:00: scheduled__2023-05-14T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:31.289006+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:41.100+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-14 00:00:00+00:00, run_id=scheduled__2023-05-14T00:00:00+00:00, run_start_date=2023-07-31 16:55:31.314526+00:00, run_end_date=2023-07-31 16:55:41.100332+00:00, run_duration=9.785806, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-14 00:00:00+00:00, data_interval_end=2023-05-15 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:41.105+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-15T00:00:00+00:00, run_after=2023-05-16T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.196+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.221+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-16 00:00:00+00:00: scheduled__2023-05-16T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:32.553974+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.222+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-16 00:00:00+00:00, run_id=scheduled__2023-05-16T00:00:00+00:00, run_start_date=2023-07-31 16:55:32.584458+00:00, run_end_date=2023-07-31 16:55:42.222347+00:00, run_duration=9.637889, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-16 00:00:00+00:00, data_interval_end=2023-05-17 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.227+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-17T00:00:00+00:00, run_after=2023-05-18T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.235+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-17 00:00:00+00:00: scheduled__2023-05-17T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:33.254993+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.236+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-17 00:00:00+00:00, run_id=scheduled__2023-05-17T00:00:00+00:00, run_start_date=2023-07-31 16:55:33.276785+00:00, run_end_date=2023-07-31 16:55:42.236172+00:00, run_duration=8.959387, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-17 00:00:00+00:00, data_interval_end=2023-05-18 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.241+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-18T00:00:00+00:00, run_after=2023-05-19T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.247+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-15 00:00:00+00:00: scheduled__2023-05-15T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:31.999826+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.247+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-15 00:00:00+00:00, run_id=scheduled__2023-05-15T00:00:00+00:00, run_start_date=2023-07-31 16:55:32.020675+00:00, run_end_date=2023-07-31 16:55:42.247616+00:00, run_duration=10.226941, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-15 00:00:00+00:00, data_interval_end=2023-05-16 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.251+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.276+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.276+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.276+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.283+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:41.357932+00:00, run_end_date=2023-07-31 16:55:41.532437+00:00, run_duration=0.174505, state=success, executor_state=success, try_number=1, max_tries=1, job_id=147, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:40.334051+00:00, queued_by_job_id=4, pid=522[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.284+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:41.358668+00:00, run_end_date=2023-07-31 16:55:41.529094+00:00, run_duration=0.170426, state=success, executor_state=success, try_number=1, max_tries=1, job_id=148, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:40.334051+00:00, queued_by_job_id=4, pid=521[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:42.284+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:41.351520+00:00, run_end_date=2023-07-31 16:55:41.521864+00:00, run_duration=0.170344, state=success, executor_state=success, try_number=1, max_tries=1, job_id=146, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:40.334051+00:00, queued_by_job_id=4, pid=520[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.327+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-19T00:00:00+00:00, run_after=2023-05-20T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.394+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.395+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.395+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.399+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.400+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.457+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.466+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-18T00:00:00+00:00 [queued]> to 6d71d229-28c5-428b-802f-87963bc819b5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.513+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-20T00:00:00+00:00, run_after=2023-05-21T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.595+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.596+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.596+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.599+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.600+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.669+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.678+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-19T00:00:00+00:00 [queued]> to dc1065b1-d82d-40c9-a24c-4f5161a263ee[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.719+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-21T00:00:00+00:00, run_after=2023-05-22T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.816+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.816+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.816+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.821+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.822+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.872+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.884+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-20T00:00:00+00:00 [queued]> to 0447d5fa-56ad-464b-95f5-e89819b27aad[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:43.919+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-22T00:00:00+00:00, run_after=2023-05-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.035+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.035+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.036+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.039+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.040+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.096+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.105+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-21T00:00:00+00:00 [queued]> to 3050b501-c4c4-4b29-af76-643b2b2d1a14[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.149+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-23T00:00:00+00:00, run_after=2023-05-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.276+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.277+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.277+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.280+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.280+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.319+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.327+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-22T00:00:00+00:00 [queued]> to 4c07bee9-5d89-4161-8e2c-e06155a8d65a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.366+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-24T00:00:00+00:00, run_after=2023-05-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.510+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.511+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.511+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.522+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.522+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.738+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.750+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-23T00:00:00+00:00 [queued]> to 94b150c2-bd49-4145-82b4-630b202c9058[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:44.848+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-25T00:00:00+00:00, run_after=2023-05-26T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.092+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.093+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.093+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.098+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.098+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.192+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.202+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-24T00:00:00+00:00 [queued]> to f6e337b4-3360-4f96-9a7b-651da25004ca[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.246+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-26T00:00:00+00:00, run_after=2023-05-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.413+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.413+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.414+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.417+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.417+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.525+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.541+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-25T00:00:00+00:00 [queued]> to 43cf1f83-147c-49bf-bb1b-4b282489daf4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.588+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-27T00:00:00+00:00, run_after=2023-05-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.744+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.744+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.744+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.747+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.747+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.811+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.817+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-26T00:00:00+00:00 [queued]> to 154af5f3-2e78-406c-8ae4-66595b8b216a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:45.849+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-28T00:00:00+00:00, run_after=2023-05-29T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.112+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.113+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.113+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.113+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.119+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.119+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.119+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.119+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.414+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.415+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.415+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.415+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.446+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:45.187343+00:00, run_end_date=2023-07-31 16:55:45.670712+00:00, run_duration=0.483369, state=success, executor_state=success, try_number=1, max_tries=1, job_id=149, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:43.396184+00:00, queued_by_job_id=4, pid=535[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.447+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-18T00:00:00+00:00 [queued]> to 4e5918a1-82b6-4c22-bf1a-15c469122d93[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.447+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:45.398758+00:00, run_end_date=2023-07-31 16:55:45.921551+00:00, run_duration=0.522793, state=success, executor_state=success, try_number=1, max_tries=1, job_id=150, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:43.597133+00:00, queued_by_job_id=4, pid=537[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.447+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-27T00:00:00+00:00 [queued]> to 2e00041e-884d-472f-9ea2-9a9f37e9f712[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.550+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-29T00:00:00+00:00, run_after=2023-05-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.874+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-20T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.875+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.875+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.875+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.875+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.875+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-20T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.881+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.881+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.881+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.882+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.882+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.882+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.882+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:46.882+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.407+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.407+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.407+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.407+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.407+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.408+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.408+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.432+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-19T00:00:00+00:00 [queued]> to d100d9d1-1ce0-4d59-84cf-383d73f79d3c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.432+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-21T00:00:00+00:00 [queued]> to d5d7bd9d-efee-451a-8bb8-0271b7a1e538[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.432+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:46.020592+00:00, run_end_date=2023-07-31 16:55:46.612254+00:00, run_duration=0.591662, state=success, executor_state=success, try_number=1, max_tries=1, job_id=152, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:44.036800+00:00, queued_by_job_id=4, pid=541[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.432+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:46.096844+00:00, run_end_date=2023-07-31 16:55:46.787600+00:00, run_duration=0.690756, state=success, executor_state=success, try_number=1, max_tries=1, job_id=153, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:44.278156+00:00, queued_by_job_id=4, pid=543[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.432+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-20T00:00:00+00:00 [queued]> to fb011235-8148-48f2-8203-d793391b914b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.433+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:45.619738+00:00, run_end_date=2023-07-31 16:55:46.133320+00:00, run_duration=0.513582, state=success, executor_state=success, try_number=1, max_tries=1, job_id=151, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:43.817937+00:00, queued_by_job_id=4, pid=539[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.433+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-28T00:00:00+00:00 [queued]> to c1b99751-7119-4eb4-b2cd-27834b2dbc21[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.469+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-30T00:00:00+00:00, run_after=2023-05-31T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.787+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.787+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.788+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.788+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.788+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.795+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.795+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.795+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.795+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.796+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:47.796+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.266+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.267+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.267+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.267+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.299+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-22T00:00:00+00:00 [queued]> to 5c0f1fcd-74ad-455c-8574-54fcb7835fec[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.299+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-23T00:00:00+00:00 [queued]> to ab5db7c3-1fe9-4f90-8a07-61e58caaf252[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.299+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:46.451155+00:00, run_end_date=2023-07-31 16:55:47.109209+00:00, run_duration=0.658054, state=success, executor_state=success, try_number=1, max_tries=1, job_id=154, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:44.515914+00:00, queued_by_job_id=4, pid=546[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.300+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-29T00:00:00+00:00 [queued]> to ff422666-f40f-42c4-afa1-9ef16a582ecb[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.359+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-31T00:00:00+00:00, run_after=2023-06-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.774+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.774+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.774+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.775+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.779+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.779+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.779+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:48.780+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.263+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.263+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.263+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.287+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-24T00:00:00+00:00 [queued]> to 54f189e5-ac29-4f07-85e7-3596dddd0076[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.287+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:47.281438+00:00, run_end_date=2023-07-31 16:55:47.917570+00:00, run_duration=0.636132, state=success, executor_state=success, try_number=1, max_tries=1, job_id=155, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:45.094721+00:00, queued_by_job_id=4, pid=554[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.287+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-30T00:00:00+00:00 [queued]> to 799b842f-afbd-4c90-b03a-adc6153c4032[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.348+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-01T00:00:00+00:00, run_after=2023-06-02T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.697+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-31T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-25T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.697+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.697+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.697+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.697+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-31T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-25T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.701+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.701+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.703+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.703+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.704+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:49.704+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.122+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.141+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-25T00:00:00+00:00 [queued]> to 47fb3fde-3708-4f66-b5e9-c0ba13ee7bc5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.143+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:47.956052+00:00, run_end_date=2023-07-31 16:55:48.895545+00:00, run_duration=0.939493, state=success, executor_state=success, try_number=1, max_tries=1, job_id=156, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:45.415294+00:00, queued_by_job_id=4, pid=566[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.144+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:48.188320+00:00, run_end_date=2023-07-31 16:55:48.916572+00:00, run_duration=0.728252, state=success, executor_state=success, try_number=1, max_tries=1, job_id=157, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:45.745581+00:00, queued_by_job_id=4, pid=567[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.144+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-26T00:00:00+00:00 [queued]> to 2a0f8fd1-e1f4-47b7-af84-6dc72391bd9f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.146+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-05-31T00:00:00+00:00 [queued]> to c398b3a3-119c-45ec-8031-1221a0635f5a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.233+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-02T00:00:00+00:00, run_after=2023-06-03T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.621+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-01T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.622+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.626+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-01T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.630+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.630+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.771+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.780+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-01T00:00:00+00:00 [queued]> to 653de843-af0b-4d87-9f96-227ea8a5a50a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:50.828+0000[0m] {[34mscheduler_job_runner.py:[0m1298} INFO[0m - DAG my_data_pipeline is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.458+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.466+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.466+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.466+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.466+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.466+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.482+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.482+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.482+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.483+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.483+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.483+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.490+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.490+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.913+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.914+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.934+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:49.450211+00:00, run_end_date=2023-07-31 16:55:50.406939+00:00, run_duration=0.956728, state=success, executor_state=success, try_number=1, max_tries=1, job_id=158, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:46.114634+00:00, queued_by_job_id=4, pid=576[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.934+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-18T00:00:00+00:00 [queued]> to 1bca0dee-cb06-4ef7-bba2-d2af4270ae05[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.934+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:50.728267+00:00, run_end_date=2023-07-31 16:55:51.336865+00:00, run_duration=0.608598, state=success, executor_state=success, try_number=1, max_tries=1, job_id=162, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:46.877930+00:00, queued_by_job_id=4, pid=587[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.934+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-27T00:00:00+00:00 [queued]> to af606eaa-2cba-48ac-87ec-df5849f29a11[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.935+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:49.447320+00:00, run_end_date=2023-07-31 16:55:50.429269+00:00, run_duration=0.981949, state=success, executor_state=success, try_number=1, max_tries=1, job_id=159, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:46.114634+00:00, queued_by_job_id=4, pid=577[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.935+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:50.378796+00:00, run_end_date=2023-07-31 16:55:51.278682+00:00, run_duration=0.899886, state=success, executor_state=success, try_number=1, max_tries=1, job_id=160, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:46.877930+00:00, queued_by_job_id=4, pid=584[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.935+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-28T00:00:00+00:00 [queued]> to 319cbc21-6721-402a-949c-5a09c83e4b25[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.935+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-02T00:00:00+00:00 [queued]> to 117fe636-c7ab-4a56-a790-0f0d0f844b9e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:51.935+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:50.720247+00:00, run_end_date=2023-07-31 16:55:51.428698+00:00, run_duration=0.708451, state=success, executor_state=success, try_number=1, max_tries=1, job_id=163, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:46.877930+00:00, queued_by_job_id=4, pid=588[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.407+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-20T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.408+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.408+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.408+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.408+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-20T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.417+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.417+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.417+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.417+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.417+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.417+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.763+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.763+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.763+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.763+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.763+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.763+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.764+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.793+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-19T00:00:00+00:00 [queued]> to 1e1b5216-4f60-44d9-b7a7-9f4d739b77fb[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.793+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-20T00:00:00+00:00 [queued]> to 89369587-59ff-49de-b97b-b4abdbcac3ed[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.793+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-21T00:00:00+00:00 [queued]> to da0911fb-c8c5-4511-a73c-55a5482aaf56[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.793+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:51.765319+00:00, run_end_date=2023-07-31 16:55:52.450423+00:00, run_duration=0.685104, state=success, executor_state=success, try_number=1, max_tries=1, job_id=165, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:47.790034+00:00, queued_by_job_id=4, pid=600[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.793+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:50.901697+00:00, run_end_date=2023-07-31 16:55:51.925194+00:00, run_duration=1.023497, state=success, executor_state=success, try_number=1, max_tries=1, job_id=161, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:46.877930+00:00, queued_by_job_id=4, pid=592[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.794+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:51.411861+00:00, run_end_date=2023-07-31 16:55:52.268077+00:00, run_duration=0.856216, state=success, executor_state=success, try_number=1, max_tries=1, job_id=166, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:47.790034+00:00, queued_by_job_id=4, pid=593[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:52.794+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:51.641792+00:00, run_end_date=2023-07-31 16:55:52.338888+00:00, run_duration=0.697096, state=success, executor_state=success, try_number=1, max_tries=1, job_id=164, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:47.790034+00:00, queued_by_job_id=4, pid=599[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:52 +0000] "GET /dags/my_data_pipeline/details HTTP/1.1" 200 46290 "http://localhost:8080/dags/my_data_pipeline/audit_log?root=" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.075+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.075+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.076+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.076+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.076+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.076+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-22T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.081+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.081+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.082+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.082+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.082+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.082+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.082+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.082+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.534+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.534+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.535+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.535+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.535+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.535+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.553+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:52.069518+00:00, run_end_date=2023-07-31 16:55:53.007983+00:00, run_duration=0.938465, state=success, executor_state=success, try_number=1, max_tries=1, job_id=167, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:48.776412+00:00, queued_by_job_id=4, pid=603[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.554+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-22T00:00:00+00:00 [queued]> to 17c2c6ff-44f4-41e0-86e8-93f1ceaeb6cf[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.554+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-23T00:00:00+00:00 [queued]> to bad57cfa-46f3-4dff-8fe6-3f77fd0b4fa8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.554+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-29T00:00:00+00:00 [queued]> to a2de70ae-120a-41b2-8675-317f8fe752c3[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.554+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:52.165826+00:00, run_end_date=2023-07-31 16:55:52.757020+00:00, run_duration=0.591194, state=success, executor_state=success, try_number=1, max_tries=1, job_id=168, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:48.776412+00:00, queued_by_job_id=4, pid=602[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.554+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-30T00:00:00+00:00 [queued]> to e798442b-4b23-4b2c-b3d4-135d268343f0[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /static/pin_32.png HTTP/1.1" 200 0 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:53 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.809+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.809+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.809+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.813+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.813+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:53.946+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.003+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-24T00:00:00+00:00 [queued]> to d09d9bee-9898-47c2-b8a0-03110e48b823[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.323+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.323+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.323+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.325+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.326+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.474+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-26T00:00:00+00:00 [queued]> to 3c73f329-44c9-462a-a322-46258dee4edd[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.474+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:52.813353+00:00, run_end_date=2023-07-31 16:55:53.835213+00:00, run_duration=1.02186, state=success, executor_state=success, try_number=1, max_tries=1, job_id=169, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:49.699299+00:00, queued_by_job_id=4, pid=609[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.707+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-31T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.707+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.708+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.708+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-31T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.716+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.716+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.716+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:54.716+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.162+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.162+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.162+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.162+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.162+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.211+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-25T00:00:00+00:00 [queued]> to 7fd70caa-8eb2-421b-87a7-15960ff27725[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.211+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-05-31T00:00:00+00:00 [queued]> to 360939e4-0450-48af-be05-5b605ac2fd67[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.211+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:53.917066+00:00, run_end_date=2023-07-31 16:55:54.690398+00:00, run_duration=0.773332, state=success, executor_state=success, try_number=1, max_tries=1, job_id=172, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:50.627268+00:00, queued_by_job_id=4, pid=622[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.211+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-05-31T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:52.827852+00:00, run_end_date=2023-07-31 16:55:54.143661+00:00, run_duration=1.315809, state=success, executor_state=success, try_number=1, max_tries=1, job_id=170, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:49.699299+00:00, queued_by_job_id=4, pid=610[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.211+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:53.147687+00:00, run_end_date=2023-07-31 16:55:54.111069+00:00, run_duration=0.963382, state=success, executor_state=success, try_number=1, max_tries=1, job_id=171, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:49.699299+00:00, queued_by_job_id=4, pid=614[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.477+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-01T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.477+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.477+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-01T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.480+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.480+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.593+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.610+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-01T00:00:00+00:00 [queued]> to 9af5da1f-b5b9-4259-b9a0-7a8e734fce01[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.858+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.859+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.859+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.859+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.862+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.863+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.863+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:55.863+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.154+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.172+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:54.989824+00:00, run_end_date=2023-07-31 16:55:55.577517+00:00, run_duration=0.587693, state=success, executor_state=success, try_number=1, max_tries=1, job_id=176, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:51.468537+00:00, queued_by_job_id=4, pid=632[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.173+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-27T00:00:00+00:00 [queued]> to 5b4f0736-19f0-499a-b0fe-e3a0f82fde5e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.173+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:55.150748+00:00, run_end_date=2023-07-31 16:55:55.857938+00:00, run_duration=0.70719, state=success, executor_state=success, try_number=1, max_tries=1, job_id=178, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:52.415104+00:00, queued_by_job_id=4, pid=635[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.173+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:54.983854+00:00, run_end_date=2023-07-31 16:55:55.482879+00:00, run_duration=0.499025, state=success, executor_state=success, try_number=1, max_tries=1, job_id=175, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:51.468537+00:00, queued_by_job_id=4, pid=629[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.173+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:55.089975+00:00, run_end_date=2023-07-31 16:55:55.779193+00:00, run_duration=0.689218, state=success, executor_state=success, try_number=1, max_tries=1, job_id=177, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:52.415104+00:00, queued_by_job_id=4, pid=633[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.174+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:54.980109+00:00, run_end_date=2023-07-31 16:55:55.664096+00:00, run_duration=0.683987, state=success, executor_state=success, try_number=1, max_tries=1, job_id=174, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:51.468537+00:00, queued_by_job_id=4, pid=630[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.174+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:54.779882+00:00, run_end_date=2023-07-31 16:55:55.426112+00:00, run_duration=0.64623, state=success, executor_state=success, try_number=1, max_tries=1, job_id=173, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:55:51.468537+00:00, queued_by_job_id=4, pid=627[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.174+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-02T00:00:00+00:00 [queued]> to adee556a-07af-4aa6-a328-b3363bfa0a5a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.232+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-18 00:00:00+00:00: scheduled__2023-05-18T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:43.316917+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.233+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-18 00:00:00+00:00, run_id=scheduled__2023-05-18T00:00:00+00:00, run_start_date=2023-07-31 16:55:43.343537+00:00, run_end_date=2023-07-31 16:55:56.233040+00:00, run_duration=12.889503, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-18 00:00:00+00:00, data_interval_end=2023-05-19 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.238+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-19T00:00:00+00:00, run_after=2023-05-20T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.244+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-21 00:00:00+00:00: scheduled__2023-05-21T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:43.912222+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.245+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-21 00:00:00+00:00, run_id=scheduled__2023-05-21T00:00:00+00:00, run_start_date=2023-07-31 16:55:43.934681+00:00, run_end_date=2023-07-31 16:55:56.245442+00:00, run_duration=12.310761, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-21 00:00:00+00:00, data_interval_end=2023-05-22 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.251+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-22T00:00:00+00:00, run_after=2023-05-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.258+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-19 00:00:00+00:00: scheduled__2023-05-19T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:43.502446+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.258+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-19 00:00:00+00:00, run_id=scheduled__2023-05-19T00:00:00+00:00, run_start_date=2023-07-31 16:55:43.534921+00:00, run_end_date=2023-07-31 16:55:56.258567+00:00, run_duration=12.723646, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-19 00:00:00+00:00, data_interval_end=2023-05-20 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.264+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-20T00:00:00+00:00, run_after=2023-05-21T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.274+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-20 00:00:00+00:00: scheduled__2023-05-20T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:43.707730+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.274+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-20 00:00:00+00:00, run_id=scheduled__2023-05-20T00:00:00+00:00, run_start_date=2023-07-31 16:55:43.736290+00:00, run_end_date=2023-07-31 16:55:56.274600+00:00, run_duration=12.53831, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-20 00:00:00+00:00, data_interval_end=2023-05-21 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.280+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-21T00:00:00+00:00, run_after=2023-05-22T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.382+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-28T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.382+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.382+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-28T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.385+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.385+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.454+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.454+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.460+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:55.509641+00:00, run_end_date=2023-07-31 16:55:56.069086+00:00, run_duration=0.559445, state=success, executor_state=success, try_number=1, max_tries=1, job_id=179, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:52.415104+00:00, queued_by_job_id=4, pid=637[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.460+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-28T00:00:00+00:00 [queued]> to 6bba81f0-6996-4a78-a7ac-f353b7f2759a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.486+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-22T00:00:00+00:00, run_after=2023-05-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.975+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-23T00:00:00+00:00, run_after=2023-05-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:56.999+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-24 00:00:00+00:00: scheduled__2023-05-24T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:44.814608+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.000+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-24 00:00:00+00:00, run_id=scheduled__2023-05-24T00:00:00+00:00, run_start_date=2023-07-31 16:55:44.887195+00:00, run_end_date=2023-07-31 16:55:56.999954+00:00, run_duration=12.112759, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-24 00:00:00+00:00, data_interval_end=2023-05-25 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.004+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-25T00:00:00+00:00, run_after=2023-05-26T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.024+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-22 00:00:00+00:00: scheduled__2023-05-22T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:44.144080+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.025+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-22 00:00:00+00:00, run_id=scheduled__2023-05-22T00:00:00+00:00, run_start_date=2023-07-31 16:55:44.160711+00:00, run_end_date=2023-07-31 16:55:57.024994+00:00, run_duration=12.864283, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-22 00:00:00+00:00, data_interval_end=2023-05-23 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.031+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-23T00:00:00+00:00, run_after=2023-05-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.110+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-30T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.110+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.110+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.111+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-30T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.114+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.114+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.114+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.114+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.284+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.284+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.284+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.284+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.284+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.284+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.284+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.299+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-29T00:00:00+00:00 [queued]> to 744568f3-4155-4f99-bd71-173e2154fd62[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.299+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:56.153263+00:00, run_end_date=2023-07-31 16:55:56.754150+00:00, run_duration=0.600887, state=success, executor_state=success, try_number=1, max_tries=1, job_id=180, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:53.810042+00:00, queued_by_job_id=4, pid=642[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.299+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:56.240554+00:00, run_end_date=2023-07-31 16:55:56.906253+00:00, run_duration=0.665699, state=success, executor_state=success, try_number=1, max_tries=1, job_id=183, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:53.078010+00:00, queued_by_job_id=4, pid=643[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.300+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:56.444663+00:00, run_end_date=2023-07-31 16:55:57.044791+00:00, run_duration=0.600128, state=success, executor_state=success, try_number=1, max_tries=1, job_id=184, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:53.078010+00:00, queued_by_job_id=4, pid=649[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.300+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:56.405379+00:00, run_end_date=2023-07-31 16:55:56.913508+00:00, run_duration=0.508129, state=success, executor_state=success, try_number=1, max_tries=1, job_id=181, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:53.078010+00:00, queued_by_job_id=4, pid=646[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.300+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:56.406940+00:00, run_end_date=2023-07-31 16:55:56.936437+00:00, run_duration=0.529497, state=success, executor_state=success, try_number=1, max_tries=1, job_id=182, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:53.078010+00:00, queued_by_job_id=4, pid=648[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.300+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-30T00:00:00+00:00 [queued]> to 9156f4d2-3076-4b8d-8884-9a75dc42808c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.378+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-24T00:00:00+00:00, run_after=2023-05-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.497+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-23 00:00:00+00:00: scheduled__2023-05-23T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:44.360719+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.498+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-23 00:00:00+00:00, run_id=scheduled__2023-05-23T00:00:00+00:00, run_start_date=2023-07-31 16:55:44.379988+00:00, run_end_date=2023-07-31 16:55:57.498017+00:00, run_duration=13.118029, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-23 00:00:00+00:00, data_interval_end=2023-05-24 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:57.505+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-24T00:00:00+00:00, run_after=2023-05-25T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:57 +0000] "GET /taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success HTTP/1.1" 200 474925 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.505+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-25T00:00:00+00:00, run_after=2023-05-26T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 0 "http://localhost:8080/static/appbuilder/css/fontawesome/solid.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:58 +0000] "GET /static/appbuilder/webfonts/fa-regular-400.woff2 HTTP/1.1" 200 0 "http://localhost:8080/static/appbuilder/css/fontawesome/regular.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.533+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-26 00:00:00+00:00: scheduled__2023-05-26T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:45.581383+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.536+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-26 00:00:00+00:00, run_id=scheduled__2023-05-26T00:00:00+00:00, run_start_date=2023-07-31 16:55:45.599258+00:00, run_end_date=2023-07-31 16:55:58.536568+00:00, run_duration=12.93731, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-26 00:00:00+00:00, data_interval_end=2023-05-27 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.540+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-27T00:00:00+00:00, run_after=2023-05-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.563+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-25 00:00:00+00:00: scheduled__2023-05-25T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:45.229162+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.564+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-25 00:00:00+00:00, run_id=scheduled__2023-05-25T00:00:00+00:00, run_start_date=2023-07-31 16:55:45.263449+00:00, run_end_date=2023-07-31 16:55:58.564058+00:00, run_duration=13.300609, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-25 00:00:00+00:00, data_interval_end=2023-05-26 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.571+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-26T00:00:00+00:00, run_after=2023-05-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.625+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-31T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.625+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.625+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.626+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.626+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-05-31T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.628+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.629+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-05-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.629+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.629+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.629+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.629+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.848+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.848+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.848+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.865+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:57.384800+00:00, run_end_date=2023-07-31 16:55:57.980101+00:00, run_duration=0.595301, state=success, executor_state=success, try_number=1, max_tries=1, job_id=186, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:54.709550+00:00, queued_by_job_id=4, pid=657[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.865+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:57.312387+00:00, run_end_date=2023-07-31 16:55:57.788400+00:00, run_duration=0.476013, state=success, executor_state=success, try_number=1, max_tries=1, job_id=185, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:54.323984+00:00, queued_by_job_id=4, pid=656[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.865+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:57.958008+00:00, run_end_date=2023-07-31 16:55:58.434177+00:00, run_duration=0.476169, state=success, executor_state=success, try_number=1, max_tries=1, job_id=189, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:56.383212+00:00, queued_by_job_id=4, pid=660[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.866+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-05-31T00:00:00+00:00 [queued]> to b559f5a0-7542-4f74-a820-846fd82079a7[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.866+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:58.052705+00:00, run_end_date=2023-07-31 16:55:58.464373+00:00, run_duration=0.411668, state=success, executor_state=success, try_number=1, max_tries=1, job_id=190, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:55.860497+00:00, queued_by_job_id=4, pid=663[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.866+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:57.621098+00:00, run_end_date=2023-07-31 16:55:58.059283+00:00, run_duration=0.438185, state=success, executor_state=success, try_number=1, max_tries=1, job_id=188, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:55.478080+00:00, queued_by_job_id=4, pid=659[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.866+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-05-31T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:57.564002+00:00, run_end_date=2023-07-31 16:55:58.103217+00:00, run_duration=0.539215, state=success, executor_state=success, try_number=1, max_tries=1, job_id=187, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:55:54.709550+00:00, queued_by_job_id=4, pid=658[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.866+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-01T00:00:00+00:00 [queued]> to e3e2b26e-985b-4399-b0d2-d01be7037f18[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.867+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-02T00:00:00+00:00 [queued]> to 2944bd75-e928-4ba3-a7fd-0777fa01fd6f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.898+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-27T00:00:00+00:00, run_after=2023-05-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.918+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-28 00:00:00+00:00: scheduled__2023-05-28T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:46.522196+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.918+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-28 00:00:00+00:00, run_id=scheduled__2023-05-28T00:00:00+00:00, run_start_date=2023-07-31 16:55:46.572944+00:00, run_end_date=2023-07-31 16:55:58.918639+00:00, run_duration=12.345695, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-28 00:00:00+00:00, data_interval_end=2023-05-29 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.922+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-29T00:00:00+00:00, run_after=2023-05-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.927+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-27 00:00:00+00:00: scheduled__2023-05-27T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:45.843759+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.927+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-27 00:00:00+00:00, run_id=scheduled__2023-05-27T00:00:00+00:00, run_start_date=2023-07-31 16:55:45.878410+00:00, run_end_date=2023-07-31 16:55:58.927912+00:00, run_duration=13.049502, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-27 00:00:00+00:00, data_interval_end=2023-05-28 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:55:58.932+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-28T00:00:00+00:00, run_after=2023-05-29T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:55:59 +0000] "GET /static/pin_32.png HTTP/1.1" 200 0 "http://localhost:8080/taskinstance/list/?_flt_3_dag_id=my_data_pipeline&_flt_3_state=success" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.016+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-29T00:00:00+00:00, run_after=2023-05-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.042+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-30 00:00:00+00:00: scheduled__2023-05-30T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:48.347181+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.043+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-30 00:00:00+00:00, run_id=scheduled__2023-05-30T00:00:00+00:00, run_start_date=2023-07-31 16:55:48.382648+00:00, run_end_date=2023-07-31 16:56:00.042915+00:00, run_duration=11.660267, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-30 00:00:00+00:00, data_interval_end=2023-05-31 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.046+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-31T00:00:00+00:00, run_after=2023-06-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.051+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-29 00:00:00+00:00: scheduled__2023-05-29T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:47.462573+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.052+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-29 00:00:00+00:00, run_id=scheduled__2023-05-29T00:00:00+00:00, run_start_date=2023-07-31 16:55:47.483460+00:00, run_end_date=2023-07-31 16:56:00.052655+00:00, run_duration=12.569195, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-29 00:00:00+00:00, data_interval_end=2023-05-30 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.056+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-30T00:00:00+00:00, run_after=2023-05-31T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.112+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.113+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.113+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.121+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:58.455374+00:00, run_end_date=2023-07-31 16:55:58.827756+00:00, run_duration=0.372382, state=success, executor_state=success, try_number=1, max_tries=1, job_id=191, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:55.860497+00:00, queued_by_job_id=4, pid=664[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.122+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:58.963075+00:00, run_end_date=2023-07-31 16:55:59.237313+00:00, run_duration=0.274238, state=success, executor_state=success, try_number=1, max_tries=1, job_id=193, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:57.111749+00:00, queued_by_job_id=4, pid=669[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:00.122+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:58.895036+00:00, run_end_date=2023-07-31 16:55:59.269533+00:00, run_duration=0.374497, state=success, executor_state=success, try_number=1, max_tries=1, job_id=192, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:57.111749+00:00, queued_by_job_id=4, pid=668[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.152+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-05-31T00:00:00+00:00, run_after=2023-06-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.184+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-01 00:00:00+00:00: scheduled__2023-06-01T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:50.222530+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.184+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-01 00:00:00+00:00, run_id=scheduled__2023-06-01T00:00:00+00:00, run_start_date=2023-07-31 16:55:50.256473+00:00, run_end_date=2023-07-31 16:56:01.184476+00:00, run_duration=10.928003, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-01 00:00:00+00:00, data_interval_end=2023-06-02 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.189+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-02T00:00:00+00:00, run_after=2023-06-03T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.199+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-05-31 00:00:00+00:00: scheduled__2023-05-31T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:49.342416+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.200+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-05-31 00:00:00+00:00, run_id=scheduled__2023-05-31T00:00:00+00:00, run_start_date=2023-07-31 16:55:49.372606+00:00, run_end_date=2023-07-31 16:56:01.200180+00:00, run_duration=11.827574, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-05-31 00:00:00+00:00, data_interval_end=2023-06-01 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.207+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-01T00:00:00+00:00, run_after=2023-06-02T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.216+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-02 00:00:00+00:00: scheduled__2023-06-02T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:55:50.815418+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.217+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-02 00:00:00+00:00, run_id=scheduled__2023-06-02T00:00:00+00:00, run_start_date=2023-07-31 16:55:50.854632+00:00, run_end_date=2023-07-31 16:56:01.217443+00:00, run_duration=10.362811, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-02 00:00:00+00:00, data_interval_end=2023-06-03 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.225+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-03T00:00:00+00:00, run_after=2023-06-04T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.259+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-05-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.259+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.259+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.265+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-05-31T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:59.888535+00:00, run_end_date=2023-07-31 16:56:00.112145+00:00, run_duration=0.22361, state=success, executor_state=success, try_number=1, max_tries=1, job_id=195, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:58.626804+00:00, queued_by_job_id=4, pid=674[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.266+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:59.906731+00:00, run_end_date=2023-07-31 16:56:00.143212+00:00, run_duration=0.236481, state=success, executor_state=success, try_number=1, max_tries=1, job_id=196, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:58.626804+00:00, queued_by_job_id=4, pid=675[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:01.266+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:55:59.883497+00:00, run_end_date=2023-07-31 16:56:00.089379+00:00, run_duration=0.205882, state=success, executor_state=success, try_number=1, max_tries=1, job_id=194, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:55:58.626804+00:00, queued_by_job_id=4, pid=673[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.312+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-04T00:00:00+00:00, run_after=2023-06-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.389+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.389+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.389+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.393+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.393+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.440+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.447+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-03T00:00:00+00:00 [queued]> to f605279f-8fd2-49a1-a932-66db10b00f06[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.506+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-05T00:00:00+00:00, run_after=2023-06-06T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.587+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.587+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.588+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.592+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.593+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.644+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.657+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-04T00:00:00+00:00 [queued]> to 0b054356-94d7-4952-bbb5-5acd5b2098ee[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.698+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-06T00:00:00+00:00, run_after=2023-06-07T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.783+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.783+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.783+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.788+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.788+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.836+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.846+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-05T00:00:00+00:00 [queued]> to 9eba5484-52b9-48f3-8c39-bd730949345b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.878+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-07T00:00:00+00:00, run_after=2023-06-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.997+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.997+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:02.997+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.002+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.002+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.066+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.090+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-06T00:00:00+00:00 [queued]> to 3bbf0c32-b5e0-40df-ae18-478e9562da72[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.127+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-08T00:00:00+00:00, run_after=2023-06-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.261+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.261+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.261+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.265+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.265+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.326+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.332+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-07T00:00:00+00:00 [queued]> to e2d51919-2925-4b5f-8d8a-aa97fb69fde5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.369+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-09T00:00:00+00:00, run_after=2023-06-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.480+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.480+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.480+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.483+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.484+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.529+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.536+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-08T00:00:00+00:00 [queued]> to 6a30398f-e7cb-4977-8fcd-3c383d9523e9[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.567+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-10T00:00:00+00:00, run_after=2023-06-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.710+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.710+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.711+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.713+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.714+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.776+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.782+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-09T00:00:00+00:00 [queued]> to 5b0539c2-e0d4-48e5-a342-716bcdca8462[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.815+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-11T00:00:00+00:00, run_after=2023-06-12T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.984+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.984+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.984+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.987+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:03.988+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.108+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.126+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-10T00:00:00+00:00 [queued]> to ea29406a-80ba-4945-b683-b31bc2479ac1[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.164+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-12T00:00:00+00:00, run_after=2023-06-13T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.366+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.366+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.367+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.370+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.370+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.427+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.435+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-11T00:00:00+00:00 [queued]> to 55c32e99-bdfd-48d7-af52-d5a0a986fe28[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.491+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-13T00:00:00+00:00, run_after=2023-06-14T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.741+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.741+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.741+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.750+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.750+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.865+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.877+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-12T00:00:00+00:00 [queued]> to 3d3280f3-f2a9-4b80-835e-4b1b4e8a3db4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:04.916+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-14T00:00:00+00:00, run_after=2023-06-15T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.160+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.160+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.160+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.160+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.165+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.165+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.165+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.165+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.360+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.360+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.360+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.374+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-03T00:00:00+00:00 [queued]> to b3cc5aad-4c3c-4af0-8d63-e0c838e588f2[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.374+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-13T00:00:00+00:00 [queued]> to af1d21f0-4d16-456d-8522-fff39a370ef5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.374+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:03.912027+00:00, run_end_date=2023-07-31 16:56:04.650924+00:00, run_duration=0.738897, state=success, executor_state=success, try_number=1, max_tries=1, job_id=197, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:02.390680+00:00, queued_by_job_id=4, pid=688[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.421+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-15T00:00:00+00:00, run_after=2023-06-16T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.702+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.703+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.703+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.703+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.703+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-04T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-05T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.708+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.708+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.708+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.708+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.708+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.709+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:05 +0000] "GET /object/next_run_datasets/my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.960+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.983+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:04.642980+00:00, run_end_date=2023-07-31 16:56:05.133500+00:00, run_duration=0.49052, state=success, executor_state=success, try_number=1, max_tries=1, job_id=199, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:02.784780+00:00, queued_by_job_id=4, pid=693[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.983+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:04.334758+00:00, run_end_date=2023-07-31 16:56:04.991097+00:00, run_duration=0.656339, state=success, executor_state=success, try_number=1, max_tries=1, job_id=198, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:02.589167+00:00, queued_by_job_id=4, pid=691[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.983+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:04.929836+00:00, run_end_date=2023-07-31 16:56:05.576426+00:00, run_duration=0.64659, state=success, executor_state=success, try_number=1, max_tries=1, job_id=200, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:02.998439+00:00, queued_by_job_id=4, pid=696[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.984+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-05T00:00:00+00:00 [queued]> to 95132f6e-b1fb-415b-a10f-71494156bc84[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.984+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-14T00:00:00+00:00 [queued]> to 6657c5fd-05b4-481e-87d4-3f7c3bed3a9b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:05.984+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-04T00:00:00+00:00 [queued]> to da1473d5-9be3-4c5d-8b45-e88b939a2d7c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.020+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-16T00:00:00+00:00, run_after=2023-06-17T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.269+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.269+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.270+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.270+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-06T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.274+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.274+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.274+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.274+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:56:06 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.478+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.479+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.491+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-06T00:00:00+00:00 [queued]> to dd19d919-cfc6-455e-8d4c-e9b72e61140b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.491+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-15T00:00:00+00:00 [queued]> to 82fa4836-3cc5-496f-a25a-261861d9755c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.551+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-17T00:00:00+00:00, run_after=2023-06-18T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.799+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-07T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.799+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.799+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.799+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.800+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-07T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.805+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.805+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.805+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.805+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.806+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:06.806+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.154+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.166+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-07T00:00:00+00:00 [queued]> to 09040d71-8b3c-4324-8456-e877bb08e9d9[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.166+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-08T00:00:00+00:00 [queued]> to 6f147f2f-2791-4d0a-a50c-23b96b877824[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.166+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:05.770809+00:00, run_end_date=2023-07-31 16:56:06.457168+00:00, run_duration=0.686359, state=success, executor_state=success, try_number=1, max_tries=1, job_id=202, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:03.481481+00:00, queued_by_job_id=4, pid=705[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.167+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-16T00:00:00+00:00 [queued]> to a591e565-7342-484c-a005-6e0cf35f8073[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.167+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:05.145409+00:00, run_end_date=2023-07-31 16:56:06.166590+00:00, run_duration=1.021181, state=success, executor_state=success, try_number=1, max_tries=1, job_id=201, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:03.262729+00:00, queued_by_job_id=4, pid=699[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.167+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:06.137884+00:00, run_end_date=2023-07-31 16:56:06.852982+00:00, run_duration=0.715098, state=success, executor_state=success, try_number=1, max_tries=1, job_id=203, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:03.711809+00:00, queued_by_job_id=4, pid=709[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.201+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-18T00:00:00+00:00, run_after=2023-06-19T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.528+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.529+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.529+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.529+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-09T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.533+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.533+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.533+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.534+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.953+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.953+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.953+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.971+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-09T00:00:00+00:00 [queued]> to 8190c1c2-9ed6-4c18-a669-fbc918d54b6a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.972+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:06.841642+00:00, run_end_date=2023-07-31 16:56:07.400602+00:00, run_duration=0.55896, state=success, executor_state=success, try_number=1, max_tries=1, job_id=204, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:04.367967+00:00, queued_by_job_id=4, pid=715[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:07.972+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-17T00:00:00+00:00 [queued]> to c3f23c5a-8212-4b6c-a28c-ce6ede8547d6[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.035+0000[0m] {[34mscheduler_job_runner.py:[0m1298} INFO[0m - DAG my_data_pipeline is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.320+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.320+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.320+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.320+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.324+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.325+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.325+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.325+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.567+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.567+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.567+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.574+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-11T00:00:00+00:00 [queued]> to 7550ce5e-68c0-4721-92bf-0e4c467d2a8f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.575+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:07.197505+00:00, run_end_date=2023-07-31 16:56:08.064759+00:00, run_duration=0.867254, state=success, executor_state=success, try_number=1, max_tries=1, job_id=205, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:03.985575+00:00, queued_by_job_id=4, pid=717[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.575+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-18T00:00:00+00:00 [queued]> to 80d4eaee-036f-4931-b1dc-b56cbc8084ff[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.827+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.827+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.827+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.827+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.827+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-10T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.837+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.837+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.837+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.837+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.838+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:08.838+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:56:09.153+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.191+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.192+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.192+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.192+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.192+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.207+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-03T00:00:00+00:00 [queued]> to 49fbcfed-81f7-48c8-9e30-02c55264185a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.207+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:07.636090+00:00, run_end_date=2023-07-31 16:56:08.358507+00:00, run_duration=0.722417, state=success, executor_state=success, try_number=1, max_tries=1, job_id=206, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:04.742385+00:00, queued_by_job_id=4, pid=721[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.207+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-10T00:00:00+00:00 [queued]> to 5c5b75d9-7662-4817-bc6b-a32663c9b71f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.207+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-12T00:00:00+00:00 [queued]> to 107cc5b5-3fbd-43c5-aa39-dee5f99f179c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.208+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:07.952546+00:00, run_end_date=2023-07-31 16:56:08.559523+00:00, run_duration=0.606977, state=success, executor_state=success, try_number=1, max_tries=1, job_id=207, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:05.162162+00:00, queued_by_job_id=4, pid=724[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /home HTTP/1.1" 200 426928 "http://localhost:8080/dags/my_data_pipeline/details" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.542+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-13T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.542+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.542+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-13T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.545+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.545+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.625+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.625+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.630+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-13T00:00:00+00:00 [queued]> to 809d13d6-ee8e-4324-822c-ce67dac61d69[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:09.630+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:08.005705+00:00, run_end_date=2023-07-31 16:56:08.928161+00:00, run_duration=0.922456, state=success, executor_state=success, try_number=1, max_tries=1, job_id=208, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:05.162162+00:00, queued_by_job_id=4, pid=727[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:09 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 200 0 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.080+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.080+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.080+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-04T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.082+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.083+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.227+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.227+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.232+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:08.684808+00:00, run_end_date=2023-07-31 16:56:09.508786+00:00, run_duration=0.823978, state=success, executor_state=success, try_number=1, max_tries=1, job_id=209, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:05.705114+00:00, queued_by_job_id=4, pid=733[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.233+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-04T00:00:00+00:00 [queued]> to 279188d9-8e54-40af-9a22-58a2aaf14b7a[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:10 +0000] "POST /last_dagruns HTTP/1.1" 200 340 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:10 +0000] "POST /task_stats HTTP/1.1" 200 26528 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:10 +0000] "POST /blocked HTTP/1.1" 200 77 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:10 +0000] "POST /dag_stats HTTP/1.1" 200 8278 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.560+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.560+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.560+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.563+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.564+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.718+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.718+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.724+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:09.040780+00:00, run_end_date=2023-07-31 16:56:09.677528+00:00, run_duration=0.636748, state=success, executor_state=success, try_number=1, max_tries=1, job_id=210, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:05.705114+00:00, queued_by_job_id=4, pid=737[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.724+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-14T00:00:00+00:00 [queued]> to 2e6bcc66-c712-45dd-97db-42c8b2d0bb05[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.967+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-06T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.967+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-06T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-08T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.971+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.971+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.971+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.971+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.972+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:10.972+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.410+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.411+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.425+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:10.056026+00:00, run_end_date=2023-07-31 16:56:10.880706+00:00, run_duration=0.82468, state=success, executor_state=success, try_number=1, max_tries=1, job_id=216, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:06.801706+00:00, queued_by_job_id=4, pid=746[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.425+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:09.650564+00:00, run_end_date=2023-07-31 16:56:10.738006+00:00, run_duration=1.087442, state=success, executor_state=success, try_number=1, max_tries=1, job_id=214, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:06.801706+00:00, queued_by_job_id=4, pid=744[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.425+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-08T00:00:00+00:00 [queued]> to 05e2145e-f10f-49e1-b2a8-765581e5070a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.426+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:10.063869+00:00, run_end_date=2023-07-31 16:56:10.861911+00:00, run_duration=0.798042, state=success, executor_state=success, try_number=1, max_tries=1, job_id=215, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:06.801706+00:00, queued_by_job_id=4, pid=747[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.426+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-06T00:00:00+00:00 [queued]> to 8eb60e60-b197-4a69-9525-8ba10943c273[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.426+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-15T00:00:00+00:00 [queued]> to 852abde3-a1a2-47ae-9a8c-440557f34da2[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.426+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:09.417590+00:00, run_end_date=2023-07-31 16:56:10.274444+00:00, run_duration=0.856854, state=success, executor_state=success, try_number=1, max_tries=1, job_id=213, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:06.271455+00:00, queued_by_job_id=4, pid=740[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.427+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:09.685088+00:00, run_end_date=2023-07-31 16:56:10.806788+00:00, run_duration=1.1217, state=success, executor_state=success, try_number=1, max_tries=1, job_id=212, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:05.705114+00:00, queued_by_job_id=4, pid=745[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.427+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:09.489915+00:00, run_end_date=2023-07-31 16:56:10.352452+00:00, run_duration=0.862537, state=success, executor_state=success, try_number=1, max_tries=1, job_id=211, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:06.271455+00:00, queued_by_job_id=4, pid=739[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.682+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-05T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.682+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.682+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.682+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.683+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-05T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-07T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.686+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.686+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.687+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.687+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.687+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:11.687+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.043+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.043+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.043+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.043+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.063+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:10.816046+00:00, run_end_date=2023-07-31 16:56:11.503781+00:00, run_duration=0.687735, state=success, executor_state=success, try_number=1, max_tries=1, job_id=219, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:08.321741+00:00, queued_by_job_id=4, pid=753[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.063+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-07T00:00:00+00:00 [queued]> to 51f4f0bd-90d7-4116-831b-99362ed90233[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.063+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-05T00:00:00+00:00 [queued]> to c0a4db22-fccd-48fd-8c3a-f68156763c2f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.063+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-16T00:00:00+00:00 [queued]> to 863ecd36-3cb5-4698-81fe-ab188e3376f5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.325+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-09T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.325+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.325+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.325+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.325+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.325+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-09T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-11T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.330+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.330+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.330+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.330+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.331+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.331+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.331+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.331+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.932+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.932+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.944+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:11.776595+00:00, run_end_date=2023-07-31 16:56:12.289235+00:00, run_duration=0.51264, state=success, executor_state=success, try_number=1, max_tries=1, job_id=221, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:08.828998+00:00, queued_by_job_id=4, pid=766[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.944+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:10.929614+00:00, run_end_date=2023-07-31 16:56:11.791945+00:00, run_duration=0.862331, state=success, executor_state=success, try_number=1, max_tries=1, job_id=217, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:07.530784+00:00, queued_by_job_id=4, pid=757[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.944+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-11T00:00:00+00:00 [queued]> to 36cf9bd2-f28a-4323-9398-e2124b56c774[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.945+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-09T00:00:00+00:00 [queued]> to 0b8bf141-e522-40e3-8a56-286a6ea2c4a3[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.945+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-18T00:00:00+00:00 [queued]> to 3e39c8dd-a4d7-4ee8-a8d7-8b6239b54bf9[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.945+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-17T00:00:00+00:00 [queued]> to b0212f55-7ab0-429b-8d68-f5b47b8b26ba[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.945+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:11.301390+00:00, run_end_date=2023-07-31 16:56:11.780419+00:00, run_duration=0.479029, state=success, executor_state=success, try_number=1, max_tries=1, job_id=220, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:08.321741+00:00, queued_by_job_id=4, pid=759[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.945+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:11.155870+00:00, run_end_date=2023-07-31 16:56:11.816439+00:00, run_duration=0.660569, state=success, executor_state=success, try_number=1, max_tries=1, job_id=218, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:07.530784+00:00, queued_by_job_id=4, pid=758[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.995+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-03 00:00:00+00:00: scheduled__2023-06-03T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:02.300509+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.995+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-03 00:00:00+00:00, run_id=scheduled__2023-06-03T00:00:00+00:00, run_start_date=2023-07-31 16:56:02.341996+00:00, run_end_date=2023-07-31 16:56:12.995661+00:00, run_duration=10.653665, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-03 00:00:00+00:00, data_interval_end=2023-06-04 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:12.999+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-04T00:00:00+00:00, run_after=2023-06-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.170+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.171+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.171+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-10T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.174+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.174+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.242+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.243+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.248+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:12.233519+00:00, run_end_date=2023-07-31 16:56:12.815071+00:00, run_duration=0.581552, state=success, executor_state=success, try_number=1, max_tries=1, job_id=222, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:08.828998+00:00, queued_by_job_id=4, pid=768[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.249+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-10T00:00:00+00:00 [queued]> to b5b0c166-884a-40af-b126-e283fc88c69f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.288+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-05T00:00:00+00:00, run_after=2023-06-06T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:13 +0000] "GET /home?status=active HTTP/1.1" 200 39279 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.533+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.533+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.534+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-12T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.539+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.539+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:13 +0000] "GET /home?status=active HTTP/1.1" 200 39279 "http://localhost:8080/home" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.678+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.678+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.687+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:12.543421+00:00, run_end_date=2023-07-31 16:56:13.271337+00:00, run_duration=0.727916, state=success, executor_state=success, try_number=1, max_tries=1, job_id=223, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:08.828998+00:00, queued_by_job_id=4, pid=773[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.687+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-12T00:00:00+00:00 [queued]> to 812b2642-c004-4177-b99e-babb0afc6f8c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:13.715+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-06T00:00:00+00:00, run_after=2023-06-07T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "POST /blocked HTTP/1.1" 200 77 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "POST /last_dagruns HTTP/1.1" 200 340 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "POST /task_stats HTTP/1.1" 200 522 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:14.916+0000[0m] {[34mscheduler_job_runner.py:[0m1298} INFO[0m - DAG my_data_pipeline is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:14 +0000] "POST /dag_stats HTTP/1.1" 200 158 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:14.974+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-04 00:00:00+00:00: scheduled__2023-06-04T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:02.495767+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:14.975+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-04 00:00:00+00:00, run_id=scheduled__2023-06-04T00:00:00+00:00, run_start_date=2023-07-31 16:56:02.522355+00:00, run_end_date=2023-07-31 16:56:14.975218+00:00, run_duration=12.452863, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-04 00:00:00+00:00, data_interval_end=2023-06-05 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:14.980+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-05T00:00:00+00:00, run_after=2023-06-06T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.123+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.123+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.123+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.123+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.123+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.123+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-13T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-14T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-15T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.128+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.128+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.129+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.129+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.129+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.129+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.129+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.129+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.551+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.551+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.552+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.552+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.552+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.552+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-04T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.552+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.552+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.574+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:13.504690+00:00, run_end_date=2023-07-31 16:56:14.221227+00:00, run_duration=0.716537, state=success, executor_state=success, try_number=1, max_tries=1, job_id=226, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:10.561362+00:00, queued_by_job_id=4, pid=784[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.575+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-13T00:00:00+00:00 [queued]> to 3a54e6b8-d9bb-422e-bac3-5df2c400448e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.575+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-14T00:00:00+00:00 [queued]> to 600a8bda-b457-4361-896f-4962d2430e0f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.575+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:13.701512+00:00, run_end_date=2023-07-31 16:56:14.791458+00:00, run_duration=1.089946, state=success, executor_state=success, try_number=1, max_tries=1, job_id=227, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:10.968950+00:00, queued_by_job_id=4, pid=785[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.576+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:13.120263+00:00, run_end_date=2023-07-31 16:56:13.931250+00:00, run_duration=0.810987, state=success, executor_state=success, try_number=1, max_tries=1, job_id=224, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:09.543174+00:00, queued_by_job_id=4, pid=779[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.576+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-04T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:13.334907+00:00, run_end_date=2023-07-31 16:56:14.145337+00:00, run_duration=0.81043, state=success, executor_state=success, try_number=1, max_tries=1, job_id=225, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:10.080952+00:00, queued_by_job_id=4, pid=781[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.576+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-19T00:00:00+00:00 [queued]> to 389935ea-0ac7-4cf7-bbd1-0ec180d31fc0[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.576+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-15T00:00:00+00:00 [queued]> to 7939679f-1bf6-429c-bf99-a1506e5afe36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.611+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-06T00:00:00+00:00, run_after=2023-06-07T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.651+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-08 00:00:00+00:00: scheduled__2023-06-08T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:03.363878+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.654+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-08 00:00:00+00:00, run_id=scheduled__2023-06-08T00:00:00+00:00, run_start_date=2023-07-31 16:56:03.381522+00:00, run_end_date=2023-07-31 16:56:15.653861+00:00, run_duration=12.272339, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-08 00:00:00+00:00, data_interval_end=2023-06-09 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.659+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-09T00:00:00+00:00, run_after=2023-06-10T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.856+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.856+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.857+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-16T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.860+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:15.860+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.031+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.031+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-08T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.031+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.038+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-08T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:14.656398+00:00, run_end_date=2023-07-31 16:56:15.407592+00:00, run_duration=0.751194, state=success, executor_state=success, try_number=1, max_tries=1, job_id=229, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:10.968950+00:00, queued_by_job_id=4, pid=790[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.039+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-16T00:00:00+00:00 [queued]> to e2e5ca8b-984e-44ad-b2e3-83dd72da6949[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.042+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:14.638549+00:00, run_end_date=2023-07-31 16:56:15.421332+00:00, run_duration=0.782783, state=success, executor_state=success, try_number=1, max_tries=1, job_id=228, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:11.684338+00:00, queued_by_job_id=4, pid=789[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.100+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-10T00:00:00+00:00, run_after=2023-06-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.250+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-07 00:00:00+00:00: scheduled__2023-06-07T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:03.120267+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.250+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-07 00:00:00+00:00, run_id=scheduled__2023-06-07T00:00:00+00:00, run_start_date=2023-07-31 16:56:03.141016+00:00, run_end_date=2023-07-31 16:56:16.250439+00:00, run_duration=13.109423, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-07 00:00:00+00:00, data_interval_end=2023-06-08 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.268+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-08T00:00:00+00:00, run_after=2023-06-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.276+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-06 00:00:00+00:00: scheduled__2023-06-06T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:02.871939+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.276+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-06 00:00:00+00:00, run_id=scheduled__2023-06-06T00:00:00+00:00, run_start_date=2023-07-31 16:56:02.891765+00:00, run_end_date=2023-07-31 16:56:16.276325+00:00, run_duration=13.38456, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-06 00:00:00+00:00, data_interval_end=2023-06-07 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.289+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-07T00:00:00+00:00, run_after=2023-06-08T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.493+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-07T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:16.501+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-07T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:15.242046+00:00, run_end_date=2023-07-31 16:56:15.894961+00:00, run_duration=0.652915, state=success, executor_state=success, try_number=1, max_tries=1, job_id=230, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:11.684338+00:00, queued_by_job_id=4, pid=797[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.551+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-08T00:00:00+00:00, run_after=2023-06-09T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.630+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-09 00:00:00+00:00: scheduled__2023-06-09T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:03.561780+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.631+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-09 00:00:00+00:00, run_id=scheduled__2023-06-09T00:00:00+00:00, run_start_date=2023-07-31 16:56:03.582906+00:00, run_end_date=2023-07-31 16:56:17.631046+00:00, run_duration=14.04814, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-09 00:00:00+00:00, data_interval_end=2023-06-10 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.636+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-10T00:00:00+00:00, run_after=2023-06-11T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.643+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-05 00:00:00+00:00: scheduled__2023-06-05T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:02.688185+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.644+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-05 00:00:00+00:00, run_id=scheduled__2023-06-05T00:00:00+00:00, run_start_date=2023-07-31 16:56:02.716946+00:00, run_end_date=2023-07-31 16:56:17.644421+00:00, run_duration=14.927475, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-05 00:00:00+00:00, data_interval_end=2023-06-06 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.650+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-06T00:00:00+00:00, run_after=2023-06-07T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.657+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-11 00:00:00+00:00: scheduled__2023-06-11T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:04.154594+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.657+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-11 00:00:00+00:00, run_id=scheduled__2023-06-11T00:00:00+00:00, run_start_date=2023-07-31 16:56:04.181049+00:00, run_end_date=2023-07-31 16:56:17.657642+00:00, run_duration=13.476593, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-11 00:00:00+00:00, data_interval_end=2023-06-12 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.662+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-12T00:00:00+00:00, run_after=2023-06-13T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.669+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-10 00:00:00+00:00: scheduled__2023-06-10T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:03.809270+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.669+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-10 00:00:00+00:00, run_id=scheduled__2023-06-10T00:00:00+00:00, run_start_date=2023-07-31 16:56:03.833862+00:00, run_end_date=2023-07-31 16:56:17.669849+00:00, run_duration=13.835987, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-10 00:00:00+00:00, data_interval_end=2023-06-11 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.675+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-11T00:00:00+00:00, run_after=2023-06-12T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.716+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-12 00:00:00+00:00: scheduled__2023-06-12T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:04.479223+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.716+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-12 00:00:00+00:00, run_id=scheduled__2023-06-12T00:00:00+00:00, run_start_date=2023-07-31 16:56:04.515062+00:00, run_end_date=2023-07-31 16:56:17.716643+00:00, run_duration=13.201581, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-12 00:00:00+00:00, data_interval_end=2023-06-13 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.723+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-13T00:00:00+00:00, run_after=2023-06-14T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.763+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.763+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.763+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.764+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-17T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-18T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.767+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.767+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.767+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.767+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.941+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-06T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-05T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-09T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-11T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-10T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-12T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.942+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-15T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.969+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-11T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:15.981874+00:00, run_end_date=2023-07-31 16:56:16.795075+00:00, run_duration=0.813201, state=success, executor_state=success, try_number=1, max_tries=1, job_id=235, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:12.327479+00:00, queued_by_job_id=4, pid=803[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.969+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-12T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:17.211171+00:00, run_end_date=2023-07-31 16:56:17.613187+00:00, run_duration=0.402016, state=success, executor_state=success, try_number=1, max_tries=1, job_id=238, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:13.535677+00:00, queued_by_job_id=4, pid=811[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.969+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-10T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:16.533145+00:00, run_end_date=2023-07-31 16:56:17.158847+00:00, run_duration=0.625702, state=success, executor_state=success, try_number=1, max_tries=1, job_id=237, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:13.171898+00:00, queued_by_job_id=4, pid=806[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.969+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-09T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:15.849075+00:00, run_end_date=2023-07-31 16:56:16.567460+00:00, run_duration=0.718385, state=success, executor_state=success, try_number=1, max_tries=1, job_id=233, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:12.327479+00:00, queued_by_job_id=4, pid=802[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.970+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:16.529083+00:00, run_end_date=2023-07-31 16:56:17.223499+00:00, run_duration=0.694416, state=success, executor_state=success, try_number=1, max_tries=1, job_id=236, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:12.327479+00:00, queued_by_job_id=4, pid=807[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.970+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-06T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:15.292890+00:00, run_end_date=2023-07-31 16:56:16.204321+00:00, run_duration=0.911431, state=success, executor_state=success, try_number=1, max_tries=1, job_id=232, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:10.968950+00:00, queued_by_job_id=4, pid=798[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.970+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-05T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:15.104260+00:00, run_end_date=2023-07-31 16:56:16.155180+00:00, run_duration=1.05092, state=success, executor_state=success, try_number=1, max_tries=1, job_id=231, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:11.684338+00:00, queued_by_job_id=4, pid=795[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.970+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:15.643992+00:00, run_end_date=2023-07-31 16:56:16.568944+00:00, run_duration=0.924952, state=success, executor_state=success, try_number=1, max_tries=1, job_id=234, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:12.327479+00:00, queued_by_job_id=4, pid=799[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.970+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-17T00:00:00+00:00 [queued]> to 9e4c4958-274d-4ac2-962b-db6bf0c73425[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.970+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-18T00:00:00+00:00 [queued]> to 317d936a-f669-43ee-bfa6-fe4452ad9040[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:17.970+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-15T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:17.432268+00:00, run_end_date=2023-07-31 16:56:17.750992+00:00, run_duration=0.318724, state=success, executor_state=success, try_number=1, max_tries=1, job_id=239, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:15.125640+00:00, queued_by_job_id=4, pid=812[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.001+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-14T00:00:00+00:00, run_after=2023-06-15T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.045+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-15 00:00:00+00:00: scheduled__2023-06-15T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:06.012660+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.045+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-15 00:00:00+00:00, run_id=scheduled__2023-06-15T00:00:00+00:00, run_start_date=2023-07-31 16:56:06.036833+00:00, run_end_date=2023-07-31 16:56:18.045541+00:00, run_duration=12.008708, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-15 00:00:00+00:00, data_interval_end=2023-06-16 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.050+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-16T00:00:00+00:00, run_after=2023-06-17T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.056+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-14 00:00:00+00:00: scheduled__2023-06-14T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:05.412772+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.056+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-14 00:00:00+00:00, run_id=scheduled__2023-06-14T00:00:00+00:00, run_start_date=2023-07-31 16:56:05.449369+00:00, run_end_date=2023-07-31 16:56:18.056340+00:00, run_duration=12.606971, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-14 00:00:00+00:00, data_interval_end=2023-06-15 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.060+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-15T00:00:00+00:00, run_after=2023-06-16T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.066+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-13 00:00:00+00:00: scheduled__2023-06-13T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:04.909602+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.067+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-13 00:00:00+00:00, run_id=scheduled__2023-06-13T00:00:00+00:00, run_start_date=2023-07-31 16:56:04.932112+00:00, run_end_date=2023-07-31 16:56:18.067083+00:00, run_duration=13.134971, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-13 00:00:00+00:00, data_interval_end=2023-06-14 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.071+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-14T00:00:00+00:00, run_after=2023-06-15T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.115+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-13T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.117+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-14T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.123+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-13T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:17.566359+00:00, run_end_date=2023-07-31 16:56:17.905763+00:00, run_duration=0.339404, state=success, executor_state=success, try_number=1, max_tries=1, job_id=241, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:15.125640+00:00, queued_by_job_id=4, pid=814[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.123+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-14T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:17.495441+00:00, run_end_date=2023-07-31 16:56:17.837844+00:00, run_duration=0.342403, state=success, executor_state=success, try_number=1, max_tries=1, job_id=240, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:15.125640+00:00, queued_by_job_id=4, pid=813[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.288+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-15T00:00:00+00:00, run_after=2023-06-16T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.309+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-16 00:00:00+00:00: scheduled__2023-06-16T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:06.540554+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.310+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-16 00:00:00+00:00, run_id=scheduled__2023-06-16T00:00:00+00:00, run_start_date=2023-07-31 16:56:06.570237+00:00, run_end_date=2023-07-31 16:56:18.310258+00:00, run_duration=11.740021, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-16 00:00:00+00:00, data_interval_end=2023-06-17 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.313+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-17T00:00:00+00:00, run_after=2023-06-18T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.352+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.352+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.352+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.354+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.355+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.392+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.392+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.392+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-16T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.398+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-16T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:17.799309+00:00, run_end_date=2023-07-31 16:56:18.088645+00:00, run_duration=0.289336, state=success, executor_state=success, try_number=1, max_tries=1, job_id=242, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:15.857904+00:00, queued_by_job_id=4, pid=817[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.398+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-19T00:00:00+00:00 [queued]> to bc989620-414a-47bf-bd6a-ec456d76833e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.399+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:17.820026+00:00, run_end_date=2023-07-31 16:56:18.156227+00:00, run_duration=0.336201, state=success, executor_state=success, try_number=1, max_tries=1, job_id=243, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:15.125640+00:00, queued_by_job_id=4, pid=818[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:18.430+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-18T00:00:00+00:00, run_after=2023-06-19T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.520+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-19T00:00:00+00:00, run_after=2023-06-20T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.549+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-17 00:00:00+00:00: scheduled__2023-06-17T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:07.195614+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.550+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-17 00:00:00+00:00, run_id=scheduled__2023-06-17T00:00:00+00:00, run_start_date=2023-07-31 16:56:07.213579+00:00, run_end_date=2023-07-31 16:56:19.549971+00:00, run_duration=12.336392, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-17 00:00:00+00:00, data_interval_end=2023-06-18 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.554+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-18T00:00:00+00:00, run_after=2023-06-19T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.559+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-18 00:00:00+00:00: scheduled__2023-06-18T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:08.029729+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.559+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-18 00:00:00+00:00, run_id=scheduled__2023-06-18T00:00:00+00:00, run_start_date=2023-07-31 16:56:08.067359+00:00, run_end_date=2023-07-31 16:56:19.559661+00:00, run_duration=11.492302, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-18 00:00:00+00:00, data_interval_end=2023-06-19 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.565+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-19T00:00:00+00:00, run_after=2023-06-20T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.579+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.579+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.580+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-19T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.583+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.583+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.624+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.624+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-17T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.624+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-18T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.624+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.636+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-17T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:18.837510+00:00, run_end_date=2023-07-31 16:56:19.024062+00:00, run_duration=0.186552, state=success, executor_state=success, try_number=1, max_tries=1, job_id=244, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:17.764824+00:00, queued_by_job_id=4, pid=823[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.637+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-19T00:00:00+00:00 [queued]> to de7f2495-4265-44b2-816c-8e401c704d11[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.637+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-18T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:18.860326+00:00, run_end_date=2023-07-31 16:56:19.030267+00:00, run_duration=0.169941, state=success, executor_state=success, try_number=1, max_tries=1, job_id=245, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:17.764824+00:00, queued_by_job_id=4, pid=824[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.637+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:19.280163+00:00, run_end_date=2023-07-31 16:56:19.456332+00:00, run_duration=0.176169, state=success, executor_state=success, try_number=1, max_tries=1, job_id=246, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:18.352969+00:00, queued_by_job_id=4, pid=825[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:19.672+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-20T00:00:00+00:00, run_after=2023-06-21T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.741+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-21T00:00:00+00:00, run_after=2023-06-22T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.771+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-19 00:00:00+00:00: scheduled__2023-06-19T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:14.911095+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.771+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-19 00:00:00+00:00, run_id=scheduled__2023-06-19T00:00:00+00:00, run_start_date=2023-07-31 16:56:14.936613+00:00, run_end_date=2023-07-31 16:56:20.771608+00:00, run_duration=5.834995, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-19 00:00:00+00:00, data_interval_end=2023-06-20 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.774+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-20T00:00:00+00:00, run_after=2023-06-21T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.787+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.787+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.787+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.789+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.789+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.826+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.826+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-19T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.840+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-19T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:20.383919+00:00, run_end_date=2023-07-31 16:56:20.577537+00:00, run_duration=0.193618, state=success, executor_state=success, try_number=1, max_tries=1, job_id=247, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:19.580593+00:00, queued_by_job_id=4, pid=828[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.840+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-20T00:00:00+00:00 [queued]> to 7085540b-822a-43e1-9aa9-52b86e714df2[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:20 +0000] "POST /task_stats HTTP/1.1" 200 521 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:20.866+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-21T00:00:00+00:00, run_after=2023-06-22T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:20 +0000] "POST /dag_stats HTTP/1.1" 200 157 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:20 +0000] "POST /last_dagruns HTTP/1.1" 200 340 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:20 +0000] "POST /next_run_datasets_summary HTTP/1.1" 200 2 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:21.940+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-22T00:00:00+00:00, run_after=2023-06-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.037+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.037+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.037+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.037+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.040+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.041+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.041+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.041+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.288+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.288+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.290+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.306+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-21T00:00:00+00:00 [queued]> to 8d8f7940-8fbb-442e-9230-c4b98d76eacf[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.307+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:21.686481+00:00, run_end_date=2023-07-31 16:56:21.876686+00:00, run_duration=0.190205, state=success, executor_state=success, try_number=1, max_tries=1, job_id=248, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:20.787891+00:00, queued_by_job_id=4, pid=831[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.307+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-20T00:00:00+00:00 [queued]> to 7b3fdb38-725a-4674-95f1-48fd0ea3377a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.348+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-23T00:00:00+00:00, run_after=2023-06-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.482+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.482+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.482+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.486+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.487+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.559+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.574+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-22T00:00:00+00:00 [queued]> to 2fb0e231-5162-46fb-885f-beea624cf096[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.621+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-24T00:00:00+00:00, run_after=2023-06-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.727+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.727+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.728+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.730+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.730+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.776+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.787+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-23T00:00:00+00:00 [queued]> to 7d138d33-465e-48d7-a03f-b9a850f98a4d[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.824+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-25T00:00:00+00:00, run_after=2023-06-26T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.926+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.927+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.927+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.930+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.931+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.988+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:22.996+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-24T00:00:00+00:00 [queued]> to fae3fe68-389c-46d5-8419-52bc6f52a95b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.029+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-26T00:00:00+00:00, run_after=2023-06-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.170+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.170+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.170+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.175+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.175+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.244+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.255+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-25T00:00:00+00:00 [queued]> to 5eada65b-9759-499f-a70b-2b02bb4d3800[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.301+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-27T00:00:00+00:00, run_after=2023-06-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.444+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.444+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.444+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.448+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.448+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.486+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.495+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-26T00:00:00+00:00 [queued]> to 51c3bc7d-2fc7-4750-b3c4-de2ad70744ba[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.556+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-28T00:00:00+00:00, run_after=2023-06-29T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.720+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.720+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.720+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.723+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.723+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.784+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.789+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-27T00:00:00+00:00 [queued]> to b2a4b49f-8013-4e43-910d-4a0ac2defc45[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.821+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-29T00:00:00+00:00, run_after=2023-06-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.966+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.967+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.967+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-20T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.971+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.971+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.972+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.972+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.972+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:23.972+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.291+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.291+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.291+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.291+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.291+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.340+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:23.316660+00:00, run_end_date=2023-07-31 16:56:23.818308+00:00, run_duration=0.501648, state=success, executor_state=success, try_number=1, max_tries=1, job_id=249, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:22.038890+00:00, queued_by_job_id=4, pid=842[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.340+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-20T00:00:00+00:00 [queued]> to f2deada9-ccda-4da5-9e26-b54c761add85[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.340+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:23.326516+00:00, run_end_date=2023-07-31 16:56:23.794475+00:00, run_duration=0.467959, state=success, executor_state=success, try_number=1, max_tries=1, job_id=250, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:22.038890+00:00, queued_by_job_id=4, pid=843[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.340+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-28T00:00:00+00:00 [queued]> to b1c83fbd-b9c0-41e4-9d73-de587815adae[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.341+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-21T00:00:00+00:00 [queued]> to dbc6572d-f541-4e84-9830-c12c7a101b70[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.422+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-30T00:00:00+00:00, run_after=2023-07-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.611+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.611+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.611+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.612+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.615+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.616+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.616+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.616+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.961+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.969+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-29T00:00:00+00:00 [queued]> to 8aa6be97-1506-44ea-b629-2b3fcfbfe668[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.970+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-22T00:00:00+00:00 [queued]> to 75f95d53-e914-4eff-b744-33eee4a36c42[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:24.970+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:23.875850+00:00, run_end_date=2023-07-31 16:56:24.465838+00:00, run_duration=0.589988, state=success, executor_state=success, try_number=1, max_tries=1, job_id=251, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:22.483170+00:00, queued_by_job_id=4, pid=854[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.014+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-01T00:00:00+00:00, run_after=2023-07-02T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.220+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.220+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.221+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.221+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.224+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.224+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.224+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.225+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.428+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.428+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.428+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.441+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:24.435972+00:00, run_end_date=2023-07-31 16:56:25.032661+00:00, run_duration=0.596689, state=success, executor_state=success, try_number=1, max_tries=1, job_id=252, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:22.728690+00:00, queued_by_job_id=4, pid=861[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.442+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-06-30T00:00:00+00:00 [queued]> to e74aa009-8cfe-4dad-adb0-22cce62ad48a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.442+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-23T00:00:00+00:00 [queued]> to ebf11168-e032-4153-9ad1-5a7e6ffa20c9[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.482+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-02T00:00:00+00:00, run_after=2023-07-03T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.741+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.741+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.741+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.741+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.745+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.745+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.745+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.745+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.923+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.924+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.924+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.931+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-01T00:00:00+00:00 [queued]> to 725dd590-1bf8-4e39-a913-45a0ff3f92ef[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.931+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:24.508114+00:00, run_end_date=2023-07-31 16:56:25.174267+00:00, run_duration=0.666153, state=success, executor_state=success, try_number=1, max_tries=1, job_id=253, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:22.928201+00:00, queued_by_job_id=4, pid=862[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.931+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-24T00:00:00+00:00 [queued]> to 284983ec-8863-4970-8e1a-045d88027b8c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:25.985+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-03T00:00:00+00:00, run_after=2023-07-04T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.210+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.210+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.210+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.210+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.214+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.214+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.214+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.214+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.451+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.451+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.451+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.452+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.474+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-25T00:00:00+00:00 [queued]> to fa3a6dc7-b74a-4b7f-ae24-01c4d01621e5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.474+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:24.880272+00:00, run_end_date=2023-07-31 16:56:25.681637+00:00, run_duration=0.801365, state=success, executor_state=success, try_number=1, max_tries=1, job_id=254, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:23.171211+00:00, queued_by_job_id=4, pid=868[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.474+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:25.409749+00:00, run_end_date=2023-07-31 16:56:26.043444+00:00, run_duration=0.633695, state=success, executor_state=success, try_number=1, max_tries=1, job_id=255, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:23.445402+00:00, queued_by_job_id=4, pid=872[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.474+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-02T00:00:00+00:00 [queued]> to 9fd3dcc9-56e8-4101-896c-e8923943b451[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.507+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-04T00:00:00+00:00, run_after=2023-07-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.547+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-20 00:00:00+00:00: scheduled__2023-06-20T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:20.737888+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.547+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-20 00:00:00+00:00, run_id=scheduled__2023-06-20T00:00:00+00:00, run_start_date=2023-07-31 16:56:20.751353+00:00, run_end_date=2023-07-31 16:56:26.547820+00:00, run_duration=5.796467, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-20 00:00:00+00:00, data_interval_end=2023-06-21 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.552+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-21T00:00:00+00:00, run_after=2023-06-22T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.690+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.690+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.691+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.691+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.691+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.695+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.695+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'extract_data', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.696+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.696+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.696+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:26.696+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:26 +0000] "POST /last_dagruns HTTP/1.1" 200 340 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:26 +0000] "POST /dag_stats HTTP/1.1" 200 158 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:26 +0000] "POST /task_stats HTTP/1.1" 200 523 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:26 +0000] "POST /next_run_datasets_summary HTTP/1.1" 200 2 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.120+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.121+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-20T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.143+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-20T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:25.675423+00:00, run_end_date=2023-07-31 16:56:26.293388+00:00, run_duration=0.617965, state=success, executor_state=success, try_number=1, max_tries=1, job_id=257, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:23.968786+00:00, queued_by_job_id=4, pid=874[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.143+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-26T00:00:00+00:00 [queued]> to 5546373c-4fac-4879-ae74-6455f6752c1d[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.144+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-27T00:00:00+00:00 [queued]> to 645ce975-5cb2-449a-a9d8-acb87af7bad7[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.144+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:26.195215+00:00, run_end_date=2023-07-31 16:56:26.761075+00:00, run_duration=0.56586, state=success, executor_state=success, try_number=1, max_tries=1, job_id=259, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:23.968786+00:00, queued_by_job_id=4, pid=880[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.144+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:25.799606+00:00, run_end_date=2023-07-31 16:56:26.475144+00:00, run_duration=0.675538, state=success, executor_state=success, try_number=1, max_tries=1, job_id=256, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:23.721163+00:00, queued_by_job_id=4, pid=877[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.144+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.extract_data scheduled__2023-07-03T00:00:00+00:00 [queued]> to 156bdde1-cc7c-4d8e-91ce-2ed2b12343f8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.168+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-22T00:00:00+00:00, run_after=2023-06-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.372+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.373+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.374+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.374+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-21T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.377+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.378+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.378+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.378+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.593+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.594+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.594+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.601+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-21T00:00:00+00:00 [queued]> to 7c0e5047-1ccd-40f8-9bf0-4ca88a4fbcbe[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.602+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-28T00:00:00+00:00 [queued]> to 7eac23d5-a20a-4a83-9e2c-342ddbff93ed[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.603+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:26.002045+00:00, run_end_date=2023-07-31 16:56:26.871015+00:00, run_duration=0.86897, state=success, executor_state=success, try_number=1, max_tries=1, job_id=258, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:23.968786+00:00, queued_by_job_id=4, pid=878[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.635+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-23T00:00:00+00:00, run_after=2023-06-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.858+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.858+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.859+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-22T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.861+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.862+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-22T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.925+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.926+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.932+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:26.810417+00:00, run_end_date=2023-07-31 16:56:27.465769+00:00, run_duration=0.655352, state=success, executor_state=success, try_number=1, max_tries=1, job_id=260, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:24.613101+00:00, queued_by_job_id=4, pid=888[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.932+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-22T00:00:00+00:00 [queued]> to fb7cb166-363d-4311-9963-d7fbb1600176[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:27.970+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-24T00:00:00+00:00, run_after=2023-06-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.565+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-25T00:00:00+00:00, run_after=2023-06-26T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.847+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.847+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.847+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.850+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.851+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.933+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.940+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-30T00:00:00+00:00 [queued]> to 55ec695f-748b-4db0-b0be-60228dd2e732[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.940+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:27.809315+00:00, run_end_date=2023-07-31 16:56:28.472433+00:00, run_duration=0.663118, state=success, executor_state=success, try_number=1, max_tries=1, job_id=261, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:25.222178+00:00, queued_by_job_id=4, pid=895[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:28.983+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-26T00:00:00+00:00, run_after=2023-06-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.160+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.161+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.161+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.161+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.161+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-23T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.166+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.166+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.166+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.166+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.166+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.166+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-23T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.592+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.592+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.592+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.593+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.593+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.593+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.612+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-06-29T00:00:00+00:00 [queued]> to 1bd8af45-0655-4e75-9273-17cb675feb1c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.612+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-06-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:28.231496+00:00, run_end_date=2023-07-31 16:56:28.806601+00:00, run_duration=0.575105, state=success, executor_state=success, try_number=1, max_tries=1, job_id=262, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:24.613101+00:00, queued_by_job_id=4, pid=901[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.612+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:28.166068+00:00, run_end_date=2023-07-31 16:56:28.825548+00:00, run_duration=0.65948, state=success, executor_state=success, try_number=1, max_tries=1, job_id=264, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:25.222178+00:00, queued_by_job_id=4, pid=899[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.612+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-07-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:28.046705+00:00, run_end_date=2023-07-31 16:56:28.816609+00:00, run_duration=0.769904, state=success, executor_state=success, try_number=1, max_tries=1, job_id=263, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:25.742971+00:00, queued_by_job_id=4, pid=900[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.613+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-01T00:00:00+00:00 [queued]> to 9c9b9dcc-4e62-405f-830e-3d2dc8a4aea4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.613+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-23T00:00:00+00:00 [queued]> to 43f24e95-05a4-49aa-8227-0ea390fac986[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.663+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-27T00:00:00+00:00, run_after=2023-06-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.856+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.856+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.856+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.856+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.856+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-24T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-25T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.860+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.860+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.861+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.861+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-24T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.861+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:29.861+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.158+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.158+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.158+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.158+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.159+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.159+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.159+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='extract_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.175+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-25T00:00:00+00:00 [queued]> to 51beff81-bf58-4b97-9b34-12f8e0f83748[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.175+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:28.658887+00:00, run_end_date=2023-07-31 16:56:29.376855+00:00, run_duration=0.717968, state=success, executor_state=success, try_number=1, max_tries=1, job_id=266, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:25.742971+00:00, queued_by_job_id=4, pid=905[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.175+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:28.668105+00:00, run_end_date=2023-07-31 16:56:29.469229+00:00, run_duration=0.801124, state=success, executor_state=success, try_number=1, max_tries=1, job_id=265, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:26.211707+00:00, queued_by_job_id=4, pid=904[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.175+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-24T00:00:00+00:00 [queued]> to bd177364-f6c2-4989-ac0f-7031fe2f4c71[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.176+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-02T00:00:00+00:00 [queued]> to 1bd4aac5-920c-45f3-adf7-0ea0e784cdfd[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.176+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-07-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:29.028285+00:00, run_end_date=2023-07-31 16:56:29.595338+00:00, run_duration=0.567053, state=success, executor_state=success, try_number=1, max_tries=1, job_id=267, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:26.211707+00:00, queued_by_job_id=4, pid=909[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.176+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=extract_data, run_id=scheduled__2023-07-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:29.054241+00:00, run_end_date=2023-07-31 16:56:29.747094+00:00, run_duration=0.692853, state=success, executor_state=success, try_number=1, max_tries=1, job_id=268, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 16:56:26.692658+00:00, queued_by_job_id=4, pid=910[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.205+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-28T00:00:00+00:00, run_after=2023-06-29T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.460+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.460+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.461+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.463+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.464+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'transform_data', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.575+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.575+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.581+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:29.600493+00:00, run_end_date=2023-07-31 16:56:30.260216+00:00, run_duration=0.659723, state=success, executor_state=success, try_number=1, max_tries=1, job_id=270, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:27.375528+00:00, queued_by_job_id=4, pid=915[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.582+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.transform_data scheduled__2023-07-03T00:00:00+00:00 [queued]> to 93c7a3f8-680a-4d24-ac69-0e4e14f545f9[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.632+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-29T00:00:00+00:00, run_after=2023-06-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.664+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-22 00:00:00+00:00: scheduled__2023-06-22T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:22.339056+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.664+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-22 00:00:00+00:00, run_id=scheduled__2023-06-22T00:00:00+00:00, run_start_date=2023-07-31 16:56:22.368846+00:00, run_end_date=2023-07-31 16:56:30.664590+00:00, run_duration=8.295744, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-22 00:00:00+00:00, data_interval_end=2023-06-23 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.669+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-23T00:00:00+00:00, run_after=2023-06-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.788+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.789+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.789+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-26T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-27T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-28T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.792+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.793+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.795+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.796+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-27T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.796+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:30.796+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-28T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.154+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.154+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.154+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.154+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.154+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-21T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.155+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-22T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.172+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-22T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:29.951307+00:00, run_end_date=2023-07-31 16:56:30.536552+00:00, run_duration=0.585245, state=success, executor_state=success, try_number=1, max_tries=1, job_id=272, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:27.859699+00:00, queued_by_job_id=4, pid=921[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.174+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:29.520135+00:00, run_end_date=2023-07-31 16:56:30.327986+00:00, run_duration=0.807851, state=success, executor_state=success, try_number=1, max_tries=1, job_id=269, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:26.692658+00:00, queued_by_job_id=4, pid=914[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.174+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:29.817414+00:00, run_end_date=2023-07-31 16:56:30.487803+00:00, run_duration=0.670389, state=success, executor_state=success, try_number=1, max_tries=1, job_id=271, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:26.692658+00:00, queued_by_job_id=4, pid=920[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.175+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-26T00:00:00+00:00 [queued]> to 99fec02f-3d55-4a9a-86cc-55c4f358eed8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.175+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-27T00:00:00+00:00 [queued]> to 7dc2139d-2660-4d55-bc83-8eb998cd9540[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.175+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-28T00:00:00+00:00 [queued]> to d82c3b09-0ad5-41df-b093-822b7edd354e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.175+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-21T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:29.992451+00:00, run_end_date=2023-07-31 16:56:30.685992+00:00, run_duration=0.693541, state=success, executor_state=success, try_number=1, max_tries=1, job_id=273, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:27.375528+00:00, queued_by_job_id=4, pid=922[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.216+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-24T00:00:00+00:00, run_after=2023-06-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.245+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-21 00:00:00+00:00: scheduled__2023-06-21T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:21.935050+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.246+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-21 00:00:00+00:00, run_id=scheduled__2023-06-21T00:00:00+00:00, run_start_date=2023-07-31 16:56:21.958066+00:00, run_end_date=2023-07-31 16:56:31.245893+00:00, run_duration=9.287827, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-21 00:00:00+00:00, data_interval_end=2023-06-22 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:31.250+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-22T00:00:00+00:00, run_after=2023-06-23T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.473+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-23T00:00:00+00:00, run_after=2023-06-24T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.534+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-25 00:00:00+00:00: scheduled__2023-06-25T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:23.024376+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.534+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-25 00:00:00+00:00, run_id=scheduled__2023-06-25T00:00:00+00:00, run_start_date=2023-07-31 16:56:23.042707+00:00, run_end_date=2023-07-31 16:56:32.534610+00:00, run_duration=9.491903, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-25 00:00:00+00:00, data_interval_end=2023-06-26 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.539+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-26T00:00:00+00:00, run_after=2023-06-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.550+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-23 00:00:00+00:00: scheduled__2023-06-23T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:22.613021+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.550+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-23 00:00:00+00:00, run_id=scheduled__2023-06-23T00:00:00+00:00, run_start_date=2023-07-31 16:56:22.650169+00:00, run_end_date=2023-07-31 16:56:32.550497+00:00, run_duration=9.900328, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-23 00:00:00+00:00, data_interval_end=2023-06-24 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.555+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-24T00:00:00+00:00, run_after=2023-06-25T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.576+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-24 00:00:00+00:00: scheduled__2023-06-24T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:22.818803+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.576+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-24 00:00:00+00:00, run_id=scheduled__2023-06-24T00:00:00+00:00, run_start_date=2023-07-31 16:56:22.840499+00:00, run_end_date=2023-07-31 16:56:32.576757+00:00, run_duration=9.736258, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-24 00:00:00+00:00, data_interval_end=2023-06-25 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.582+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-25T00:00:00+00:00, run_after=2023-06-26T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.618+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.619+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.619+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.619+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.619+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.619+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-29T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-06-30T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-07-01T00:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-07-02T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.622+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.622+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-29T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.623+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.623+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-06-30T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.623+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.623+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-07-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.624+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.624+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-07-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:32 +0000] "POST /last_dagruns HTTP/1.1" 200 340 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:32 +0000] "POST /dag_stats HTTP/1.1" 200 157 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:32 +0000] "POST /task_stats HTTP/1.1" 200 522 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:32 +0000] "POST /next_run_datasets_summary HTTP/1.1" 200 2 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.972+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.973+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.973+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.973+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.973+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.973+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.974+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.974+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-23T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.974+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.974+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-24T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.974+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-25T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.974+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='transform_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.997+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-29T00:00:00+00:00 [queued]> to 508e2e0d-6a29-4663-81d1-206a05f44cdf[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.998+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:31.066166+00:00, run_end_date=2023-07-31 16:56:31.710047+00:00, run_duration=0.643881, state=success, executor_state=success, try_number=1, max_tries=1, job_id=274, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:28.848387+00:00, queued_by_job_id=4, pid=932[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.998+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-06-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:31.679529+00:00, run_end_date=2023-07-31 16:56:32.260728+00:00, run_duration=0.581199, state=success, executor_state=success, try_number=1, max_tries=1, job_id=277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:29.163552+00:00, queued_by_job_id=4, pid=937[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.999+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-25T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:31.938599+00:00, run_end_date=2023-07-31 16:56:32.388414+00:00, run_duration=0.449815, state=success, executor_state=success, try_number=1, max_tries=1, job_id=279, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:29.858040+00:00, queued_by_job_id=4, pid=942[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.999+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-24T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:32.132003+00:00, run_end_date=2023-07-31 16:56:32.441161+00:00, run_duration=0.309158, state=success, executor_state=success, try_number=1, max_tries=1, job_id=280, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:29.858040+00:00, queued_by_job_id=4, pid=943[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.999+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-06-30T00:00:00+00:00 [queued]> to 71906c5a-f546-40c7-9b32-f3058ca01db7[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:32.999+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-07-01T00:00:00+00:00 [queued]> to 39f41973-6a94-4fdb-b7fb-439575db68ac[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.000+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-07-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:31.906985+00:00, run_end_date=2023-07-31 16:56:32.323650+00:00, run_duration=0.416665, state=success, executor_state=success, try_number=1, max_tries=1, job_id=278, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:29.858040+00:00, queued_by_job_id=4, pid=941[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.000+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-07-02T00:00:00+00:00 [queued]> to a216432c-8531-4367-9a08-69832a43a2ee[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.000+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-07-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:32.416181+00:00, run_end_date=2023-07-31 16:56:32.749028+00:00, run_duration=0.332847, state=success, executor_state=success, try_number=1, max_tries=1, job_id=281, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:30.461627+00:00, queued_by_job_id=4, pid=944[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.001+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-23T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:31.388486+00:00, run_end_date=2023-07-31 16:56:31.783176+00:00, run_duration=0.39469, state=success, executor_state=success, try_number=1, max_tries=1, job_id=276, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:29.163552+00:00, queued_by_job_id=4, pid=934[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.001+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=transform_data, run_id=scheduled__2023-07-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:31.391885+00:00, run_end_date=2023-07-31 16:56:31.954829+00:00, run_duration=0.562944, state=success, executor_state=success, try_number=1, max_tries=1, job_id=275, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 16:56:29.163552+00:00, queued_by_job_id=4, pid=935[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.027+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-26T00:00:00+00:00, run_after=2023-06-27T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.071+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-28 00:00:00+00:00: scheduled__2023-06-28T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:23.815168+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.071+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-28 00:00:00+00:00, run_id=scheduled__2023-06-28T00:00:00+00:00, run_start_date=2023-07-31 16:56:23.831924+00:00, run_end_date=2023-07-31 16:56:33.071886+00:00, run_duration=9.239962, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-28 00:00:00+00:00, data_interval_end=2023-06-29 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.077+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-29T00:00:00+00:00, run_after=2023-06-30T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.138+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.139+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG my_data_pipeline has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.139+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: my_data_pipeline.load_data scheduled__2023-07-03T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.141+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.142+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_data_pipeline', 'load_data', 'scheduled__2023-07-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.203+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.204+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-28T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.220+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-28T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:32.521784+00:00, run_end_date=2023-07-31 16:56:32.930002+00:00, run_duration=0.408218, state=success, executor_state=success, try_number=1, max_tries=1, job_id=282, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:30.790659+00:00, queued_by_job_id=4, pid=945[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.220+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: my_data_pipeline.load_data scheduled__2023-07-03T00:00:00+00:00 [queued]> to 81c798a3-cb27-401d-a8af-0a5a7fc68c19[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.244+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-30T00:00:00+00:00, run_after=2023-07-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.265+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-26 00:00:00+00:00: scheduled__2023-06-26T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:23.295517+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.265+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-26 00:00:00+00:00, run_id=scheduled__2023-06-26T00:00:00+00:00, run_start_date=2023-07-31 16:56:23.312184+00:00, run_end_date=2023-07-31 16:56:33.265748+00:00, run_duration=9.953564, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-26 00:00:00+00:00, data_interval_end=2023-06-27 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.269+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-27T00:00:00+00:00, run_after=2023-06-28T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.274+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-27 00:00:00+00:00: scheduled__2023-06-27T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:23.543871+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.275+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-27 00:00:00+00:00, run_id=scheduled__2023-06-27T00:00:00+00:00, run_start_date=2023-07-31 16:56:23.574012+00:00, run_end_date=2023-07-31 16:56:33.275291+00:00, run_duration=9.701279, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-27 00:00:00+00:00, data_interval_end=2023-06-28 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.280+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-28T00:00:00+00:00, run_after=2023-06-29T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.358+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-26T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.358+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-27T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.363+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-26T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:32.620407+00:00, run_end_date=2023-07-31 16:56:33.094468+00:00, run_duration=0.474061, state=success, executor_state=success, try_number=1, max_tries=1, job_id=283, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:30.790659+00:00, queued_by_job_id=4, pid=946[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.363+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-27T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:32.698835+00:00, run_end_date=2023-07-31 16:56:33.100719+00:00, run_duration=0.401884, state=success, executor_state=success, try_number=1, max_tries=1, job_id=284, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:30.790659+00:00, queued_by_job_id=4, pid=951[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:33.982+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-29T00:00:00+00:00, run_after=2023-06-30T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /home?status=all HTTP/1.1" 302 315 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall HTTP/1.1" 200 17842 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 200 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dall" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:34 +0000] "GET /static/appbuilder/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 0 "http://localhost:8080/static/appbuilder/css/fontawesome/solid.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.099+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-30T00:00:00+00:00, run_after=2023-07-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.115+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-07-03 00:00:00+00:00: scheduled__2023-07-03T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:26.502508+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.115+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-07-03 00:00:00+00:00, run_id=scheduled__2023-07-03T00:00:00+00:00, run_start_date=2023-07-31 16:56:26.520371+00:00, run_end_date=2023-07-31 16:56:35.115528+00:00, run_duration=8.595157, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-03 00:00:00+00:00, data_interval_end=2023-07-04 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.118+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-04T00:00:00+00:00, run_after=2023-07-05T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.122+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-07-01 00:00:00+00:00: scheduled__2023-07-01T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:25.476389+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.122+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-07-01 00:00:00+00:00, run_id=scheduled__2023-07-01T00:00:00+00:00, run_start_date=2023-07-31 16:56:25.500077+00:00, run_end_date=2023-07-31 16:56:35.122733+00:00, run_duration=9.622656, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-01 00:00:00+00:00, data_interval_end=2023-07-02 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.126+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-02T00:00:00+00:00, run_after=2023-07-03T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.130+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-30 00:00:00+00:00: scheduled__2023-06-30T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:25.008826+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.130+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-30 00:00:00+00:00, run_id=scheduled__2023-06-30T00:00:00+00:00, run_start_date=2023-07-31 16:56:25.031625+00:00, run_end_date=2023-07-31 16:56:35.130875+00:00, run_duration=10.09925, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-30 00:00:00+00:00, data_interval_end=2023-07-01 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.134+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-01T00:00:00+00:00, run_after=2023-07-02T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.138+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-06-29 00:00:00+00:00: scheduled__2023-06-29T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:24.399103+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.139+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-06-29 00:00:00+00:00, run_id=scheduled__2023-06-29T00:00:00+00:00, run_start_date=2023-07-31 16:56:24.438356+00:00, run_end_date=2023-07-31 16:56:35.139033+00:00, run_duration=10.700677, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-06-29 00:00:00+00:00, data_interval_end=2023-06-30 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.142+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-06-30T00:00:00+00:00, run_after=2023-07-01T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.147+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun my_data_pipeline @ 2023-07-02 00:00:00+00:00: scheduled__2023-07-02T00:00:00+00:00, state:running, queued_at: 2023-07-31 16:56:25.971577+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.147+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=my_data_pipeline, execution_date=2023-07-02 00:00:00+00:00, run_id=scheduled__2023-07-02T00:00:00+00:00, run_start_date=2023-07-31 16:56:25.998519+00:00, run_end_date=2023-07-31 16:56:35.147240+00:00, run_duration=9.148721, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-02 00:00:00+00:00, data_interval_end=2023-07-03 00:00:00+00:00, dag_hash=1b2caca5fb80fe6d696745293d978d36[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.150+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-03T00:00:00+00:00, run_after=2023-07-04T00:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.181+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-29T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.181+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-06-30T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.182+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-01T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.182+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-02T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.182+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='my_data_pipeline', task_id='load_data', run_id='scheduled__2023-07-03T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.186+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-29T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:34.003596+00:00, run_end_date=2023-07-31 16:56:34.288926+00:00, run_duration=0.28533, state=success, executor_state=success, try_number=1, max_tries=1, job_id=285, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:32.620471+00:00, queued_by_job_id=4, pid=960[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.187+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-07-01T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:34.109622+00:00, run_end_date=2023-07-31 16:56:34.343819+00:00, run_duration=0.234197, state=success, executor_state=success, try_number=1, max_tries=1, job_id=288, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:32.620471+00:00, queued_by_job_id=4, pid=961[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.187+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-06-30T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:34.029465+00:00, run_end_date=2023-07-31 16:56:34.287677+00:00, run_duration=0.258212, state=success, executor_state=success, try_number=1, max_tries=1, job_id=287, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:32.620471+00:00, queued_by_job_id=4, pid=959[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.187+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-07-02T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:33.998582+00:00, run_end_date=2023-07-31 16:56:34.258984+00:00, run_duration=0.260402, state=success, executor_state=success, try_number=1, max_tries=1, job_id=286, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:32.620471+00:00, queued_by_job_id=4, pid=958[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.187+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=my_data_pipeline, task_id=load_data, run_id=scheduled__2023-07-03T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 16:56:34.322651+00:00, run_end_date=2023-07-31 16:56:34.544173+00:00, run_duration=0.221522, state=success, executor_state=success, try_number=1, max_tries=1, job_id=289, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 16:56:33.139934+00:00, queued_by_job_id=4, pid=962[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:56:35.964+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for my_data_pipeline to 2023-07-04T00:00:00+00:00, run_after=2023-07-05T00:00:00+00:00[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:56:36 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.19.0.1 - - [31/Jul/2023:16:56:36 +0000] "POST /paused?is_paused=false&dag_id=my_data_pipeline HTTP/1.1" 200 2 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:57:06 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:57:09.221+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-redis-1              | 1:M 31 Jul 2023 16:57:32.024 * 100 changes in 300 seconds. Saving...
airflow-redis-1              | 1:M 31 Jul 2023 16:57:32.025 * Background saving started by pid 193
airflow-redis-1              | 193:C 31 Jul 2023 16:57:32.028 * DB saved on disk
airflow-redis-1              | 193:C 31 Jul 2023 16:57:32.029 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
airflow-redis-1              | 1:M 31 Jul 2023 16:57:32.125 * Background saving terminated with success
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:57:36 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:58:06 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:58:09.279+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T16:58:11.303+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:58:36 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:59:06 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T16:59:09.333+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:16:59:36 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:00:07 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:00:09.392+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:00:37 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:01:07 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:01:09.445+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:01:37 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:02:07 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:02:09.497+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:02:37 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:03:07 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:03:09.555+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T17:03:11.384+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:03:37 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:04:07 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:04:09.618+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:04:37 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:05:08 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:05:09.689+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:05:38 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:06:08 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:06:09.754+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:06:38 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:07:08 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:07:09.818+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:07:38 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:08:08 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:08:09.879+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T17:08:11.465+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:08:38 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:09:08 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:09:09.942+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:09:39 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:10:09 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:10:10.003+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:10:39 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:11:09 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:11:10.062+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:11:39 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-redis-1              | 1:M 31 Jul 2023 17:11:50.213 * 100 changes in 300 seconds. Saving...
airflow-redis-1              | 1:M 31 Jul 2023 17:11:50.213 * Background saving started by pid 705
airflow-redis-1              | 705:C 31 Jul 2023 17:11:50.215 * DB saved on disk
airflow-redis-1              | 705:C 31 Jul 2023 17:11:50.216 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
airflow-redis-1              | 1:M 31 Jul 2023 17:11:50.313 * Background saving terminated with success
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:12:09 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:12:10.116+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:12:39 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:13:09 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:13:10.178+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T17:13:11.551+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:13:39 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:14:09 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:14:10.239+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:14:40 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:15:10 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:15:10.302+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:15:40 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:16:10.362+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:16:10 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:16:40 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:17:10.424+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:17:10 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:17:40 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:18:10.495+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:18:10 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T17:18:11.642+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:18:40 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:19:10.557+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:19:10 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:19:41 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:20:10.620+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:20:11 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:20:41 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:21:10.682+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:21:11 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:21:41 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:22:10.749+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:22:12 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:22:42 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:23:10.815+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T17:23:11.731+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:23:12 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:23:42 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:24:10.883+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:24:12 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:24:42 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:25:10.951+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:25:12 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:25:42 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:26:11.006+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:26:12 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-redis-1              | 1:M 31 Jul 2023 17:26:24.060 * 100 changes in 300 seconds. Saving...
airflow-redis-1              | 1:M 31 Jul 2023 17:26:24.061 * Background saving started by pid 1234
airflow-redis-1              | 1234:C 31 Jul 2023 17:26:24.065 * DB saved on disk
airflow-redis-1              | 1234:C 31 Jul 2023 17:26:24.065 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
airflow-redis-1              | 1:M 31 Jul 2023 17:26:24.161 * Background saving terminated with success
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:26:42 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:27:11.074+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:27:13 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:27:43 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:28:11.144+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T17:28:11.803+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:28:13 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:28:43 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T17:29:11.207+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:17:29:13 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
== startdev 2023-07-31T20:22:01Z Start Airflow local containers
== startdev 2023-07-31T20:22:22Z Start Airflow local containers
== startdev 2023-07-31T20:22:48Z Start Airflow local containers
== startdev 2023-07-31T20:23:04Z Start Airflow local containers
== startdev 2023-07-31T20:29:58Z Start Airflow local containers
#1 [internal] load .dockerignore
#1 transferring context: 2B done
#1 DONE 0.0s

#2 [internal] load build definition from airflow.Dockerfile
#2 transferring dockerfile: 274B done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/apache/airflow:2.6.3
#3 DONE 0.0s

#4 [1/2] FROM docker.io/apache/airflow:2.6.3
#4 DONE 0.2s

#5 [2/2] RUN apt-get update   && apt-get install -y --no-install-recommends          vim   && apt-get autoremove -yqq --purge   && apt-get clean   && rm -rf /var/lib/apt/lists/*
#5 0.793 Get:1 http://deb.debian.org/debian bullseye InRelease [116 kB]
#5 1.099 Get:2 http://repo.mysql.com/apt/debian bullseye InRelease [17.9 kB]
#5 1.350 Get:3 http://deb.debian.org/debian-security bullseye-security InRelease [48.4 kB]
#5 1.610 Get:4 http://deb.debian.org/debian bullseye-updates InRelease [44.1 kB]
#5 1.736 Get:5 http://repo.mysql.com/apt/debian bullseye/mysql-8.0 amd64 Packages [12.6 kB]
#5 1.736 Get:6 http://deb.debian.org/debian bullseye/main amd64 Packages [8183 kB]
#5 2.183 Get:7 https://packages.microsoft.com/debian/11/prod bullseye InRelease [3629 B]
#5 2.556 Get:8 https://packages.microsoft.com/debian/11/prod bullseye/main armhf Packages [15.5 kB]
#5 2.800 Get:9 https://packages.microsoft.com/debian/11/prod bullseye/main arm64 Packages [16.8 kB]
#5 2.803 Get:10 https://packages.microsoft.com/debian/11/prod bullseye/main all Packages [1149 B]
#5 3.020 Get:11 https://packages.microsoft.com/debian/11/prod bullseye/main amd64 Packages [96.8 kB]
#5 7.279 Get:12 https://apt.postgresql.org/pub/repos/apt bullseye-pgdg InRelease [123 kB]
#5 8.135 Get:13 https://apt.postgresql.org/pub/repos/apt bullseye-pgdg/main amd64 Packages [286 kB]
#5 12.91 Get:14 http://deb.debian.org/debian-security bullseye-security/main amd64 Packages [252 kB]
#5 13.11 Get:15 http://deb.debian.org/debian bullseye-updates/main amd64 Packages [14.8 kB]
#5 14.05 Fetched 9232 kB in 14s (673 kB/s)
#5 14.05 Reading package lists...
#5 14.72 Reading package lists...
#5 15.34 Building dependency tree...
#5 15.49 Reading state information...
#5 15.72 The following additional packages will be installed:
#5 15.72   libgpm2 vim-common vim-runtime xxd
#5 15.72 Suggested packages:
#5 15.72   gpm ctags vim-doc vim-scripts
#5 15.83 The following NEW packages will be installed:
#5 15.83   libgpm2 vim vim-common vim-runtime xxd
#5 16.15 0 upgraded, 5 newly installed, 0 to remove and 7 not upgraded.
#5 16.15 Need to get 8174 kB of archives.
#5 16.15 After this operation, 36.9 MB of additional disk space will be used.
#5 16.15 Get:1 http://deb.debian.org/debian bullseye/main amd64 xxd amd64 2:8.2.2434-3+deb11u1 [192 kB]
#5 16.56 Get:2 http://deb.debian.org/debian bullseye/main amd64 vim-common all 2:8.2.2434-3+deb11u1 [226 kB]
#5 16.92 Get:3 http://deb.debian.org/debian bullseye/main amd64 libgpm2 amd64 1.20.7-8 [35.6 kB]
#5 16.92 Get:4 http://deb.debian.org/debian bullseye/main amd64 vim-runtime all 2:8.2.2434-3+deb11u1 [6226 kB]
#5 23.85 Get:5 http://deb.debian.org/debian bullseye/main amd64 vim amd64 2:8.2.2434-3+deb11u1 [1494 kB]
#5 25.85 Fetched 8174 kB in 9s (906 kB/s)
#5 25.88 Selecting previously unselected package xxd.
#5 25.88 (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 12117 files and directories currently installed.)
#5 25.92 Preparing to unpack .../xxd_2%3a8.2.2434-3+deb11u1_amd64.deb ...
#5 25.92 Unpacking xxd (2:8.2.2434-3+deb11u1) ...
#5 25.96 Selecting previously unselected package vim-common.
#5 25.96 Preparing to unpack .../vim-common_2%3a8.2.2434-3+deb11u1_all.deb ...
#5 25.97 Unpacking vim-common (2:8.2.2434-3+deb11u1) ...
#5 26.01 Selecting previously unselected package libgpm2:amd64.
#5 26.02 Preparing to unpack .../libgpm2_1.20.7-8_amd64.deb ...
#5 26.02 Unpacking libgpm2:amd64 (1.20.7-8) ...
#5 26.05 Selecting previously unselected package vim-runtime.
#5 26.05 Preparing to unpack .../vim-runtime_2%3a8.2.2434-3+deb11u1_all.deb ...
#5 26.06 Adding 'diversion of /usr/share/vim/vim82/doc/help.txt to /usr/share/vim/vim82/doc/help.txt.vim-tiny by vim-runtime'
#5 26.07 Adding 'diversion of /usr/share/vim/vim82/doc/tags to /usr/share/vim/vim82/doc/tags.vim-tiny by vim-runtime'
#5 26.07 Unpacking vim-runtime (2:8.2.2434-3+deb11u1) ...
#5 26.77 Selecting previously unselected package vim.
#5 26.77 Preparing to unpack .../vim_2%3a8.2.2434-3+deb11u1_amd64.deb ...
#5 26.78 Unpacking vim (2:8.2.2434-3+deb11u1) ...
#5 26.94 Setting up libgpm2:amd64 (1.20.7-8) ...
#5 26.95 Setting up xxd (2:8.2.2434-3+deb11u1) ...
#5 26.95 Setting up vim-common (2:8.2.2434-3+deb11u1) ...
#5 26.96 Setting up vim-runtime (2:8.2.2434-3+deb11u1) ...
#5 27.05 Setting up vim (2:8.2.2434-3+deb11u1) ...
#5 27.06 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vim (vim) in auto mode
#5 27.07 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vimdiff (vimdiff) in auto mode
#5 27.07 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rvim (rvim) in auto mode
#5 27.07 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/rview (rview) in auto mode
#5 27.08 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/vi (vi) in auto mode
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/da/man1/vi.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/de/man1/vi.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/fr/man1/vi.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/it/man1/vi.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/ja/man1/vi.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/pl/man1/vi.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/ru/man1/vi.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/man1/vi.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group vi) doesn't exist
#5 27.08 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/view (view) in auto mode
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/da/man1/view.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group view) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/de/man1/view.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group view) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/fr/man1/view.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group view) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/it/man1/view.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group view) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/ja/man1/view.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group view) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/pl/man1/view.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group view) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/ru/man1/view.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group view) doesn't exist
#5 27.08 update-alternatives: warning: skip creation of /usr/share/man/man1/view.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group view) doesn't exist
#5 27.09 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/ex (ex) in auto mode
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/da/man1/ex.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/de/man1/ex.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/fr/man1/ex.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/it/man1/ex.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/ja/man1/ex.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/pl/man1/ex.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/ru/man1/ex.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/man1/ex.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group ex) doesn't exist
#5 27.09 update-alternatives: using /usr/bin/vim.basic to provide /usr/bin/editor (editor) in auto mode
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/da/man1/editor.1.gz because associated file /usr/share/man/da/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/de/man1/editor.1.gz because associated file /usr/share/man/de/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/fr/man1/editor.1.gz because associated file /usr/share/man/fr/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/it/man1/editor.1.gz because associated file /usr/share/man/it/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/ja/man1/editor.1.gz because associated file /usr/share/man/ja/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/pl/man1/editor.1.gz because associated file /usr/share/man/pl/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/ru/man1/editor.1.gz because associated file /usr/share/man/ru/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.09 update-alternatives: warning: skip creation of /usr/share/man/man1/editor.1.gz because associated file /usr/share/man/man1/vim.1.gz (of link group editor) doesn't exist
#5 27.10 Processing triggers for libc-bin (2.31-13+deb11u6) ...
#5 DONE 28.3s

#6 exporting to image
#6 exporting layers
#6 exporting layers 0.4s done
#6 writing image sha256:46a9027a559fb6dde4e2082b34dd42c3d69c873c4ebb339f2e0dacc4b214ef0a done
#6 naming to docker.io/library/airflow-airflow-init done
#6 DONE 0.4s
Attaching to airflow-airflow-init-1
airflow-airflow-init-1  | 
airflow-airflow-init-1  | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1  | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1  | [[34m2023-07-31T20:33:01.601+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:01.602+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:01.605+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:01.606+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1  | Upgrades done
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.442+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.446+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Public[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.448+0000[0m] {[34mmanager.py:[0m853} WARNING[0m - No user yet created, use flask fab command to do it.[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.489+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Passwords[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.494+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Passwords to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.503+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Passwords[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.506+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Passwords to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.520+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on My Password[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.524+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.531+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on My Password[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.535+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.548+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on My Profile[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.551+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.558+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on My Profile[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.561+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.586+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.590+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.596+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.600+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.608+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.612+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.618+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.622+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.631+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on List Users[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.635+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on List Users to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.646+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Security[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.649+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Security to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.669+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.678+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.684+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.689+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.696+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.700+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.707+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.713+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.724+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on List Roles[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.728+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on List Roles to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.748+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on User Stats Chart[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.752+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on User Stats Chart to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.766+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on User's Statistics[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.770+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on User's Statistics to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.797+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Permissions[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.800+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Permissions to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.811+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Actions[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.815+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Actions to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.838+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on View Menus[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.841+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on View Menus to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.852+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Resources[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.855+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Resources to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.881+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Permission Views[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.885+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Permission Views to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.898+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Permission Pairs[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:04.902+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Permission Pairs to role Admin[0m
airflow-airflow-init-1  | [[34m2023-07-31T20:33:05.478+0000[0m] {[34mmanager.py:[0m212} INFO[0m - Added user airflow[0m
airflow-airflow-init-1  | User "airflow" created with role "Admin"
airflow-airflow-init-1  | 2.6.3
airflow-airflow-init-1 exited with code 0
#1 [internal] load build definition from airflow.Dockerfile
#1 [internal] load build definition from airflow.Dockerfile
#1 transferring dockerfile: 40B done
#1 DONE 0.0s

#2 [internal] load .dockerignore
#2 transferring context: 2B done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/apache/airflow:2.6.3
#3 DONE 0.0s

#4 [1/2] FROM docker.io/apache/airflow:2.6.3
#4 DONE 0.0s

#5 [2/2] RUN apt-get update   && apt-get install -y --no-install-recommends          vim   && apt-get autoremove -yqq --purge   && apt-get clean   && rm -rf /var/lib/apt/lists/*
#5 CACHED

#6 exporting to image
#6 exporting layers done
#6 writing image sha256:a88de1aeabdedb6b4af33916821a038d5506b5fc20a296ba1472581f03d6540b done
#6 naming to docker.io/library/airflow-airflow-triggerer done
#6 DONE 0.0s
#1 transferring dockerfile: 274B done
#1 DONE 0.0s

#2 [internal] load .dockerignore
#2 transferring context: 2B done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/apache/airflow:2.6.3
#1 [internal] load build definition from airflow.Dockerfile
#1 transferring dockerfile: 274B done
#1 DONE 0.0s

#2 [internal] load .dockerignore
#2 transferring context: 2B done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/apache/airflow:2.6.3
#3 DONE 0.0s

#4 [1/2] FROM docker.io/apache/airflow:2.6.3
#4 DONE 0.0s

#5 [2/2] RUN apt-get update   && apt-get install -y --no-install-recommends          vim   && apt-get autoremove -yqq --purge   && apt-get clean   && rm -rf /var/lib/apt/lists/*
#5 CACHED

#6 exporting to image
#6 exporting layers done
#6 writing image sha256:a503d0f4c6d11210d985f3f868ee0de86e5f6311f4ae0ef1af6fa43eb5fc3b81 done
#6 naming to docker.io/library/airflow-airflow-scheduler done
#6 DONE 0.0s
#1 [internal] load build definition from airflow.Dockerfile
#1 transferring dockerfile: 274B done
#1 DONE 0.0s

#2 [internal] load .dockerignore
#2 transferring context: 2B done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/apache/airflow:2.6.3
#3 DONE 0.0s

#4 [1/2] FROM docker.io/apache/airflow:2.6.3
#4 DONE 0.0s

#5 [2/2] RUN apt-get update   && apt-get install -y --no-install-recommends          vim   && apt-get autoremove -yqq --purge   && apt-get clean   && rm -rf /var/lib/apt/lists/*
#5 CACHED

#6 exporting to image
#6 exporting layers done
#6 writing image sha256:4a8f60b2138d0626fe51ecca2403685f2c737b3cae6cd7100d54aa7cace2b75d done
#6 naming to docker.io/library/airflow-airflow-worker done
#6 DONE 0.0s
#3 DONE 0.0s

#4 [1/2] FROM docker.io/apache/airflow:2.6.3
#4 DONE 0.0s

#5 [2/2] RUN apt-get update   && apt-get install -y --no-install-recommends          vim   && apt-get autoremove -yqq --purge   && apt-get clean   && rm -rf /var/lib/apt/lists/*
#5 CACHED

#6 exporting to image
#6 exporting layers done
#6 writing image sha256:b470632975c1519301ecd2e69b9f29d7052c9c47b429afee5de283e4eb4eb13d done
#6 naming to docker.io/library/airflow-airflow-webserver done
#6 DONE 0.0s
Attaching to airflow-airflow-init-1, airflow-airflow-scheduler-1, airflow-airflow-triggerer-1, airflow-airflow-webserver-1, airflow-airflow-worker-1, airflow-postgres-1, airflow-redis-1
airflow-airflow-init-1       | 
airflow-airflow-init-1       | DB: postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | Performing upgrade with database postgresql+psycopg2://airflow:***@postgres/airflow
airflow-airflow-init-1       | [[34m2023-07-31T20:33:11.813+0000[0m] {[34mmigration.py:[0m213} INFO[0m - Context impl PostgresqlImpl.[0m
airflow-airflow-init-1       | [[34m2023-07-31T20:33:11.814+0000[0m] {[34mmigration.py:[0m220} INFO[0m - Will assume transactional DDL.[0m
airflow-airflow-init-1       | [[34m2023-07-31T20:33:11.823+0000[0m] {[34mdb.py:[0m1591} INFO[0m - Creating tables[0m
airflow-airflow-init-1       | Upgrades done
airflow-airflow-init-1       | airflow already exist in the db
airflow-airflow-init-1       | 2.6.3
airflow-airflow-init-1 exited with code 0
airflow-airflow-worker-1     | 
airflow-airflow-webserver-1  | 
airflow-airflow-scheduler-1  | 
airflow-airflow-triggerer-1  | 
airflow-airflow-worker-1     | BACKEND=redis
airflow-airflow-worker-1     | DB_HOST=redis
airflow-airflow-worker-1     | DB_PORT=6379
airflow-airflow-worker-1     | 
airflow-airflow-scheduler-1  | BACKEND=redis
airflow-airflow-scheduler-1  | DB_HOST=redis
airflow-airflow-scheduler-1  | DB_PORT=6379
airflow-airflow-scheduler-1  | 
airflow-airflow-triggerer-1  |   ____________       _____________
airflow-airflow-triggerer-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-triggerer-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-triggerer-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-triggerer-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:33:28.955+0000[0m] {[34mtriggerer_job_runner.py:[0m173} INFO[0m - Setting up TriggererHandlerWrapper with handler <FileTaskHandler (NOTSET)>[0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:33:29.926+0000[0m] {[34mtriggerer_job_runner.py:[0m229} INFO[0m - Setting up logging queue listener with handlers [<RedirectStdHandler <stdout> (NOTSET)>, <TriggererHandlerWrapper (NOTSET)>][0m
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:33:29.953+0000[0m] {[34mtriggerer_job_runner.py:[0m325} INFO[0m - Starting the triggerer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.267+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.275+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.284+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.289+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.297+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.302+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.311+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on DAG Runs[0m
airflow-airflow-scheduler-1  |   ____________       _____________
airflow-airflow-scheduler-1  |  ____    |__( )_________  __/__  /________      __
airflow-airflow-scheduler-1  | ____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
airflow-airflow-scheduler-1  | ___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
airflow-airflow-scheduler-1  |  _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:33:31.315+0000[0m] {[34mexecutor_loader.py:[0m114} INFO[0m - Loaded executor: CeleryExecutor[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.316+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.323+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on DAG Runs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.328+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.350+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Browse[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.355+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role Admin[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:33:31.362+0000[0m] {[34mscheduler_job_runner.py:[0m788} INFO[0m - Starting the scheduler[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:33:31.363+0000[0m] {[34mscheduler_job_runner.py:[0m795} INFO[0m - Processing each file at most -1 times[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:33:31.370+0000[0m] {[34mmanager.py:[0m165} INFO[0m - Launched DagFileProcessorManager with pid: 31[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:33:31.371+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:33:31.373+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone Timezone('UTC')[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.380+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Jobs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.385+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.393+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Jobs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.398+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.436+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Audit Logs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.442+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.450+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Audit Logs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.456+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.501+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.508+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.523+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.530+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.538+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.543+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.552+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.558+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.567+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Variables[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.573+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Variables to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.597+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.603+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Admin to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.631+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.640+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.648+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.653+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.661+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.750+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.760+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.766+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.773+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Task Instances[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.778+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.823+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Task Reschedules[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.830+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Reschedules to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.839+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Task Reschedules[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.845+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Reschedules to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.899+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Triggers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.906+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Triggers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.918+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Triggers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.924+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Triggers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.952+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Configurations[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.957+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Configurations to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.965+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Configurations[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:31.971+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Configurations to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.011+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.023+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.039+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.045+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.052+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.058+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.067+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.072+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.080+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Connections[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.086+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Connections to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.133+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.140+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.149+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.160+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.168+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: muldelete on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.174+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission muldelete on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.182+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulemailsent on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.189+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulemailsent on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.197+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulemailsentfalse on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.203+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulemailsentfalse on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.211+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulnotificationsent on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.217+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulnotificationsent on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.228+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: mulnotificationsentfalse on SLA Misses[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.235+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission mulnotificationsentfalse on SLA Misses to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.282+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Plugins[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.289+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.302+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Plugins[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.311+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.341+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Providers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.348+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Providers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.357+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Providers[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.363+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Providers to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.405+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.412+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.421+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.427+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.434+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.440+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.449+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.456+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.467+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Pools[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.473+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Pools to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.525+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can create on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.532+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.540+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.549+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.561+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.570+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.580+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on XComs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.586+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on XComs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.626+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on DAG Dependencies[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.633+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.665+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on DAGs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.672+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.690+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Datasets[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.696+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.714+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Documentation[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.721+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.736+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: menu access on Docs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:32.746+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:33.261+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAGs[0m
airflow-airflow-worker-1     |  
airflow-airflow-worker-1     |  -------------- celery@9453d8a3282b v5.2.7 (dawn-chorus)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     | -- ******* ---- Linux-5.19.0-50-generic-x86_64-with-debian-11.7 2023-07-31 20:33:33
airflow-airflow-worker-1     | - *** --- * --- 
airflow-airflow-worker-1     | - ** ---------- [config]
airflow-airflow-worker-1     | - ** ---------- .> app:         airflow.executors.celery_executor:0x7fea577fd990
airflow-airflow-worker-1     | - ** ---------- .> transport:   redis://redis:6379/0
airflow-airflow-worker-1     | - ** ---------- .> results:     postgresql://airflow:**@postgres/airflow
airflow-airflow-worker-1     | - *** --- * --- .> concurrency: 16 (prefork)
airflow-airflow-worker-1     | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)
airflow-airflow-worker-1     | --- ***** ----- 
airflow-airflow-worker-1     |  -------------- [queues]
airflow-airflow-worker-1     |                 .> default          exchange=default(direct) key=default
airflow-airflow-worker-1     |                 
airflow-airflow-worker-1     | 
airflow-airflow-worker-1     | [tasks]
airflow-airflow-worker-1     |   . airflow.executors.celery_executor.execute_command
airflow-airflow-worker-1     | 
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:33.290+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can edit on DAGs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:33.305+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can delete on DAGs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:33.594+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Datasets[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:33.701+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on ImportError[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:33.897+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Code[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:33.930+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Warnings[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.139+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.149+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.153+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.163+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on DAG Dependencies[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.167+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.171+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.176+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.180+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.184+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.188+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.191+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.195+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.198+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.202+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.206+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.210+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.216+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.222+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.243+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Task Logs[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.248+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.251+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.259+0000[0m] {[34mmanager.py:[0m504} INFO[0m - Created Permission View: can read on Website[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.262+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.266+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.277+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.285+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.288+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.292+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.296+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.303+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.309+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.313+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.317+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.320+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.324+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role Viewer[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.329+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.334+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.337+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.344+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.347+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.351+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.354+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.357+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.361+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.364+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.367+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.371+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.374+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.377+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.380+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.383+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.387+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.394+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.397+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.406+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.411+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.416+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.428+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.437+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.440+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.444+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.457+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.461+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.464+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.468+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.471+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.475+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.478+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.483+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAGs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.487+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.492+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.496+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Task Instances to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.500+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.503+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.507+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAG Runs to role User[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.512+0000[0m] {[34mmanager.py:[0m243} INFO[0m - Inserted Role: Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.518+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Audit Logs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.521+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.529+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.533+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.536+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.540+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.543+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.545+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.548+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Jobs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.551+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Password to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.554+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Password to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.557+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on My Profile to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.560+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on My Profile to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.563+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Plugins to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.566+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on SLA Misses to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.570+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.578+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.581+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on XComs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.594+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.600+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Browse to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.603+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.607+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Dependencies to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.615+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.618+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Datasets to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.622+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Documentation to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.625+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Docs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.628+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Jobs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.632+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Audit Logs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.635+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Plugins to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.638+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on SLA Misses to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.641+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.644+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.649+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAGs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.653+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.657+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.660+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Task Instances to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.664+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.668+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.671+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAG Runs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.675+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Configurations to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.678+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Admin to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.683+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Configurations to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.690+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.698+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.701+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.706+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission menu access on XComs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.709+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.712+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.715+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.719+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Connections to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.723+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.728+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.732+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.738+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Pools to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.745+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Providers to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.750+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can create on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.753+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.757+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.763+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on Variables to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.767+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on XComs to role Op[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.770+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.778+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Dependencies to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.781+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Code to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.784+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Datasets to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.787+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on ImportError to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.790+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on DAG Warnings to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.800+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Task Logs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.808+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can read on Website to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.810+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can edit on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:34.813+0000[0m] {[34mmanager.py:[0m562} INFO[0m - Added Permission can delete on DAGs to role Admin[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:33:40.530+0000[0m] {[34mproviders_manager.py:[0m247} INFO[0m - Optional provider feature disabled when importing 'airflow.providers.google.leveldb.hooks.leveldb.LevelDBHook' from 'apache-airflow-providers-google' package[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:33:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:34:22 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /home?status=active HTTP/1.1" 302 321 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive HTTP/1.1" 200 17862 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:26 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:27 +0000] "GET /static/appbuilder/webfonts/fa-solid-900.woff2 HTTP/1.1" 200 0 "http://localhost:8080/static/appbuilder/css/fontawesome/solid.min.css" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:34:30.021+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | [[34m2023-07-31T20:34:33.124+0000[0m] {[34mmanager.py:[0m226} INFO[0m - Updated user Airflow Admin[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "POST /login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive HTTP/1.1" 302 267 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /home?status=active HTTP/1.1" 200 31700 "http://localhost:8080/login/?next=http%3A%2F%2Flocalhost%3A8080%2Fhome%3Fstatus%3Dactive" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:33 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:34 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:34 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:34 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:34 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:34 +0000] "GET /static/pin_32.png HTTP/1.1" 304 0 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /home?status=all HTTP/1.1" 200 427155 "http://localhost:8080/home?status=active" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/dist/dags.75834f6135d1a798beb8.js HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:37 +0000] "GET /static/pin_32.png HTTP/1.1" 304 0 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:38 +0000] "POST /blocked HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:38 +0000] "POST /last_dagruns HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:38 +0000] "POST /dag_stats HTTP/1.1" 200 8268 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:38 +0000] "POST /task_stats HTTP/1.1" 200 26518 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:52 +0000] "POST /paused?is_paused=true&dag_id=TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.441+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:05:00+00:00, run_after=2023-07-31T00:10:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.539+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.539+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.540+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.544+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.544+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.772+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.786+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:00:00+00:00 [queued]> to 62b7b6b8-3b76-4939-be9e-99f209f42e34[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.833+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:10:00+00:00, run_after=2023-07-31T00:15:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.886+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:05:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.886+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.886+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:05:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.889+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.889+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.931+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.937+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:05:00+00:00 [queued]> to 4204f639-2754-4332-b6c7-907609a84716[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:34:52 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:52.971+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:15:00+00:00, run_after=2023-07-31T00:20:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.034+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:10:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.035+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.035+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:10:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.038+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.038+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.079+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.086+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:10:00+00:00 [queued]> to 155dba5e-65e6-4f91-92a1-34c8f2f27ca0[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.116+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:20:00+00:00, run_after=2023-07-31T00:25:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.190+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:15:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.191+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.191+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:15:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.194+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.194+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.238+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.244+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:15:00+00:00 [queued]> to 7a103832-dcaf-4902-b8eb-2a0630e62e76[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.274+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:25:00+00:00, run_after=2023-07-31T00:30:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.377+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:20:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.377+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.377+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:20:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.380+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.381+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.427+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.436+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:20:00+00:00 [queued]> to d59329a1-dfd6-4859-b631-8103484d6f85[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.488+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:30:00+00:00, run_after=2023-07-31T00:35:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.595+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.595+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.595+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.599+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.600+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /dags/TEST_DAG/grid HTTP/1.1" 200 10179 "http://localhost:8080/home?status=all" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.649+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.658+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:25:00+00:00 [queued]> to 65156789-5060-4558-94f9-b18f1102c865[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.688+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:35:00+00:00, run_after=2023-07-31T00:40:00+00:00[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.827+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.827+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.829+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:30:00+00:00 [scheduled]>[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.832+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.833+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.976+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:53.992+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:30:00+00:00 [queued]> to d08e520b-53dd-42aa-be31-1d57ef896a49[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:53 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.047+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:40:00+00:00, run_after=2023-07-31T00:45:00+00:00[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/grid.fd7d0b19bd6a74faf072.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:54 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.245+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.245+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.245+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.252+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.252+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.340+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.348+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:35:00+00:00 [queued]> to ca19a05c-9392-414b-9f9a-1b7f60554f9f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.399+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:45:00+00:00, run_after=2023-07-31T00:50:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.553+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:40:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.553+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.553+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:40:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.557+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.557+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.638+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.660+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:40:00+00:00 [queued]> to 2a304bae-e686-454b-be3d-b5d52a1b1619[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.694+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:50:00+00:00, run_after=2023-07-31T00:55:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.842+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:45:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.843+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.843+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:45:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.846+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.846+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.957+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.964+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:45:00+00:00 [queued]> to 03f1898a-3e52-4391-b64c-36baa09d3e3c[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:54.994+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:55:00+00:00, run_after=2023-07-31T01:00:00+00:00[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:55 +0000] "GET /object/grid_data?dag_id=TEST_DAG&num_runs=25 HTTP/1.1" 200 10824 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.200+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:50:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.201+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.201+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:50:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.204+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.205+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:55 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.299+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.306+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:50:00+00:00 [queued]> to 3151220c-37e2-42ec-8598-e992a33480cd[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.342+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:00:00+00:00, run_after=2023-07-31T01:05:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.535+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:55:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.535+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.536+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:55:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.542+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.543+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T00:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.637+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.655+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T00:55:00+00:00 [queued]> to c3121a13-eb12-4993-b0b2-1cd4f6319418[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.697+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:05:00+00:00, run_after=2023-07-31T01:10:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.910+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.910+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.910+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.916+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:55.916+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.000+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.008+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:00:00+00:00 [queued]> to 30f091ea-8506-4747-aced-f795b3dcd913[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.061+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:10:00+00:00, run_after=2023-07-31T01:15:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.324+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:05:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.325+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.325+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:05:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.329+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.329+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.503+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.510+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:05:00+00:00 [queued]> to 4eb37bf1-7913-4c27-9290-73a67e098c21[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.559+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:15:00+00:00, run_after=2023-07-31T01:20:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.803+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:10:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.804+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.804+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:10:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.807+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.807+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.943+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.950+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:10:00+00:00 [queued]> to 660cd4cf-c151-425b-8691-b25fb7792321[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:56.994+0000[0m] {[34mscheduler_job_runner.py:[0m1298} INFO[0m - DAG TEST_DAG is at (or above) max_active_runs (16 of 16), not creating any more runs[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.259+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.260+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.260+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.260+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.266+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.266+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.266+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.266+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.494+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.494+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.494+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.512+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:00:00+00:00 [queued]> to b194dad1-4fe4-49bb-8e39-23894c46c339[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.513+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:05:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:56.453970+00:00, run_end_date=2023-07-31 20:34:57.065634+00:00, run_duration=0.611664, state=success, executor_state=success, try_number=1, max_tries=1, job_id=5, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:52.887202+00:00, queued_by_job_id=2, pid=104[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.513+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:15:00+00:00 [queued]> to 080b6e46-4d09-4c92-a794-de4b4d30713b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.786+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:20:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.786+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.787+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.787+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.787+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.787+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:20:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.792+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.792+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.792+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.793+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.793+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.793+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.793+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:57.793+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.317+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.318+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.318+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.318+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.318+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.318+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.319+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.319+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.319+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.319+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.343+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:56.157337+00:00, run_end_date=2023-07-31 20:34:56.960372+00:00, run_duration=0.803035, state=success, executor_state=success, try_number=1, max_tries=1, job_id=6, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:52.540823+00:00, queued_by_job_id=2, pid=100[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.344+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:05:00+00:00 [queued]> to b6e01ba8-97e9-482c-b21c-22506bf19e7b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.345+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:10:00+00:00 [queued]> to 8968baa9-08db-411d-a071-63b1cf043217[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.345+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:10:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:56.534586+00:00, run_end_date=2023-07-31 20:34:57.472396+00:00, run_duration=0.93781, state=success, executor_state=success, try_number=1, max_tries=1, job_id=8, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:53.036147+00:00, queued_by_job_id=2, pid=107[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.345+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:15:00+00:00 [queued]> to 9d42c04e-f410-4fe1-8909-51ecf601a458[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.345+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:15:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:56.473549+00:00, run_end_date=2023-07-31 20:34:57.481429+00:00, run_duration=1.00788, state=success, executor_state=success, try_number=1, max_tries=1, job_id=4, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:53.192091+00:00, queued_by_job_id=2, pid=108[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.346+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:20:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:56.293827+00:00, run_end_date=2023-07-31 20:34:57.263088+00:00, run_duration=0.969261, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:53.378525+00:00, queued_by_job_id=2, pid=101[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.346+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:20:00+00:00 [queued]> to b3832e9e-b68e-4c6d-9a6c-ed7d1d811e8a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.346+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:25:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:56.793034+00:00, run_end_date=2023-07-31 20:34:57.835793+00:00, run_duration=1.042759, state=success, executor_state=success, try_number=1, max_tries=1, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:53.596640+00:00, queued_by_job_id=2, pid=109[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.346+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:30:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:56.947617+00:00, run_end_date=2023-07-31 20:34:57.800951+00:00, run_duration=0.853334, state=success, executor_state=success, try_number=1, max_tries=1, job_id=9, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:53.830375+00:00, queued_by_job_id=2, pid=111[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:34:58 +0000] "GET /object/grid_data?dag_id=TEST_DAG&num_runs=25 HTTP/1.1" 200 15985 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.589+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:25:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.590+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.590+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.590+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:25:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.593+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.594+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.594+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.594+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.827+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.827+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.840+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:25:00+00:00 [queued]> to 1899d8c9-bf95-4e5c-b06c-85eeae155413[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:58.840+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:30:00+00:00 [queued]> to 46aa83cf-ae9f-40cf-8013-314cf230669f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.061+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.061+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.061+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.064+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.064+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.210+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.210+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.216+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:35:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:57.773295+00:00, run_end_date=2023-07-31 20:34:58.599013+00:00, run_duration=0.825718, state=success, executor_state=success, try_number=1, max_tries=1, job_id=10, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:54.246695+00:00, queued_by_job_id=2, pid=120[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:34:59.216+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:35:00+00:00 [queued]> to 8a3d13b2-292f-4f2d-bab8-5defe57607cb[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.707+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 5 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:40:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:45:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:50:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:55:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:05:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.707+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 11/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.707+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.707+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.707+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.708+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.708+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:40:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:45:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:50:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:55:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:05:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.711+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.711+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T00:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:00.712+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.253+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.254+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.310+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:40:00+00:00 [queued]> to cbf66755-9c31-45ca-9888-b2a99865e927[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:40:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:59.335094+00:00, run_end_date=2023-07-31 20:35:00.084425+00:00, run_duration=0.749331, state=success, executor_state=success, try_number=1, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:54.554382+00:00, queued_by_job_id=2, pid=134[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:45:00+00:00 [queued]> to fc50aaa3-4980-4ee0-be0c-9152d6e9c2c4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:45:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:59.108924+00:00, run_end_date=2023-07-31 20:34:59.975149+00:00, run_duration=0.866225, state=success, executor_state=success, try_number=1, max_tries=1, job_id=13, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:54.844139+00:00, queued_by_job_id=2, pid=132[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:50:00+00:00 [queued]> to 91d7f647-f93c-49b4-94d1-14aca7f52de8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:50:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:59.017522+00:00, run_end_date=2023-07-31 20:34:59.716358+00:00, run_duration=0.698836, state=success, executor_state=success, try_number=1, max_tries=1, job_id=12, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:55.202378+00:00, queued_by_job_id=2, pid=129[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T00:55:00+00:00 [queued]> to e1dc765d-1bfa-46ed-91c9-8495e6dc2791[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T00:55:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:58.673016+00:00, run_end_date=2023-07-31 20:34:59.446329+00:00, run_duration=0.773313, state=success, executor_state=success, try_number=1, max_tries=1, job_id=11, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:55.536967+00:00, queued_by_job_id=2, pid=128[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:05:00+00:00, map_index=-1, run_start_date=2023-07-31 20:34:59.997780+00:00, run_end_date=2023-07-31 20:35:00.494234+00:00, run_duration=0.496454, state=success, executor_state=success, try_number=1, max_tries=1, job_id=15, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:56.326099+00:00, queued_by_job_id=2, pid=140[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.311+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:05:00+00:00 [queued]> to 6fc81d31-2170-41b3-9edf-5686ce58acfc[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.650+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.650+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.650+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.650+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.650+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.655+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.656+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.656+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.656+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.656+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.656+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:01 +0000] "GET /object/grid_data?dag_id=TEST_DAG&num_runs=25 HTTP/1.1" 200 16696 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.966+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.967+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.967+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.967+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.967+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.967+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.967+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.987+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:00.487127+00:00, run_end_date=2023-07-31 20:35:01.383001+00:00, run_duration=0.895874, state=success, executor_state=success, try_number=1, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:57.261695+00:00, queued_by_job_id=2, pid=143[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.987+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:00:00+00:00 [queued]> to 2f11eba4-fef4-474f-8bd4-967f4139c1f4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.987+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:15:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:00.760686+00:00, run_end_date=2023-07-31 20:35:01.552303+00:00, run_duration=0.791617, state=success, executor_state=success, try_number=1, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:57.788390+00:00, queued_by_job_id=2, pid=150[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.987+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:00:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:00.637827+00:00, run_end_date=2023-07-31 20:35:01.458455+00:00, run_duration=0.820628, state=success, executor_state=success, try_number=1, max_tries=1, job_id=17, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:55.911677+00:00, queued_by_job_id=2, pid=144[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.988+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:00:00+00:00 [queued]> to 7aa5908e-7dad-4cfa-8dae-c2838cc12775[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.988+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:15:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:00.483654+00:00, run_end_date=2023-07-31 20:35:01.243730+00:00, run_duration=0.760076, state=success, executor_state=success, try_number=1, max_tries=1, job_id=16, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:57.261695+00:00, queued_by_job_id=2, pid=142[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:01.988+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:15:00+00:00 [queued]> to e8894d60-8bb0-48dc-82cf-f8202feca6a8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.312+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.313+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.313+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.313+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.313+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.313+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.320+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.320+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.320+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.320+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.320+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.320+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.321+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.321+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.740+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.741+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.741+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.741+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.741+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.741+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.741+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.741+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.761+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:10:00+00:00 [queued]> to 13220312-bfcf-4cc0-967c-72b2f1e2ae54[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.762+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:10:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:01.345773+00:00, run_end_date=2023-07-31 20:35:02.043815+00:00, run_duration=0.698042, state=success, executor_state=success, try_number=1, max_tries=1, job_id=22, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:57.788390+00:00, queued_by_job_id=2, pid=154[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.762+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:15:00+00:00 [queued]> to 201c960a-c542-4790-9838-39a4970f2151[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.762+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:25:00+00:00 [queued]> to 9da6128c-e4b5-4a3b-a1b2-2cafa2472aa8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.763+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:25:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:00.957191+00:00, run_end_date=2023-07-31 20:35:02.038939+00:00, run_duration=1.081748, state=success, executor_state=success, try_number=1, max_tries=1, job_id=19, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:58.591512+00:00, queued_by_job_id=2, pid=151[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.763+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:30:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:01.676706+00:00, run_end_date=2023-07-31 20:35:02.303066+00:00, run_duration=0.62636, state=success, executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:58.591512+00:00, queued_by_job_id=2, pid=156[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.763+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:10:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:01.085145+00:00, run_end_date=2023-07-31 20:35:01.837412+00:00, run_duration=0.752267, state=success, executor_state=success, try_number=1, max_tries=1, job_id=21, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:34:56.805034+00:00, queued_by_job_id=2, pid=153[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:02.763+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:10:00+00:00 [queued]> to 0e78a658-bc5f-4854-89e9-19b26527810b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.095+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.095+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.095+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.095+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.099+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.099+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.099+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.099+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.400+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.400+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.400+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.420+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:05:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:02.016749+00:00, run_end_date=2023-07-31 20:35:02.792382+00:00, run_duration=0.775633, state=success, executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:57.788390+00:00, queued_by_job_id=2, pid=162[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.420+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:05:00+00:00 [queued]> to 4697245d-a1e3-4ad7-a30d-efcbecaee097[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.421+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:30:00+00:00 [queued]> to 7679d473-d55b-46e3-857a-173f2f81a4ae[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.856+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.857+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.857+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.861+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:03.862+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.036+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.036+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.036+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.054+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:35:00+00:00 [queued]> to 952e5445-afef-444e-b403-bbaa8bfbb6a1[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.055+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:35:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:02.494440+00:00, run_end_date=2023-07-31 20:35:03.240629+00:00, run_duration=0.746189, state=success, executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:59.062469+00:00, queued_by_job_id=2, pid=169[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.055+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:55:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:02.727248+00:00, run_end_date=2023-07-31 20:35:03.543468+00:00, run_duration=0.81622, state=success, executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:00.708823+00:00, queued_by_job_id=2, pid=170[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.371+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:20:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:40:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:50:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:55:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.371+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 12/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.371+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 13/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.371+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 14/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.371+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.371+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:20:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:40:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:50:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:55:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.376+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.376+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.376+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.376+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.376+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.377+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.377+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.377+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:04 +0000] "GET /object/grid_data?dag_id=TEST_DAG&num_runs=25 HTTP/1.1" 200 17310 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.925+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.926+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.926+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.926+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.926+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.926+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.926+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.959+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:20:00+00:00 [queued]> to 89cccfef-ab15-4140-9307-558b1e9a6307[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.960+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:20:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:03.254790+00:00, run_end_date=2023-07-31 20:35:03.886598+00:00, run_duration=0.631808, state=success, executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:34:57.788390+00:00, queued_by_job_id=2, pid=178[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.960+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:40:00+00:00 [queued]> to cceb02c8-e83c-4beb-94c2-80b22dd620e5[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.960+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:40:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:03.241257+00:00, run_end_date=2023-07-31 20:35:03.919309+00:00, run_duration=0.678052, state=success, executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:00.708823+00:00, queued_by_job_id=2, pid=176[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.960+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:50:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:03.373350+00:00, run_end_date=2023-07-31 20:35:04.176183+00:00, run_duration=0.802833, state=success, executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:00.708823+00:00, queued_by_job_id=2, pid=180[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.961+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:50:00+00:00 [queued]> to 8a50d52c-ff41-4f3f-8d6c-947e5b4ca4bd[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:04.961+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:55:00+00:00 [queued]> to da8149e8-8f26-4f6b-9fd4-3321b5fa9701[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.250+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:45:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.250+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 15/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.254+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:45:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.257+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.257+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T00:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.381+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.384+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.389+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T00:45:00+00:00 [queued]> to 9f2d3c4e-437e-45f6-a695-114ae38a076f[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:05.390+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T00:45:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:03.935631+00:00, run_end_date=2023-07-31 20:35:04.812809+00:00, run_duration=0.877178, state=success, executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:00.708823+00:00, queued_by_job_id=2, pid=183[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.795+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:15:00+00:00: scheduled__2023-07-31T00:15:00+00:00, state:running, queued_at: 2023-07-31 20:34:53.110739+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.796+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:15:00+00:00, run_id=scheduled__2023-07-31T00:15:00+00:00, run_start_date=2023-07-31 20:34:53.125560+00:00, run_end_date=2023-07-31 20:35:06.796809+00:00, run_duration=13.671249, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:15:00+00:00, data_interval_end=2023-07-31 00:20:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.803+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:20:00+00:00, run_after=2023-07-31T00:25:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.812+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:00:00+00:00: scheduled__2023-07-31T00:00:00+00:00, state:running, queued_at: 2023-07-31 20:34:52.407619+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.812+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:00:00+00:00, run_id=scheduled__2023-07-31T00:00:00+00:00, run_start_date=2023-07-31 20:34:52.468108+00:00, run_end_date=2023-07-31 20:35:06.812538+00:00, run_duration=14.34443, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:00:00+00:00, data_interval_end=2023-07-31 00:05:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.828+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:05:00+00:00, run_after=2023-07-31T00:10:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.836+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:05:00+00:00: scheduled__2023-07-31T00:05:00+00:00, state:running, queued_at: 2023-07-31 20:34:52.826353+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.837+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:05:00+00:00, run_id=scheduled__2023-07-31T00:05:00+00:00, run_start_date=2023-07-31 20:34:52.844023+00:00, run_end_date=2023-07-31 20:35:06.836887+00:00, run_duration=13.992864, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:05:00+00:00, data_interval_end=2023-07-31 00:10:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.844+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:10:00+00:00, run_after=2023-07-31T00:15:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.853+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:25:00+00:00: scheduled__2023-07-31T00:25:00+00:00, state:running, queued_at: 2023-07-31 20:34:53.482189+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.855+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:25:00+00:00, run_id=scheduled__2023-07-31T00:25:00+00:00, run_start_date=2023-07-31 20:34:53.499984+00:00, run_end_date=2023-07-31 20:35:06.855460+00:00, run_duration=13.355476, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:25:00+00:00, data_interval_end=2023-07-31 00:30:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.862+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:30:00+00:00, run_after=2023-07-31T00:35:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.874+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:10:00+00:00: scheduled__2023-07-31T00:10:00+00:00, state:running, queued_at: 2023-07-31 20:34:52.966074+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.877+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:10:00+00:00, run_id=scheduled__2023-07-31T00:10:00+00:00, run_start_date=2023-07-31 20:34:52.982665+00:00, run_end_date=2023-07-31 20:35:06.877581+00:00, run_duration=13.894916, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:10:00+00:00, data_interval_end=2023-07-31 00:15:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:06.884+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:15:00+00:00, run_after=2023-07-31T00:20:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.035+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 4 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:15:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.035+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.035+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.035+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.036+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.036+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:00:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:15:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.039+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.039+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.039+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.039+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T01:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.039+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.039+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T01:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.040+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.040+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'load_data', 'scheduled__2023-07-31T01:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.465+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.466+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.467+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.467+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.467+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.492+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:00:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:04.995943+00:00, run_end_date=2023-07-31 20:35:05.992377+00:00, run_duration=0.996434, state=success, executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:01.651895+00:00, queued_by_job_id=2, pid=194[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.492+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:05:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:06.041755+00:00, run_end_date=2023-07-31 20:35:06.631802+00:00, run_duration=0.590047, state=success, executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:03.096510+00:00, queued_by_job_id=2, pid=201[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.492+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:10:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:05.372847+00:00, run_end_date=2023-07-31 20:35:06.156776+00:00, run_duration=0.783929, state=success, executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:02.314981+00:00, queued_by_job_id=2, pid=198[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.493+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:15:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:05.307052+00:00, run_end_date=2023-07-31 20:35:06.186996+00:00, run_duration=0.879944, state=success, executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:02.314981+00:00, queued_by_job_id=2, pid=197[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.493+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:25:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:05.798539+00:00, run_end_date=2023-07-31 20:35:06.445141+00:00, run_duration=0.646602, state=success, executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:02.314981+00:00, queued_by_job_id=2, pid=200[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.493+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:00:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:04.747334+00:00, run_end_date=2023-07-31 20:35:05.573152+00:00, run_duration=0.825818, state=success, executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:01.651895+00:00, queued_by_job_id=2, pid=192[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.493+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:00:00+00:00 [queued]> to ad89a8a5-bc9d-4511-8e95-03e061728ce6[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.497+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:05:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:05.198314+00:00, run_end_date=2023-07-31 20:35:06.046259+00:00, run_duration=0.847945, state=success, executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:00.708823+00:00, queued_by_job_id=2, pid=195[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.497+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:05:00+00:00 [queued]> to 38f2183a-26eb-48ee-bf6e-f4b97d7057c1[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.497+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:10:00+00:00 [queued]> to bc87e4be-42b7-436e-89ca-982f64ea5a03[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.497+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:10:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:05.674203+00:00, run_end_date=2023-07-31 20:35:06.370502+00:00, run_duration=0.696299, state=success, executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:02.314981+00:00, queued_by_job_id=2, pid=199[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.498+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.load_data scheduled__2023-07-31T01:15:00+00:00 [queued]> to fedc7c38-c9eb-4559-bd9a-20ed13a2b185[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.498+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:15:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:04.616840+00:00, run_end_date=2023-07-31 20:35:05.591750+00:00, run_duration=0.97491, state=success, executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:01.651895+00:00, queued_by_job_id=2, pid=191[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.557+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:20:00+00:00, run_after=2023-07-31T00:25:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.713+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:30:00+00:00: scheduled__2023-07-31T00:30:00+00:00, state:running, queued_at: 2023-07-31 20:34:53.682775+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.715+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:30:00+00:00, run_id=scheduled__2023-07-31T00:30:00+00:00, run_start_date=2023-07-31 20:34:53.699319+00:00, run_end_date=2023-07-31 20:35:07.714971+00:00, run_duration=14.015652, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:30:00+00:00, data_interval_end=2023-07-31 00:35:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:07.723+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:35:00+00:00, run_after=2023-07-31T00:40:00+00:00[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:08 +0000] "GET /object/grid_data?dag_id=TEST_DAG&num_runs=25 HTTP/1.1" 200 18335 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.455+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:40:00+00:00, run_after=2023-07-31T00:45:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.482+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:45:00+00:00: scheduled__2023-07-31T00:45:00+00:00, state:running, queued_at: 2023-07-31 20:34:54.687272+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.482+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:45:00+00:00, run_id=scheduled__2023-07-31T00:45:00+00:00, run_start_date=2023-07-31 20:34:54.706623+00:00, run_end_date=2023-07-31 20:35:08.482657+00:00, run_duration=13.776034, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:45:00+00:00, data_interval_end=2023-07-31 00:50:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.486+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:50:00+00:00, run_after=2023-07-31T00:55:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.493+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:40:00+00:00: scheduled__2023-07-31T00:40:00+00:00, state:running, queued_at: 2023-07-31 20:34:54.389597+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.493+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:40:00+00:00, run_id=scheduled__2023-07-31T00:40:00+00:00, run_start_date=2023-07-31 20:34:54.417513+00:00, run_end_date=2023-07-31 20:35:08.493526+00:00, run_duration=14.076013, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:40:00+00:00, data_interval_end=2023-07-31 00:45:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.499+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:45:00+00:00, run_after=2023-07-31T00:50:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.505+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:20:00+00:00: scheduled__2023-07-31T00:20:00+00:00, state:running, queued_at: 2023-07-31 20:34:53.268543+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.505+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:20:00+00:00, run_id=scheduled__2023-07-31T00:20:00+00:00, run_start_date=2023-07-31 20:34:53.285990+00:00, run_end_date=2023-07-31 20:35:08.505540+00:00, run_duration=15.21955, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:20:00+00:00, data_interval_end=2023-07-31 00:25:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.511+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:25:00+00:00, run_after=2023-07-31T00:30:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.517+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:50:00+00:00: scheduled__2023-07-31T00:50:00+00:00, state:running, queued_at: 2023-07-31 20:34:54.988272+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.517+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:50:00+00:00, run_id=scheduled__2023-07-31T00:50:00+00:00, run_start_date=2023-07-31 20:34:55.006462+00:00, run_end_date=2023-07-31 20:35:08.517676+00:00, run_duration=13.511214, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:50:00+00:00, data_interval_end=2023-07-31 00:55:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.523+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:55:00+00:00, run_after=2023-07-31T01:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.530+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:35:00+00:00: scheduled__2023-07-31T00:35:00+00:00, state:running, queued_at: 2023-07-31 20:34:54.031851+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.530+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:35:00+00:00, run_id=scheduled__2023-07-31T00:35:00+00:00, run_start_date=2023-07-31 20:34:54.071867+00:00, run_end_date=2023-07-31 20:35:08.530903+00:00, run_duration=14.459036, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:35:00+00:00, data_interval_end=2023-07-31 00:40:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.535+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T00:40:00+00:00, run_after=2023-07-31T00:45:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.542+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 00:55:00+00:00: scheduled__2023-07-31T00:55:00+00:00, state:running, queued_at: 2023-07-31 20:34:55.336082+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.543+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 00:55:00+00:00, run_id=scheduled__2023-07-31T00:55:00+00:00, run_start_date=2023-07-31 20:34:55.356342+00:00, run_end_date=2023-07-31 20:35:08.543115+00:00, run_duration=13.186773, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 00:55:00+00:00, data_interval_end=2023-07-31 01:00:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.548+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:00:00+00:00, run_after=2023-07-31T01:05:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.642+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.642+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.643+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.643+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.643+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.643+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.650+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:30:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:06.878387+00:00, run_end_date=2023-07-31 20:35:07.551724+00:00, run_duration=0.673337, state=success, executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:03.096510+00:00, queued_by_job_id=2, pid=208[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.651+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:35:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:07.382331+00:00, run_end_date=2023-07-31 20:35:08.311531+00:00, run_duration=0.9292, state=success, executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:03.858291+00:00, queued_by_job_id=2, pid=215[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.651+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:40:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:07.325162+00:00, run_end_date=2023-07-31 20:35:08.115163+00:00, run_duration=0.790001, state=success, executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:04.372621+00:00, queued_by_job_id=2, pid=214[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.651+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:45:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:07.669710+00:00, run_end_date=2023-07-31 20:35:08.368762+00:00, run_duration=0.699052, state=success, executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:05.255104+00:00, queued_by_job_id=2, pid=217[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.651+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:50:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:07.455077+00:00, run_end_date=2023-07-31 20:35:08.088371+00:00, run_duration=0.633294, state=success, executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:04.372621+00:00, queued_by_job_id=2, pid=216[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:08.652+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:55:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:07.335555+00:00, run_end_date=2023-07-31 20:35:08.040437+00:00, run_duration=0.704882, state=success, executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:04.372621+00:00, queued_by_job_id=2, pid=213[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.681+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:05:00+00:00, run_after=2023-07-31T01:10:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.707+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 01:10:00+00:00: scheduled__2023-07-31T01:10:00+00:00, state:running, queued_at: 2023-07-31 20:34:56.553932+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.708+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 01:10:00+00:00, run_id=scheduled__2023-07-31T01:10:00+00:00, run_start_date=2023-07-31 20:34:56.574622+00:00, run_end_date=2023-07-31 20:35:09.707980+00:00, run_duration=13.133358, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 01:10:00+00:00, data_interval_end=2023-07-31 01:15:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.712+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:15:00+00:00, run_after=2023-07-31T01:20:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.720+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 01:00:00+00:00: scheduled__2023-07-31T01:00:00+00:00, state:running, queued_at: 2023-07-31 20:34:55.690079+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.721+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 01:00:00+00:00, run_id=scheduled__2023-07-31T01:00:00+00:00, run_start_date=2023-07-31 20:34:55.709691+00:00, run_end_date=2023-07-31 20:35:09.721101+00:00, run_duration=14.01141, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 01:00:00+00:00, data_interval_end=2023-07-31 01:05:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.726+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:05:00+00:00, run_after=2023-07-31T01:10:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.733+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 01:15:00+00:00: scheduled__2023-07-31T01:15:00+00:00, state:running, queued_at: 2023-07-31 20:34:56.974859+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.734+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 01:15:00+00:00, run_id=scheduled__2023-07-31T01:15:00+00:00, run_start_date=2023-07-31 20:34:57.005926+00:00, run_end_date=2023-07-31 20:35:09.733997+00:00, run_duration=12.728071, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 01:15:00+00:00, data_interval_end=2023-07-31 01:20:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.739+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:20:00+00:00, run_after=2023-07-31T01:25:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.747+0000[0m] {[34mdagrun.py:[0m630} INFO[0m - Marking run <DagRun TEST_DAG @ 2023-07-31 01:05:00+00:00: scheduled__2023-07-31T01:05:00+00:00, state:running, queued_at: 2023-07-31 20:34:56.051451+00:00. externally triggered: False> successful[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.747+0000[0m] {[34mdagrun.py:[0m696} INFO[0m - DagRun Finished: dag_id=TEST_DAG, execution_date=2023-07-31 01:05:00+00:00, run_id=scheduled__2023-07-31T01:05:00+00:00, run_start_date=2023-07-31 20:34:56.076465+00:00, run_end_date=2023-07-31 20:35:09.747747+00:00, run_duration=13.671282, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2023-07-31 01:05:00+00:00, data_interval_end=2023-07-31 01:10:00+00:00, dag_hash=8d942b17caa4fc30ac84b49866a9e1d8[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.751+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:10:00+00:00, run_after=2023-07-31T01:15:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.770+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T00:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.770+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.770+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.770+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.771+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='load_data', run_id='scheduled__2023-07-31T01:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.776+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T00:20:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:07.796602+00:00, run_end_date=2023-07-31 20:35:08.464398+00:00, run_duration=0.667796, state=success, executor_state=success, try_number=1, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:04.372621+00:00, queued_by_job_id=2, pid=218[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.776+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T01:00:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:08.801794+00:00, run_end_date=2023-07-31 20:35:08.990176+00:00, run_duration=0.188382, state=success, executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:07.036833+00:00, queued_by_job_id=2, pid=223[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.776+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T01:05:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:08.939365+00:00, run_end_date=2023-07-31 20:35:09.130772+00:00, run_duration=0.191407, state=success, executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:07.036833+00:00, queued_by_job_id=2, pid=225[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.776+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T01:10:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:08.923998+00:00, run_end_date=2023-07-31 20:35:09.107931+00:00, run_duration=0.183933, state=success, executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:07.036833+00:00, queued_by_job_id=2, pid=224[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:09.776+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=load_data, run_id=scheduled__2023-07-31T01:15:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:08.947766+00:00, run_end_date=2023-07-31 20:35:09.137674+00:00, run_duration=0.189908, state=success, executor_state=success, try_number=1, max_tries=1, job_id=50, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2023-07-31 20:35:07.036833+00:00, queued_by_job_id=2, pid=226[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:10.812+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:15:00+00:00, run_after=2023-07-31T01:20:00+00:00[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:11 +0000] "GET /object/grid_data?dag_id=TEST_DAG&num_runs=25 HTTP/1.1" 200 19029 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:11.890+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:20:00+00:00, run_after=2023-07-31T01:25:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.065+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:25:00+00:00, run_after=2023-07-31T01:30:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.124+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:20:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.125+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 0/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.125+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:20:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.129+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:20:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.129+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.171+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.180+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:20:00+00:00 [queued]> to 159fa2e1-6d81-471e-9a6e-b237624fc7ab[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.219+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:30:00+00:00, run_after=2023-07-31T01:35:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.288+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.288+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 1/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.288+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.292+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:25:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.292+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.342+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.351+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:25:00+00:00 [queued]> to 48f49d0f-7cb8-442b-b9c0-bc6e1cbb55f4[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.389+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:35:00+00:00, run_after=2023-07-31T01:40:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.486+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.487+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 2/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.487+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.490+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:30:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.491+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.543+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.550+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:30:00+00:00 [queued]> to 53e8ea29-76ea-452e-af72-d3007de5f340[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.589+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:40:00+00:00, run_after=2023-07-31T01:45:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.702+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.702+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 3/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.702+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:35:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.707+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:35:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.707+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.765+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.776+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:35:00+00:00 [queued]> to ecbd9ee4-f2e0-4581-9a1b-8d8904aef10e[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.809+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:45:00+00:00, run_after=2023-07-31T01:50:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.917+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:40:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.917+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 4/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.917+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:40:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.920+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:40:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.921+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.969+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:12.975+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:40:00+00:00 [queued]> to e0e1082c-5218-46a9-8b5b-4b4f162f78a1[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.010+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:50:00+00:00, run_after=2023-07-31T01:55:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.130+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:45:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.131+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 5/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.131+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:45:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.134+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:45:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.134+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:45:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.240+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.248+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:45:00+00:00 [queued]> to 20a06520-3bc2-49f0-ba2d-61ce9a4b809b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.295+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T01:55:00+00:00, run_after=2023-07-31T02:00:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.433+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:50:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.433+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 6/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.433+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:50:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.437+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:50:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.438+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:50:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.535+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.547+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:50:00+00:00 [queued]> to 6e8b25a5-db0e-48a2-9051-6899c9b0c5fa[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.612+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T02:00:00+00:00, run_after=2023-07-31T02:05:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.800+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:55:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.801+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.801+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:55:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.805+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:55:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.805+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T01:55:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.909+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.915+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T01:55:00+00:00 [queued]> to a7219758-4d52-4ee7-ab96-df70a54d3027[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:13.958+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T02:05:00+00:00, run_after=2023-07-31T02:10:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.141+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 1 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.142+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.142+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:00:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.145+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.145+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.248+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.256+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:00:00+00:00 [queued]> to e57d3452-8f1b-46c5-9199-548b16f678d9[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.318+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T02:10:00+00:00, run_after=2023-07-31T02:15:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.538+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:20:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.539+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 7/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.539+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.539+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.539+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:05:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:20:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:25:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.545+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:05:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.545+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T02:05:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.546+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:20:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.546+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:20:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.546+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:25:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.546+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:25:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.846+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.847+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.875+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:20:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:13.616634+00:00, run_end_date=2023-07-31 20:35:14.216637+00:00, run_duration=0.600003, state=success, executor_state=success, try_number=1, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:12.126345+00:00, queued_by_job_id=2, pid=239[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.875+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:20:00+00:00 [queued]> to 90dde044-326a-4b53-bacd-e40917302858[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.875+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:25:00+00:00 [queued]> to f816ba00-d0d7-48e8-8c68-8489fc99640b[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.876+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:25:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:13.681897+00:00, run_end_date=2023-07-31 20:35:14.252865+00:00, run_duration=0.570968, state=success, executor_state=success, try_number=1, max_tries=1, job_id=52, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:12.289841+00:00, queued_by_job_id=2, pid=240[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.876+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:05:00+00:00 [queued]> to 5a1bc30c-705b-40de-8e54-1f667945f960[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:14.964+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T02:15:00+00:00, run_after=2023-07-31T02:20:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.231+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 2 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.231+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.231+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.232+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:10:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:30:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.236+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:10:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.236+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T02:10:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.236+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:30:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.236+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:30:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.562+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.563+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.563+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.586+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:30:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:14.223983+00:00, run_end_date=2023-07-31 20:35:14.742790+00:00, run_duration=0.518807, state=success, executor_state=success, try_number=1, max_tries=1, job_id=53, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:12.488064+00:00, queued_by_job_id=2, pid=244[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.587+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:30:00+00:00 [queued]> to 7fd82063-e60a-440a-97a7-1a8822ddb173[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.587+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:10:00+00:00 [queued]> to 2bfcc3cf-712f-4b53-9ffe-2ed5ae4cb40a[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.667+0000[0m] {[34mdag.py:[0m3508} INFO[0m - Setting next_dagrun for TEST_DAG to 2023-07-31T02:20:00+00:00, run_after=2023-07-31T02:25:00+00:00[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.937+0000[0m] {[34mscheduler_job_runner.py:[0m412} INFO[0m - 3 tasks up for execution:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:35:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:40:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.938+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 8/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.938+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 9/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.938+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG TEST_DAG has 10/16 running and queued tasks[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.938+0000[0m] {[34mscheduler_job_runner.py:[0m587} INFO[0m - Setting the following tasks to queued state:
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:15:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:35:00+00:00 [scheduled]>
airflow-airflow-scheduler-1  | 	<TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:40:00+00:00 [scheduled]>[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.944+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:15:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.944+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'extract_data', 'scheduled__2023-07-31T02:15:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.945+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:35:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.945+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:35:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.945+0000[0m] {[34mscheduler_job_runner.py:[0m625} INFO[0m - Sending TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:40:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:15.946+0000[0m] {[34mbase_executor.py:[0m147} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'TEST_DAG', 'transform_data', 'scheduled__2023-07-31T01:40:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_dag.py'][0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:16 +0000] "POST /paused?is_paused=false&dag_id=TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.292+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.293+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.293+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.293+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.293+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.293+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:45:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.319+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:35:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:14.708105+00:00, run_end_date=2023-07-31 20:35:15.253567+00:00, run_duration=0.545462, state=success, executor_state=success, try_number=1, max_tries=1, job_id=54, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:12.703889+00:00, queued_by_job_id=2, pid=249[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.320+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:35:00+00:00 [queued]> to be0a6e6e-6ac6-4378-84e8-be0c2fb744e2[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.320+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:40:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:14.927042+00:00, run_end_date=2023-07-31 20:35:15.505454+00:00, run_duration=0.578412, state=success, executor_state=success, try_number=1, max_tries=1, job_id=55, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:12.918708+00:00, queued_by_job_id=2, pid=251[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.320+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.transform_data scheduled__2023-07-31T01:40:00+00:00 [queued]> to f160acd7-1854-488b-86e4-f25549d439e0[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.321+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:45:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:15.196383+00:00, run_end_date=2023-07-31 20:35:15.833561+00:00, run_duration=0.637178, state=success, executor_state=success, try_number=1, max_tries=1, job_id=56, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:13.132049+00:00, queued_by_job_id=2, pid=253[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:16.321+0000[0m] {[34mscheduler_job_runner.py:[0m703} INFO[0m - Setting external_id for <TaskInstance: TEST_DAG.extract_data scheduled__2023-07-31T02:15:00+00:00 [queued]> to d5862639-0a21-436f-b2b5-23f73a21e9eb[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:17.100+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:50:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:17.106+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:50:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:15.621007+00:00, run_end_date=2023-07-31 20:35:16.258065+00:00, run_duration=0.637058, state=success, executor_state=success, try_number=1, max_tries=1, job_id=57, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:13.435279+00:00, queued_by_job_id=2, pid=256[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:17 +0000] "GET /dags/TEST_DAG/graph HTTP/1.1" 200 11966 "http://localhost:8080/dags/TEST_DAG/grid" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:17 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:17 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:17 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.css HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.184+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T01:55:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.184+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:00:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.184+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:05:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.184+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:20:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.184+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:25:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.184+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:10:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.185+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:30:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.208+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:20:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:17.005847+00:00, run_end_date=2023-07-31 20:35:17.472119+00:00, run_duration=0.466272, state=success, executor_state=success, try_number=1, max_tries=1, job_id=62, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:14.541399+00:00, queued_by_job_id=2, pid=271[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.209+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:25:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:16.820401+00:00, run_end_date=2023-07-31 20:35:17.384737+00:00, run_duration=0.564336, state=success, executor_state=success, try_number=1, max_tries=1, job_id=60, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:14.541399+00:00, queued_by_job_id=2, pid=267[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.209+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:30:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:17.357989+00:00, run_end_date=2023-07-31 20:35:17.774426+00:00, run_duration=0.416437, state=success, executor_state=success, try_number=1, max_tries=1, job_id=63, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:15.233322+00:00, queued_by_job_id=2, pid=273[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.209+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T01:55:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:16.424209+00:00, run_end_date=2023-07-31 20:35:16.984897+00:00, run_duration=0.560688, state=success, executor_state=success, try_number=1, max_tries=1, job_id=58, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:13.802631+00:00, queued_by_job_id=2, pid=264[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.209+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T02:00:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:16.413033+00:00, run_end_date=2023-07-31 20:35:16.961869+00:00, run_duration=0.548836, state=success, executor_state=success, try_number=1, max_tries=1, job_id=59, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:14.143064+00:00, queued_by_job_id=2, pid=265[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.210+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T02:05:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:17.001592+00:00, run_end_date=2023-07-31 20:35:17.536986+00:00, run_duration=0.535394, state=success, executor_state=success, try_number=1, max_tries=1, job_id=61, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:14.541399+00:00, queued_by_job_id=2, pid=270[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:18.210+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T02:10:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:17.451842+00:00, run_end_date=2023-07-31 20:35:17.865177+00:00, run_duration=0.413335, state=success, executor_state=success, try_number=1, max_tries=1, job_id=64, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:15.233322+00:00, queued_by_job_id=2, pid=274[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/d3-shape.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/graph.0fda9db613abebc1b43a.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /static/dist/dagre-d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:18 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:19.012+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='extract_data', run_id='scheduled__2023-07-31T02:15:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:19.013+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:35:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:19.013+0000[0m] {[34mscheduler_job_runner.py:[0m677} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='TEST_DAG', task_id='transform_data', run_id='scheduled__2023-07-31T01:40:00+00:00', try_number=1, map_index=-1)[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:19.024+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:35:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:17.812522+00:00, run_end_date=2023-07-31 20:35:18.164747+00:00, run_duration=0.352225, state=success, executor_state=success, try_number=1, max_tries=1, job_id=65, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:15.940168+00:00, queued_by_job_id=2, pid=275[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:19.025+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=transform_data, run_id=scheduled__2023-07-31T01:40:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:18.056395+00:00, run_end_date=2023-07-31 20:35:18.381601+00:00, run_duration=0.325206, state=success, executor_state=success, try_number=1, max_tries=1, job_id=67, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2023-07-31 20:35:15.940168+00:00, queued_by_job_id=2, pid=277[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:35:19.025+0000[0m] {[34mscheduler_job_runner.py:[0m733} INFO[0m - TaskInstance Finished: dag_id=TEST_DAG, task_id=extract_data, run_id=scheduled__2023-07-31T02:15:00+00:00, map_index=-1, run_start_date=2023-07-31 20:35:17.840014+00:00, run_end_date=2023-07-31 20:35:18.253835+00:00, run_duration=0.413821, state=success, executor_state=success, try_number=1, max_tries=1, job_id=66, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2023-07-31 20:35:15.940168+00:00, queued_by_job_id=2, pid=276[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:21 +0000] "GET /object/task_instances?dag_id=TEST_DAG&execution_date=2023-07-31T02%3A15%3A00%2B00%3A00 HTTP/1.1" 200 2112 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /dags/TEST_DAG/calendar HTTP/1.1" 200 139734 "http://localhost:8080/dags/TEST_DAG/graph" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:23 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/calendar.604d75f4e337e3558e87.css HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/calendar.604d75f4e337e3558e87.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:24 +0000] "GET /static/loading.gif HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:25 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:35:30.108+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /dags/TEST_DAG/duration?days=30 HTTP/1.1" 200 49616 "http://localhost:8080/dags/TEST_DAG/calendar" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/nv.d3.min.css HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/nv.d3.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /static/dist/durationChart.89b44e023d6e6031dec0.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:44 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /dags/TEST_DAG/tries?days=30 HTTP/1.1" 200 45873 "http://localhost:8080/dags/TEST_DAG/duration?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/nv.d3.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/nv.d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:47 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /dags/TEST_DAG/landing-times?days=30 HTTP/1.1" 200 46239 "http://localhost:8080/dags/TEST_DAG/tries?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:48 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/nv.d3.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/nv.d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:49 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:51 +0000] "GET /dags/TEST_DAG/gantt HTTP/1.1" 200 46726 "http://localhost:8080/dags/TEST_DAG/landing-times?days=30" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:51 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:51 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/chart.481474e9dc8726162195.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/d3.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/d3-tip.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/gantt.9995f2d594526c5d78cc.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /static/dist/gantt.9995f2d594526c5d78cc.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:52 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:35:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /dags/TEST_DAG/code HTTP/1.1" 200 47965 "http://localhost:8080/dags/TEST_DAG/gantt" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:54 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/dagCode.f0a516f657a0c4d2f6e2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:35:55 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /dags/TEST_DAG/audit_log HTTP/1.1" 200 111476 "http://localhost:8080/dags/TEST_DAG/code" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/fontawesome/fontawesome.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/fontawesome/solid.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/fontawesome/regular.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/fontawesome/brands.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/fontawesome/v4-shims.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/select2/select2-bootstrap-theme.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/select2/select2.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/flags/flags16.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/css/ab.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/airflowDefaultTheme.9c52407a4b82b6d0a2da.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/materialIcons.087c3315826ce743dc8d.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/loadingDots.5da42d00b5455806e709.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/bootstrap-datetimepicker.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/js/jquery-latest.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/switch.ed802dd5ece5b1999671.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/js/ab_filters.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/js/ab_actions.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/flash.a58a9322159cd5cd08c3.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/js/bootstrap.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/datepicker/bootstrap-datepicker.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/js/ab.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/appbuilder/select2/select2.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/moment.805846635248ee428644.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/main.7482f675ad7c97dc7702.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/bootstrap-datetimepicker.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/bootstrap3-typeahead.min.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/dataTables.bootstrap.min.css HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/dag.6d311bfbbeb8a16285a9.js HTTP/1.1" 304 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/jquery.dataTables.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /static/dist/dataTables.bootstrap.min.js HTTP/1.1" 200 0 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 172.20.0.1 - - [31/Jul/2023:20:36:01 +0000] "GET /object/next_run_datasets/TEST_DAG HTTP/1.1" 200 2 "http://localhost:8080/dags/TEST_DAG/audit_log" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:36:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:36:30.169+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:36:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:37:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:37:30.230+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-redis-1              | 1:M 31 Jul 2023 20:37:44.002 * 100 changes in 300 seconds. Saving...
airflow-redis-1              | 1:M 31 Jul 2023 20:37:44.002 * Background saving started by pid 196
airflow-redis-1              | 196:C 31 Jul 2023 20:37:44.015 * DB saved on disk
airflow-redis-1              | 196:C 31 Jul 2023 20:37:44.015 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB
airflow-redis-1              | 1:M 31 Jul 2023 20:37:44.102 * Background saving terminated with success
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:37:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:38:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:38:30.291+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-scheduler-1  | [[34m2023-07-31T20:38:31.508+0000[0m] {[34mscheduler_job_runner.py:[0m1553} INFO[0m - Resetting orphaned tasks for active dag runs[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:38:53 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:39:23 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
airflow-airflow-triggerer-1  | [[34m2023-07-31T20:39:30.351+0000[0m] {[34mtriggerer_job_runner.py:[0m483} INFO[0m - 0 triggers currently running[0m
airflow-airflow-webserver-1  | 127.0.0.1 - - [31/Jul/2023:20:39:54 +0000] "GET /health HTTP/1.1" 200 243 "-" "curl/7.74.0"
